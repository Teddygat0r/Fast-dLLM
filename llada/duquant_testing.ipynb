{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4a738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshuaz/dllm/Fast-dLLM/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model.modeling_llada import LLaDAModelLM\n",
    "from transformers import AutoTokenizer\n",
    "from quantization_calibration_dataset import LLaDACalibrationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "from duquant_utils import create_quant_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0fd18c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 707.20it/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"GSAI-ML/LLaDA-8B-Instruct\"\n",
    "device = \"cuda\"\n",
    "\n",
    "model = LLaDAModelLM.from_pretrained(MODEL_PATH, trust_remote_code=True, torch_dtype=torch.bfloat16).to(device).eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fafa0b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_args = {\n",
    "    \"nsamples\": 128,\n",
    "    \"seqlen\": 2048,\n",
    "    \"wbits\": 8,\n",
    "    \"abits\": 8,\n",
    "    \"alpha\": 0.5, # for smoothquant\n",
    "    \"act_group_size\": None,\n",
    "    \"smooth\": True,\n",
    "    \"quant_method\": \"duquant\",\n",
    "    \"symmetric\": True,\n",
    "    \"group_size\": None,\n",
    "    \"swc\": 0.8,\n",
    "    \"lac\": 0.9,\n",
    "    \"lwc\": False,\n",
    "    \"block_size\": 128,\n",
    "    \"max_rotation_step\": 256,\n",
    "    \"permutation_times\": 1,\n",
    "    \"batch_size\": 1\n",
    "}\n",
    "\n",
    "# args = argparse.Namespace(**user_args)\n",
    "args = create_quant_args(user_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bde2e12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Calibration Buffer with Mask ID: 126336...\n",
      "Concatenating and tokenizing dataset...\n",
      "Total tokens in concatenated dataset: 2608998\n",
      "Calibration Dataset Ready: 128 tensors.\n"
     ]
    }
   ],
   "source": [
    "act_scales = torch.load(\"act_scales/LLaDA-8B-Instruct.pt\")        \n",
    "dataset = LLaDACalibrationDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    seq_len=args.seqlen,\n",
    "    samples=args.nsamples,\n",
    "    block_size=args.block_size,\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b5241fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "import torch\n",
    "from torch import nn\n",
    "from duquant_utils import set_init_duquant_params_state, set_quant_state, smooth_and_let_inplace\n",
    "from model.quantize.int_linear import QuantLinear\n",
    "from model.int_llada_layer import LLaDaQuantLayer\n",
    "\n",
    "CLIPMIN = 1e-5\n",
    "\n",
    "def duquant(model: nn.Module, act_scales: dict, dataloader, args):\n",
    "    layers = model.model.transformer.blocks\n",
    "    use_cache = model.config.use_cache\n",
    "    model.config.use_cache = False\n",
    "    dtype = torch.bfloat16\n",
    "    dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seqlen = args.seqlen\n",
    "    pairs = {\n",
    "        \"q_proj\":\"qkv\",\n",
    "        \"attn_out\":\"out\",\n",
    "        \"up_proj\":\"fc1\",\n",
    "        \"ff_out\":\"down\",\n",
    "    }\n",
    "\n",
    "    inps = torch.zeros(\n",
    "        (args.nsamples, seqlen, model.config.hidden_size), dtype=dtype, device=dev\n",
    "    )\n",
    "    cache = {\"i\": 0}\n",
    "\n",
    "    class Catcher(nn.Module):\n",
    "        def __init__(self, module):\n",
    "            super().__init__()\n",
    "            self.module = module\n",
    "\n",
    "        def forward(self, inp, **kwargs):\n",
    "            if len(inp.shape) == 3:\n",
    "                 inps[cache[\"i\"]] = inp[0] \n",
    "            else:\n",
    "                 inps[cache[\"i\"]] = inp\n",
    "            cache[\"i\"] += 1\n",
    "            return self.module(inp, **kwargs)\n",
    "    \n",
    "    layers[0] = Catcher(layers[0])\n",
    "\n",
    "    input_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            if cache[\"i\"] >= args.nsamples:\n",
    "                break\n",
    "            try:\n",
    "                input_ids.append(batch['input_ids'])\n",
    "                model(batch['input_ids'].to(dev))\n",
    "\n",
    "            except ValueError:\n",
    "                pass\n",
    "    \n",
    "    layers[0] = layers[0].module\n",
    "    layers[0] = layers[0].cpu()\n",
    "\n",
    "    print(layers[0])\n",
    "    duquant_parameters = {}\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    quant_inps = inps\n",
    "    rotate_inps = copy.copy(inps).mean(dim=0)\n",
    "\n",
    "    fp_inps = copy.deepcopy(inps)\n",
    "    \n",
    "    for i in range(len(layers)):\n",
    "        print(\"Starting Layer, \" + str(i))\n",
    "        args.q_quant_params = copy.copy(args.act_quant_params)\n",
    "        args.k_quant_params = copy.copy(args.act_quant_params)\n",
    "        layer = layers[i]\n",
    "        qlayer = LLaDaQuantLayer(layer, args)\n",
    "        qlayer.set_quant_state(weight_quant=False, act_quant=True)\n",
    "\n",
    "        for name, module in layer.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                weight_quant = QuantLinear(module, weight_quant_params=copy.copy(args.weight_quant_params), act_quant_params=copy.copy(args.act_quant_params))\n",
    "                setattr(qlayer, name, weight_quant)\n",
    "\n",
    "        qlayer.load_state_dict(layer.state_dict())\n",
    "        qlayer.to(dev)\n",
    "\n",
    "        set_init_duquant_params_state(qlayer, True)\n",
    "        set_quant_state(qlayer, weight_quant=False, act_quant=True)\n",
    "\n",
    "        qlayer.register_parameter(\"qkt_smooth_scale\",torch.nn.Parameter(torch.ones(qlayer.q_proj.out_features,device=dev, dtype=dtype), requires_grad=False))\n",
    "        for name, module in qlayer.named_modules():\n",
    "            if isinstance(module, QuantLinear):\n",
    "                for key in pairs.keys():\n",
    "                    if key in name:\n",
    "                        act = act_scales[f\"model.transformer.blocks.{i}.{key}\"].to(device=dev, dtype=dtype).clamp(min=CLIPMIN)\n",
    "                        weight = module.weight.abs().max(dim=0)[0].clamp(min=CLIPMIN)\n",
    "                        scale = (act.pow(args.alpha)/weight.to(act.device).pow(1-args.alpha)).clamp(min=CLIPMIN)\n",
    "\n",
    "                        qlayer.register_parameter(f\"{pairs[key]}_smooth_scale\",torch.nn.Parameter(scale, requires_grad=False))\n",
    "\n",
    "        qlayer.to(dtype=torch.bfloat16)\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                qlayer.qkt_smooth_scale.clamp_(min=0.5)\n",
    "        except:\n",
    "            pass\n",
    "        smooth_and_let_inplace(qlayer, args)\n",
    "\n",
    "        # perform duquant process\n",
    "        set_init_duquant_params_state(qlayer, False)\n",
    "        set_quant_state(qlayer, weight_quant=True, act_quant=True)\n",
    "        with torch.no_grad():\n",
    "            with torch.amp.autocast(device_type=dev):\n",
    "                rotate_inps = qlayer(rotate_inps.unsqueeze(0))[0][0]\n",
    "            qlayer.register_duquant_params()\n",
    "            set_init_duquant_params_state(qlayer, True)\n",
    "\n",
    "        qlayer.to(dtype=torch.bfloat16)\n",
    "        with torch.no_grad():\n",
    "            for name, module in qlayer.named_modules():\n",
    "                if isinstance(module, QuantLinear):\n",
    "                    module.weight = module.weight_quantizer(module.weight, return_no_quant=True)\n",
    "\n",
    "        set_quant_state(qlayer, weight_quant=False, act_quant=True)\n",
    "        layers[i] = qlayer.to(\"cpu\")\n",
    "        # i dont think this is necessary for loading\n",
    "        # duquant_parameters[i] = duquant_state_dict(qlayer)\n",
    "\n",
    "        del layer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.model.transformer.embed_tokens = model.model.transformer.wte.to('cpu')\n",
    "    del inps\n",
    "    del quant_inps\n",
    "    del fp_inps\n",
    "    del rotate_inps\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()                    \n",
    "    model.config.use_cache = use_cache\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "950f97cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaDALlamaBlock(\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (act): SiLU()\n",
      "  (attn_out): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (ff_out): Linear(in_features=12288, out_features=4096, bias=False)\n",
      "  (rotary_emb): RotaryEmbedding()\n",
      "  (attn_norm): RMSLayerNorm()\n",
      "  (ff_norm): RMSLayerNorm()\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (ff_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
      ")\n",
      "Starting Layer, 0\n",
      "Starting Layer, 1\n",
      "Starting Layer, 2\n",
      "Starting Layer, 3\n",
      "Starting Layer, 4\n",
      "Starting Layer, 5\n",
      "Starting Layer, 6\n",
      "Starting Layer, 7\n",
      "Starting Layer, 8\n",
      "Starting Layer, 9\n",
      "Starting Layer, 10\n",
      "Starting Layer, 11\n",
      "Starting Layer, 12\n",
      "Starting Layer, 13\n",
      "Starting Layer, 14\n",
      "Starting Layer, 15\n",
      "Starting Layer, 16\n",
      "Starting Layer, 17\n",
      "Starting Layer, 18\n",
      "Starting Layer, 19\n",
      "Starting Layer, 20\n",
      "Starting Layer, 21\n",
      "Starting Layer, 22\n",
      "Starting Layer, 23\n",
      "Starting Layer, 24\n",
      "Starting Layer, 25\n",
      "Starting Layer, 26\n",
      "Starting Layer, 27\n",
      "Starting Layer, 28\n",
      "Starting Layer, 29\n",
      "Starting Layer, 30\n",
      "Starting Layer, 31\n"
     ]
    }
   ],
   "source": [
    "model = duquant(model, act_scales, dataloader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6055bdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLaDAModelLM(\n",
       "  (model): LLaDAModel(\n",
       "    (transformer): ModuleDict(\n",
       "      (wte): Embedding(126464, 4096)\n",
       "      (emb_drop): Dropout(p=0.0, inplace=False)\n",
       "      (ln_f): RMSLayerNorm()\n",
       "      (blocks): ModuleList(\n",
       "        (0-31): 32 x LLaDaQuantLayer(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (act): SiLU()\n",
       "          (attn_out): QuantLinear(\n",
       "            (weight_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (act_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (ff_out): QuantLinear(\n",
       "            (weight_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (act_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (attn_norm): RMSLayerNorm()\n",
       "          (ff_norm): RMSLayerNorm()\n",
       "          (q_proj): QuantLinear(\n",
       "            (weight_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (act_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (k_proj): QuantLinear(\n",
       "            (weight_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (act_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (v_proj): QuantLinear(\n",
       "            (weight_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (act_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (ff_proj): QuantLinear(\n",
       "            (weight_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (act_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (up_proj): QuantLinear(\n",
       "            (weight_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (act_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (qkt_matmul): QuantMatMul(\n",
       "            (x1_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (x2_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (pv_matmul): QuantMatMul(\n",
       "            (x1_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "            (x2_quantizer): UniformAffineQuantizer(\n",
       "              (sigmoid): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ff_out): Linear(in_features=4096, out_features=126464, bias=False)\n",
       "      (embed_tokens): Embedding(126464, 4096)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33468b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot's reply: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from generate import generate\n",
    "\n",
    "user_input = input(\"Enter your question: \")\n",
    "\n",
    "m = [{\"role\": \"user\", \"content\": user_input}]\n",
    "user_input = tokenizer.apply_chat_template(m, add_generation_prompt=True, tokenize=False)\n",
    "input_ids = tokenizer(user_input)['input_ids']\n",
    "input_ids = torch.tensor(input_ids).to(device).unsqueeze(0)\n",
    "\n",
    "out, nfe = generate(model, input_ids, steps=128, gen_length=128, block_length=args.block_size, temperature=0., remasking='low_confidence', threshold=0.9)\n",
    "answer = tokenizer.batch_decode(out[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "print(f\"Bot's reply: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "856fbd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 213.11it/s]\n"
     ]
    }
   ],
   "source": [
    "original_model = LLaDAModelLM.from_pretrained(MODEL_PATH, trust_remote_code=True, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43d03495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equality found in model.transformer.ff_out.weight\n",
      "Quantized weight shape: torch.Size([126464, 4096])\n",
      "Original weight shape: torch.Size([126464, 4096])\n",
      "Equality found in model.transformer.wte.weight\n",
      "Quantized weight shape: torch.Size([126464, 4096])\n",
      "Original weight shape: torch.Size([126464, 4096])\n",
      "Equality found in model.transformer.ln_f.weight\n",
      "Quantized weight shape: torch.Size([4096])\n",
      "Original weight shape: torch.Size([4096])\n"
     ]
    }
   ],
   "source": [
    "quantized_state_dict = model.state_dict()\n",
    "original_state_dict = original_model.state_dict()\n",
    "\n",
    "for key in quantized_state_dict.keys():\n",
    "    quantized_state_dict[key] = quantized_state_dict[key].to(\"cpu\")\n",
    "\n",
    "for key in original_state_dict.keys():\n",
    "    original_state_dict[key] = original_state_dict[key].to(\"cpu\")\n",
    "\n",
    "common_keys = set(quantized_state_dict.keys()) & set(original_state_dict.keys())\n",
    "for key in common_keys:\n",
    "    quantized_weight = quantized_state_dict[key]\n",
    "    original_weight = original_state_dict[key]\n",
    "    if torch.equal(quantized_weight, original_weight):\n",
    "        print(f\"Equality found in {key}\")\n",
    "        print(f\"Quantized weight shape: {quantized_weight.shape}\")\n",
    "        print(f\"Original weight shape: {original_weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "033d7ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.transformer.blocks.9.ff_proj.bias', 'model.transformer.blocks.25.ori_layer.k_proj.weight', 'model.transformer.blocks.8.up_proj.bias', 'model.transformer.blocks.5.attn_out.bias', 'model.transformer.blocks.28.ff_norm.bias', 'model.transformer.blocks.17.ori_layer.attn_norm.weight', 'model.transformer.blocks.29.ori_layer.ff_out.weight', 'model.transformer.blocks.28.down_smooth_shift', 'model.transformer.blocks.8.attn_out.bias', 'model.transformer.blocks.2.q_proj.bias', 'model.transformer.blocks.0.fc1_smooth_shift', 'model.transformer.blocks.9.ori_layer.v_proj.weight', 'model.transformer.blocks.22.q_proj.bias', 'model.transformer.blocks.1.qkv_smooth_shift', 'model.transformer.blocks.3.ori_layer.q_proj.weight', 'model.transformer.blocks.20.ori_layer.q_proj.weight', 'model.transformer.blocks.19.ori_layer.attn_norm.weight', 'model.transformer.blocks.28.fc1_smooth_shift', 'model.transformer.blocks.19.ff_norm.bias', 'model.transformer.blocks.10.ori_layer.ff_out.weight', 'model.transformer.blocks.14.ori_layer.q_proj.weight', 'model.transformer.blocks.14.ori_layer.ff_norm.weight', 'model.transformer.blocks.20.ori_layer.attn_out.weight', 'model.transformer.blocks.15.down_smooth_shift', 'model.transformer.blocks.12.ori_layer.ff_out.weight', 'model.transformer.blocks.13.ori_layer.v_proj.weight', 'model.transformer.blocks.12.ori_layer.attn_out.weight', 'model.transformer.blocks.21.down_smooth_shift', 'model.transformer.blocks.8.ff_norm.bias', 'model.transformer.blocks.6.ori_layer.ff_out.weight', 'model.transformer.blocks.5.down_smooth_shift', 'model.transformer.blocks.13.ff_out.bias', 'model.transformer.blocks.0.v_proj.bias', 'model.transformer.blocks.21.ori_layer.up_proj.weight', 'model.transformer.blocks.9.fc1_smooth_shift', 'model.transformer.blocks.4.qkv_smooth_shift', 'model.transformer.blocks.4.ff_out.bias', 'model.transformer.blocks.10.fc1_smooth_shift', 'model.transformer.blocks.6.attn_norm.bias', 'model.transformer.blocks.20.ori_layer.ff_proj.weight', 'model.transformer.blocks.31.out_smooth_shift', 'model.transformer.blocks.26.ori_layer.q_proj.weight', 'model.transformer.blocks.22.ori_layer.attn_out.weight', 'model.transformer.blocks.3.attn_norm.bias', 'model.transformer.blocks.9.ori_layer.up_proj.weight', 'model.transformer.blocks.23.ori_layer.v_proj.weight', 'model.transformer.blocks.2.ori_layer.k_proj.weight', 'model.transformer.blocks.7.attn_out.bias', 'model.transformer.blocks.17.out_smooth_shift', 'model.transformer.blocks.28.ori_layer.up_proj.weight', 'model.transformer.blocks.31.ori_layer.q_proj.weight', 'model.transformer.blocks.23.down_smooth_shift', 'model.transformer.blocks.0.ff_proj.bias', 'model.transformer.blocks.31.q_proj.bias', 'model.transformer.blocks.23.ff_proj.bias', 'model.transformer.blocks.2.ff_norm.bias', 'model.transformer.blocks.26.down_smooth_shift', 'model.transformer.blocks.12.attn_out.bias', 'model.transformer.blocks.30.attn_norm.bias', 'model.transformer.blocks.23.ff_norm.bias', 'model.transformer.blocks.17.ori_layer.k_proj.weight', 'model.transformer.blocks.28.up_proj.bias', 'model.transformer.blocks.6.ori_layer.k_proj.weight', 'model.transformer.blocks.28.ori_layer.q_proj.weight', 'model.transformer.blocks.11.ori_layer.ff_out.weight', 'model.transformer.blocks.22.ff_out.bias', 'model.transformer.blocks.30.ori_layer.v_proj.weight', 'model.transformer.blocks.15.up_proj.bias', 'model.transformer.blocks.14.attn_norm.bias', 'model.transformer.blocks.19.up_proj.bias', 'model.transformer.blocks.31.ori_layer.k_proj.weight', 'model.transformer.blocks.27.attn_norm.bias', 'model.transformer.blocks.1.ori_layer.q_proj.weight', 'model.transformer.blocks.28.attn_norm.bias', 'model.transformer.blocks.14.down_smooth_shift', 'model.transformer.blocks.3.ori_layer.attn_out.weight', 'model.transformer.blocks.16.attn_out.bias', 'model.transformer.blocks.22.qkv_smooth_shift', 'model.transformer.blocks.12.fc1_smooth_shift', 'model.transformer.blocks.14.v_proj.bias', 'model.transformer.blocks.19.ori_layer.v_proj.weight', 'model.transformer.blocks.8.attn_norm.bias', 'model.transformer.blocks.3.fc1_smooth_shift', 'model.transformer.blocks.6.k_proj.bias', 'model.transformer.blocks.12.up_proj.bias', 'model.transformer.blocks.0.ori_layer.attn_out.weight', 'model.transformer.blocks.5.ori_layer.attn_out.weight', 'model.transformer.blocks.8.k_proj.bias', 'model.transformer.blocks.28.k_proj.bias', 'model.transformer.blocks.1.up_proj.bias', 'model.transformer.blocks.23.k_proj.bias', 'model.transformer.blocks.4.fc1_smooth_shift', 'model.transformer.blocks.10.ori_layer.ff_proj.weight', 'model.transformer.blocks.10.ori_layer.attn_out.weight', 'model.transformer.blocks.12.ff_norm.bias', 'model.transformer.blocks.23.up_proj.bias', 'model.transformer.blocks.3.ff_out.bias', 'model.transformer.blocks.13.ori_layer.q_proj.weight', 'model.transformer.blocks.24.up_proj.bias', 'model.transformer.blocks.11.attn_norm.bias', 'model.transformer.blocks.8.fc1_smooth_shift', 'model.transformer.blocks.3.out_smooth_shift', 'model.transformer.blocks.28.ori_layer.ff_norm.weight', 'model.transformer.blocks.3.ori_layer.ff_proj.weight', 'model.transformer.blocks.20.qkv_smooth_shift', 'model.transformer.blocks.6.q_proj.bias', 'model.transformer.blocks.31.k_proj.bias', 'model.transformer.blocks.31.ori_layer.ff_norm.weight', 'model.transformer.blocks.26.ori_layer.k_proj.weight', 'model.transformer.blocks.1.ori_layer.ff_out.weight', 'model.transformer.blocks.2.ori_layer.q_proj.weight', 'model.transformer.blocks.16.ff_proj.bias', 'model.transformer.blocks.17.ff_norm.bias', 'model.transformer.blocks.15.ori_layer.v_proj.weight', 'model.transformer.blocks.15.attn_out.bias', 'model.transformer.blocks.20.ori_layer.ff_norm.weight', 'model.transformer.blocks.10.down_smooth_shift', 'model.transformer.blocks.22.ff_norm.bias', 'model.transformer.blocks.23.attn_out.bias', 'model.transformer.blocks.21.fc1_smooth_shift', 'model.transformer.blocks.11.ori_layer.attn_out.weight', 'model.transformer.blocks.9.ori_layer.ff_norm.weight', 'model.transformer.blocks.18.attn_out.bias', 'model.transformer.blocks.4.v_proj.bias', 'model.transformer.blocks.9.q_proj.bias', 'model.transformer.blocks.3.ori_layer.v_proj.weight', 'model.transformer.blocks.10.ori_layer.k_proj.weight', 'model.transformer.blocks.7.ff_out.bias', 'model.transformer.blocks.16.ori_layer.attn_norm.weight', 'model.transformer.blocks.31.attn_norm.bias', 'model.transformer.blocks.29.ff_norm.bias', 'model.transformer.blocks.2.qkv_smooth_shift', 'model.transformer.blocks.8.ori_layer.ff_proj.weight', 'model.transformer.blocks.30.ori_layer.attn_out.weight', 'model.transformer.blocks.3.ori_layer.ff_norm.weight', 'model.transformer.blocks.15.q_proj.bias', 'model.transformer.blocks.14.fc1_smooth_shift', 'model.transformer.blocks.4.out_smooth_shift', 'model.transformer.blocks.14.ori_layer.attn_norm.weight', 'model.transformer.blocks.18.q_proj.bias', 'model.transformer.blocks.17.up_proj.bias', 'model.transformer.blocks.22.ori_layer.k_proj.weight', 'model.transformer.blocks.10.out_smooth_shift', 'model.transformer.blocks.12.ff_proj.bias', 'model.transformer.blocks.18.ori_layer.k_proj.weight', 'model.transformer.blocks.13.q_proj.bias', 'model.transformer.blocks.5.ff_out.bias', 'model.transformer.blocks.8.ff_out.bias', 'model.transformer.blocks.5.up_proj.bias', 'model.transformer.blocks.15.ff_out.bias', 'model.transformer.blocks.29.ori_layer.attn_norm.weight', 'model.transformer.blocks.5.q_proj.bias', 'model.transformer.blocks.7.q_proj.bias', 'model.transformer.blocks.2.ori_layer.up_proj.weight', 'model.transformer.blocks.28.ori_layer.ff_proj.weight', 'model.transformer.blocks.29.ori_layer.v_proj.weight', 'model.transformer.blocks.30.ff_proj.bias', 'model.transformer.blocks.19.k_proj.bias', 'model.transformer.blocks.14.ff_norm.bias', 'model.transformer.blocks.1.attn_out.bias', 'model.transformer.blocks.0.ori_layer.attn_norm.weight', 'model.transformer.blocks.26.qkv_smooth_shift', 'model.transformer.blocks.20.ori_layer.v_proj.weight', 'model.transformer.blocks.21.attn_norm.bias', 'model.transformer.blocks.25.ff_norm.bias', 'model.transformer.blocks.6.ff_out.bias', 'model.transformer.blocks.26.k_proj.bias', 'model.transformer.blocks.18.fc1_smooth_shift', 'model.transformer.blocks.2.ori_layer.ff_proj.weight', 'model.transformer.blocks.4.ori_layer.v_proj.weight', 'model.transformer.blocks.29.ori_layer.up_proj.weight', 'model.transformer.blocks.24.q_proj.bias', 'model.transformer.blocks.12.down_smooth_shift', 'model.transformer.blocks.26.ori_layer.ff_out.weight', 'model.transformer.blocks.9.attn_out.bias', 'model.transformer.blocks.26.v_proj.bias', 'model.transformer.blocks.7.ori_layer.up_proj.weight', 'model.transformer.blocks.18.qkv_smooth_shift', 'model.transformer.blocks.4.ori_layer.attn_norm.weight', 'model.transformer.blocks.7.ori_layer.attn_norm.weight', 'model.transformer.blocks.17.ori_layer.q_proj.weight', 'model.transformer.blocks.0.q_proj.bias', 'model.transformer.blocks.18.ori_layer.ff_proj.weight', 'model.transformer.blocks.11.k_proj.bias', 'model.transformer.blocks.13.ori_layer.k_proj.weight', 'model.transformer.blocks.6.v_proj.bias', 'model.transformer.blocks.1.v_proj.bias', 'model.transformer.blocks.6.down_smooth_shift', 'model.transformer.blocks.19.ff_out.bias', 'model.transformer.blocks.24.ff_out.bias', 'model.transformer.blocks.28.q_proj.bias', 'model.transformer.blocks.5.ori_layer.q_proj.weight', 'model.transformer.blocks.27.ori_layer.ff_proj.weight', 'model.transformer.blocks.11.ff_out.bias', 'model.transformer.blocks.13.v_proj.bias', 'model.transformer.blocks.11.out_smooth_shift', 'model.transformer.blocks.12.v_proj.bias', 'model.transformer.blocks.20.out_smooth_shift', 'model.transformer.blocks.12.ori_layer.k_proj.weight', 'model.transformer.blocks.25.ori_layer.v_proj.weight', 'model.transformer.blocks.11.ori_layer.ff_proj.weight', 'model.transformer.blocks.8.ori_layer.up_proj.weight', 'model.transformer.blocks.10.ori_layer.q_proj.weight', 'model.transformer.blocks.27.k_proj.bias', 'model.transformer.blocks.18.ori_layer.ff_out.weight', 'model.transformer.blocks.11.ori_layer.q_proj.weight', 'model.transformer.blocks.11.ori_layer.up_proj.weight', 'model.transformer.blocks.30.ori_layer.q_proj.weight', 'model.transformer.blocks.3.v_proj.bias', 'model.transformer.blocks.4.ori_layer.ff_out.weight', 'model.transformer.blocks.25.attn_out.bias', 'model.transformer.blocks.17.ff_out.bias', 'model.transformer.blocks.1.ori_layer.v_proj.weight', 'model.transformer.blocks.24.v_proj.bias', 'model.transformer.blocks.25.attn_norm.bias', 'model.transformer.blocks.25.ori_layer.ff_out.weight', 'model.transformer.blocks.6.ff_proj.bias', 'model.transformer.blocks.17.qkv_smooth_shift', 'model.transformer.blocks.5.ff_norm.bias', 'model.transformer.blocks.29.ori_layer.ff_proj.weight', 'model.transformer.blocks.29.v_proj.bias', 'model.transformer.blocks.20.q_proj.bias', 'model.transformer.blocks.10.attn_norm.bias', 'model.transformer.blocks.1.out_smooth_shift', 'model.transformer.blocks.27.out_smooth_shift', 'model.transformer.blocks.6.ori_layer.ff_proj.weight', 'model.transformer.blocks.1.fc1_smooth_shift', 'model.transformer.blocks.13.ori_layer.ff_out.weight', 'model.transformer.blocks.30.ori_layer.up_proj.weight', 'model.transformer.blocks.24.ff_norm.bias', 'model.transformer.blocks.15.ori_layer.ff_proj.weight', 'model.transformer.blocks.7.down_smooth_shift', 'model.transformer.blocks.17.v_proj.bias', 'model.transformer.blocks.11.qkv_smooth_shift', 'model.transformer.blocks.26.out_smooth_shift', 'model.transformer.blocks.20.ff_proj.bias', 'model.transformer.blocks.22.out_smooth_shift', 'model.transformer.blocks.12.q_proj.bias', 'model.transformer.blocks.26.fc1_smooth_shift', 'model.transformer.blocks.15.fc1_smooth_shift', 'model.transformer.blocks.25.ff_proj.bias', 'model.transformer.blocks.29.attn_out.bias', 'model.transformer.blocks.5.attn_norm.bias', 'model.transformer.blocks.15.attn_norm.bias', 'model.transformer.blocks.0.up_proj.bias', 'model.transformer.blocks.24.ori_layer.up_proj.weight', 'model.transformer.blocks.16.ori_layer.ff_out.weight', 'model.transformer.blocks.17.ori_layer.ff_out.weight', 'model.transformer.blocks.24.ori_layer.q_proj.weight', 'model.transformer.blocks.28.v_proj.bias', 'model.transformer.blocks.13.ori_layer.ff_norm.weight', 'model.transformer.blocks.7.ori_layer.k_proj.weight', 'model.transformer.blocks.11.ori_layer.v_proj.weight', 'model.transformer.blocks.5.ori_layer.ff_proj.weight', 'model.transformer.blocks.21.ori_layer.ff_norm.weight', 'model.transformer.blocks.8.out_smooth_shift', 'model.transformer.blocks.19.down_smooth_shift', 'model.transformer.blocks.18.ff_norm.bias', 'model.transformer.blocks.3.ori_layer.k_proj.weight', 'model.transformer.blocks.8.q_proj.bias', 'model.transformer.blocks.4.attn_out.bias', 'model.transformer.blocks.6.fc1_smooth_shift', 'model.transformer.blocks.14.up_proj.bias', 'model.transformer.blocks.14.ff_out.bias', 'model.transformer.blocks.0.ori_layer.ff_proj.weight', 'model.transformer.blocks.29.ori_layer.k_proj.weight', 'model.transformer.blocks.19.v_proj.bias', 'model.transformer.blocks.19.ori_layer.attn_out.weight', 'model.transformer.blocks.7.ori_layer.ff_proj.weight', 'model.transformer.blocks.9.ori_layer.attn_norm.weight', 'model.transformer.blocks.27.ff_proj.bias', 'model.transformer.blocks.11.fc1_smooth_shift', 'model.transformer.blocks.18.ff_out.bias', 'model.transformer.blocks.10.qkv_smooth_shift', 'model.transformer.blocks.8.ori_layer.q_proj.weight', 'model.transformer.blocks.25.ff_out.bias', 'model.transformer.blocks.25.ori_layer.q_proj.weight', 'model.transformer.blocks.6.attn_out.bias', 'model.transformer.blocks.1.ori_layer.up_proj.weight', 'model.transformer.blocks.6.ori_layer.attn_norm.weight', 'model.transformer.blocks.0.down_smooth_shift', 'model.transformer.blocks.0.ori_layer.ff_norm.weight', 'model.transformer.blocks.7.ori_layer.v_proj.weight', 'model.transformer.blocks.6.ori_layer.attn_out.weight', 'model.transformer.blocks.6.ff_norm.bias', 'model.transformer.blocks.27.ff_out.bias', 'model.transformer.blocks.25.out_smooth_shift', 'model.transformer.blocks.25.ori_layer.attn_out.weight', 'model.transformer.blocks.15.ori_layer.attn_norm.weight', 'model.transformer.blocks.24.k_proj.bias', 'model.transformer.blocks.13.ori_layer.up_proj.weight', 'model.transformer.blocks.8.ori_layer.k_proj.weight', 'model.transformer.blocks.14.ff_proj.bias', 'model.transformer.blocks.30.qkv_smooth_shift', 'model.transformer.blocks.23.ori_layer.q_proj.weight', 'model.transformer.blocks.2.attn_norm.bias', 'model.transformer.blocks.14.ori_layer.ff_proj.weight', 'model.transformer.blocks.0.k_proj.bias', 'model.transformer.blocks.2.down_smooth_shift', 'model.transformer.blocks.22.down_smooth_shift', 'model.transformer.blocks.24.ori_layer.attn_out.weight', 'model.transformer.blocks.16.ori_layer.k_proj.weight', 'model.transformer.blocks.13.ff_norm.bias', 'model.transformer.blocks.5.v_proj.bias', 'model.transformer.blocks.31.ori_layer.ff_proj.weight', 'model.transformer.blocks.26.ori_layer.ff_proj.weight', 'model.transformer.blocks.28.ori_layer.attn_norm.weight', 'model.transformer.blocks.0.qkv_smooth_shift', 'model.transformer.blocks.26.attn_norm.bias', 'model.transformer.blocks.14.k_proj.bias', 'model.transformer.blocks.30.ori_layer.ff_norm.weight', 'model.transformer.blocks.30.ori_layer.ff_proj.weight', 'model.transformer.blocks.18.ori_layer.attn_norm.weight', 'model.transformer.blocks.28.ori_layer.attn_out.weight', 'model.transformer.blocks.21.ori_layer.ff_out.weight', 'model.transformer.blocks.3.up_proj.bias', 'model.transformer.blocks.22.ori_layer.ff_proj.weight', 'model.transformer.blocks.19.out_smooth_shift', 'model.transformer.blocks.30.ff_out.bias', 'model.transformer.blocks.19.q_proj.bias', 'model.transformer.blocks.18.k_proj.bias', 'model.transformer.blocks.27.up_proj.bias', 'model.transformer.blocks.8.ori_layer.attn_out.weight', 'model.transformer.blocks.31.v_proj.bias', 'model.transformer.blocks.7.k_proj.bias', 'model.transformer.blocks.30.ori_layer.attn_norm.weight', 'model.transformer.blocks.1.q_proj.bias', 'model.transformer.blocks.13.ori_layer.attn_norm.weight', 'model.transformer.blocks.19.qkv_smooth_shift', 'model.transformer.blocks.31.ori_layer.v_proj.weight', 'model.transformer.blocks.4.ori_layer.q_proj.weight', 'model.transformer.blocks.13.ori_layer.ff_proj.weight', 'model.transformer.blocks.16.qkv_smooth_shift', 'model.transformer.blocks.20.ori_layer.up_proj.weight', 'model.transformer.blocks.28.ff_out.bias', 'model.transformer.blocks.2.up_proj.bias', 'model.transformer.blocks.19.ff_proj.bias', 'model.transformer.blocks.5.ori_layer.attn_norm.weight', 'model.transformer.blocks.16.ff_out.bias', 'model.transformer.blocks.2.fc1_smooth_shift', 'model.transformer.blocks.31.up_proj.bias', 'model.transformer.blocks.31.ff_out.bias', 'model.transformer.blocks.15.v_proj.bias', 'model.transformer.blocks.31.ori_layer.attn_norm.weight', 'model.transformer.blocks.22.attn_out.bias', 'model.transformer.blocks.16.out_smooth_shift', 'model.transformer.blocks.18.down_smooth_shift', 'model.transformer.blocks.5.ori_layer.k_proj.weight', 'model.transformer.blocks.2.ori_layer.ff_norm.weight', 'model.transformer.blocks.0.out_smooth_shift', 'model.transformer.blocks.26.ff_norm.bias', 'model.transformer.blocks.21.q_proj.bias', 'model.transformer.blocks.26.ori_layer.up_proj.weight', 'model.transformer.blocks.14.out_smooth_shift', 'model.transformer.blocks.27.ori_layer.up_proj.weight', 'model.transformer.blocks.26.q_proj.bias', 'model.transformer.blocks.3.ff_norm.bias', 'model.transformer.blocks.21.out_smooth_shift', 'model.transformer.blocks.24.ori_layer.v_proj.weight', 'model.transformer.blocks.24.attn_norm.bias', 'model.transformer.blocks.5.ori_layer.ff_out.weight', 'model.transformer.blocks.29.up_proj.bias', 'model.transformer.blocks.27.ori_layer.ff_out.weight', 'model.transformer.blocks.15.ff_norm.bias', 'model.transformer.blocks.23.fc1_smooth_shift', 'model.transformer.blocks.1.ff_out.bias', 'model.transformer.blocks.21.v_proj.bias', 'model.transformer.blocks.12.ff_out.bias', 'model.transformer.blocks.2.out_smooth_shift', 'model.transformer.blocks.29.k_proj.bias', 'model.transformer.blocks.15.k_proj.bias', 'model.transformer.blocks.20.fc1_smooth_shift', 'model.transformer.blocks.4.down_smooth_shift', 'model.transformer.blocks.24.ori_layer.attn_norm.weight', 'model.transformer.blocks.11.ori_layer.k_proj.weight', 'model.transformer.blocks.24.fc1_smooth_shift', 'model.transformer.blocks.30.ff_norm.bias', 'model.transformer.blocks.13.up_proj.bias', 'model.transformer.blocks.20.up_proj.bias', 'model.transformer.blocks.22.ori_layer.attn_norm.weight', 'model.transformer.blocks.16.ori_layer.up_proj.weight', 'model.transformer.blocks.16.ff_norm.bias', 'model.transformer.blocks.0.ori_layer.k_proj.weight', 'model.transformer.blocks.18.up_proj.bias', 'model.transformer.blocks.6.out_smooth_shift', 'model.transformer.blocks.9.k_proj.bias', 'model.transformer.blocks.17.down_smooth_shift', 'model.transformer.blocks.8.ori_layer.ff_norm.weight', 'model.transformer.blocks.6.up_proj.bias', 'model.transformer.blocks.29.ff_proj.bias', 'model.transformer.blocks.5.qkv_smooth_shift', 'model.transformer.blocks.13.out_smooth_shift', 'model.transformer.blocks.4.ff_proj.bias', 'model.transformer.blocks.18.ori_layer.v_proj.weight', 'model.transformer.blocks.10.ori_layer.ff_norm.weight', 'model.transformer.blocks.18.ori_layer.attn_out.weight', 'model.transformer.blocks.5.ori_layer.up_proj.weight', 'model.transformer.blocks.7.ori_layer.attn_out.weight', 'model.transformer.blocks.13.ff_proj.bias', 'model.transformer.blocks.17.fc1_smooth_shift', 'model.transformer.blocks.3.q_proj.bias', 'model.transformer.blocks.19.ori_layer.ff_out.weight', 'model.transformer.blocks.7.ori_layer.q_proj.weight', 'model.transformer.blocks.12.ori_layer.v_proj.weight', 'model.transformer.blocks.11.ff_proj.bias', 'model.transformer.blocks.29.out_smooth_shift', 'model.transformer.blocks.21.ori_layer.q_proj.weight', 'model.transformer.blocks.17.ori_layer.attn_out.weight', 'model.transformer.blocks.29.down_smooth_shift', 'model.transformer.blocks.29.ori_layer.ff_norm.weight', 'model.transformer.blocks.23.q_proj.bias', 'model.transformer.blocks.30.fc1_smooth_shift', 'model.transformer.blocks.22.up_proj.bias', 'model.transformer.blocks.25.qkv_smooth_shift', 'model.transformer.blocks.20.attn_norm.bias', 'model.transformer.blocks.16.k_proj.bias', 'model.transformer.blocks.23.ori_layer.attn_norm.weight', 'model.transformer.blocks.27.ori_layer.attn_out.weight', 'model.transformer.blocks.3.attn_out.bias', 'model.transformer.blocks.23.ori_layer.ff_norm.weight', 'model.transformer.blocks.29.qkv_smooth_shift', 'model.transformer.blocks.11.attn_out.bias', 'model.transformer.blocks.4.q_proj.bias', 'model.transformer.blocks.27.ori_layer.ff_norm.weight', 'model.transformer.blocks.23.ori_layer.ff_proj.weight', 'model.transformer.blocks.19.ori_layer.q_proj.weight', 'model.transformer.blocks.15.ori_layer.k_proj.weight', 'model.transformer.blocks.23.ff_out.bias', 'model.transformer.blocks.26.attn_out.bias', 'model.transformer.blocks.4.up_proj.bias', 'model.transformer.blocks.0.attn_norm.bias', 'model.transformer.blocks.10.ori_layer.attn_norm.weight', 'model.transformer.blocks.17.q_proj.bias', 'model.transformer.blocks.5.ori_layer.ff_norm.weight', 'model.transformer.blocks.1.ff_norm.bias', 'model.transformer.blocks.8.v_proj.bias', 'model.transformer.blocks.12.out_smooth_shift', 'model.transformer.blocks.24.ori_layer.ff_norm.weight', 'model.transformer.blocks.29.attn_norm.bias', 'model.transformer.blocks.31.ori_layer.ff_out.weight', 'model.transformer.blocks.18.ori_layer.q_proj.weight', 'model.transformer.blocks.30.q_proj.bias', 'model.transformer.blocks.25.q_proj.bias', 'model.transformer.blocks.22.ori_layer.ff_norm.weight', 'model.transformer.blocks.12.ori_layer.ff_proj.weight', 'model.transformer.blocks.16.ori_layer.q_proj.weight', 'model.transformer.blocks.27.ori_layer.q_proj.weight', 'model.transformer.blocks.28.ori_layer.ff_out.weight', 'model.transformer.blocks.22.k_proj.bias', 'model.transformer.blocks.26.ori_layer.attn_out.weight', 'model.transformer.blocks.13.fc1_smooth_shift', 'model.transformer.blocks.4.ori_layer.k_proj.weight', 'model.transformer.blocks.8.ori_layer.ff_out.weight', 'model.transformer.blocks.27.q_proj.bias', 'model.transformer.blocks.3.ff_proj.bias', 'model.transformer.blocks.25.ori_layer.up_proj.weight', 'model.transformer.blocks.16.ori_layer.ff_norm.weight', 'model.transformer.blocks.12.attn_norm.bias', 'model.transformer.blocks.19.attn_out.bias', 'model.transformer.blocks.11.v_proj.bias', 'model.transformer.blocks.1.ori_layer.ff_proj.weight', 'model.transformer.blocks.20.ori_layer.k_proj.weight', 'model.transformer.blocks.6.ori_layer.q_proj.weight', 'model.transformer.blocks.31.fc1_smooth_shift', 'model.transformer.blocks.26.ori_layer.attn_norm.weight', 'model.transformer.blocks.17.ori_layer.ff_proj.weight', 'model.transformer.blocks.1.k_proj.bias', 'model.transformer.blocks.31.qkv_smooth_shift', 'model.transformer.blocks.24.down_smooth_shift', 'model.transformer.blocks.3.ori_layer.ff_out.weight', 'model.transformer.blocks.16.ori_layer.attn_out.weight', 'model.transformer.blocks.6.ori_layer.up_proj.weight', 'model.transformer.blocks.2.v_proj.bias', 'model.transformer.blocks.9.ori_layer.ff_out.weight', 'model.transformer.blocks.9.out_smooth_shift', 'model.transformer.blocks.17.attn_out.bias', 'model.transformer.blocks.4.ff_norm.bias', 'model.transformer.blocks.24.ori_layer.k_proj.weight', 'model.transformer.blocks.18.ori_layer.up_proj.weight', 'model.transformer.blocks.31.attn_out.bias', 'model.transformer.blocks.13.k_proj.bias', 'model.transformer.blocks.24.ori_layer.ff_out.weight', 'model.transformer.blocks.1.down_smooth_shift', 'model.transformer.blocks.21.ori_layer.attn_out.weight', 'model.transformer.blocks.30.attn_out.bias', 'model.transformer.blocks.27.ff_norm.bias', 'model.transformer.blocks.28.qkv_smooth_shift', 'model.transformer.blocks.11.up_proj.bias', 'model.transformer.blocks.31.ori_layer.attn_out.weight', 'model.transformer.blocks.31.down_smooth_shift', 'model.transformer.blocks.25.down_smooth_shift', 'model.transformer.blocks.12.ori_layer.ff_norm.weight', 'model.transformer.blocks.2.attn_out.bias', 'model.transformer.blocks.14.ori_layer.k_proj.weight', 'model.transformer.blocks.20.down_smooth_shift', 'model.transformer.blocks.8.ori_layer.v_proj.weight', 'model.transformer.blocks.18.attn_norm.bias', 'model.transformer.blocks.12.ori_layer.up_proj.weight', 'model.transformer.blocks.15.ori_layer.up_proj.weight', 'model.transformer.blocks.27.attn_out.bias', 'model.transformer.blocks.31.ff_norm.bias', 'model.transformer.blocks.5.ff_proj.bias', 'model.transformer.blocks.22.ori_layer.q_proj.weight', 'model.transformer.blocks.9.attn_norm.bias', 'model.transformer.blocks.5.fc1_smooth_shift', 'model.transformer.blocks.17.attn_norm.bias', 'model.transformer.blocks.15.ori_layer.ff_norm.weight', 'model.transformer.blocks.17.ori_layer.ff_norm.weight', 'model.transformer.blocks.30.down_smooth_shift', 'model.transformer.blocks.28.ff_proj.bias', 'model.transformer.blocks.21.qkv_smooth_shift', 'model.transformer.blocks.30.up_proj.bias', 'model.transformer.blocks.8.ff_proj.bias', 'model.transformer.blocks.13.ori_layer.attn_out.weight', 'model.transformer.blocks.9.ori_layer.q_proj.weight', 'model.transformer.blocks.21.k_proj.bias', 'model.transformer.blocks.29.ori_layer.attn_out.weight', 'model.transformer.blocks.18.ff_proj.bias', 'model.transformer.blocks.14.ori_layer.v_proj.weight', 'model.transformer.blocks.29.ori_layer.q_proj.weight', 'model.transformer.blocks.7.fc1_smooth_shift', 'model.transformer.blocks.9.v_proj.bias', 'model.transformer.blocks.23.attn_norm.bias', 'model.transformer.blocks.2.ori_layer.ff_out.weight', 'model.transformer.blocks.22.ff_proj.bias', 'model.transformer.blocks.14.q_proj.bias', 'model.transformer.blocks.9.ff_out.bias', 'model.transformer.blocks.9.ori_layer.attn_out.weight', 'model.transformer.blocks.9.qkv_smooth_shift', 'model.transformer.blocks.17.ori_layer.v_proj.weight', 'model.transformer.blocks.8.down_smooth_shift', 'model.transformer.blocks.19.ori_layer.k_proj.weight', 'model.transformer.blocks.1.ori_layer.attn_out.weight', 'model.transformer.blocks.3.ori_layer.attn_norm.weight', 'model.transformer.blocks.23.qkv_smooth_shift', 'model.transformer.blocks.27.fc1_smooth_shift', 'model.transformer.blocks.18.ori_layer.ff_norm.weight', 'model.transformer.blocks.30.k_proj.bias', 'model.transformer.blocks.20.ori_layer.ff_out.weight', 'model.transformer.blocks.15.ori_layer.q_proj.weight', 'model.transformer.blocks.28.ori_layer.v_proj.weight', 'model.transformer.blocks.21.ff_proj.bias', 'model.transformer.blocks.31.ff_proj.bias', 'model.transformer.blocks.16.ori_layer.ff_proj.weight', 'model.transformer.blocks.12.ori_layer.q_proj.weight', 'model.transformer.blocks.23.ori_layer.attn_out.weight', 'model.transformer.blocks.23.ori_layer.k_proj.weight', 'model.transformer.blocks.21.attn_out.bias', 'model.transformer.blocks.26.ori_layer.v_proj.weight', 'model.transformer.blocks.10.q_proj.bias', 'model.transformer.blocks.7.v_proj.bias', 'model.transformer.blocks.16.q_proj.bias', 'model.transformer.blocks.26.ff_out.bias', 'model.transformer.blocks.21.ori_layer.k_proj.weight', 'model.transformer.blocks.22.attn_norm.bias', 'model.transformer.blocks.30.ori_layer.k_proj.weight', 'model.transformer.blocks.16.fc1_smooth_shift', 'model.transformer.blocks.20.ff_norm.bias', 'model.transformer.blocks.24.qkv_smooth_shift', 'model.transformer.blocks.10.ff_norm.bias', 'model.transformer.blocks.1.ori_layer.k_proj.weight', 'model.transformer.blocks.3.ori_layer.up_proj.weight', 'model.transformer.blocks.15.qkv_smooth_shift', 'model.transformer.blocks.19.ori_layer.up_proj.weight', 'model.transformer.blocks.31.ori_layer.up_proj.weight', 'model.transformer.blocks.9.down_smooth_shift', 'model.transformer.blocks.27.qkv_smooth_shift', 'model.transformer.blocks.29.fc1_smooth_shift', 'model.transformer.blocks.14.qkv_smooth_shift', 'model.transformer.blocks.7.ori_layer.ff_norm.weight', 'model.transformer.blocks.8.qkv_smooth_shift', 'model.transformer.blocks.27.ori_layer.k_proj.weight', 'model.transformer.blocks.18.v_proj.bias', 'model.transformer.blocks.2.ori_layer.attn_norm.weight', 'model.transformer.blocks.26.up_proj.bias', 'model.transformer.blocks.0.ori_layer.ff_out.weight', 'model.transformer.blocks.3.k_proj.bias', 'model.transformer.blocks.1.ori_layer.attn_norm.weight', 'model.transformer.blocks.0.ori_layer.up_proj.weight', 'model.transformer.blocks.0.ori_layer.v_proj.weight', 'model.transformer.blocks.17.k_proj.bias', 'model.transformer.blocks.22.ori_layer.up_proj.weight', 'model.transformer.blocks.1.ff_proj.bias', 'model.transformer.blocks.9.ff_norm.bias', 'model.transformer.blocks.16.up_proj.bias', 'model.transformer.blocks.14.ori_layer.ff_out.weight', 'model.transformer.blocks.15.ff_proj.bias', 'model.transformer.blocks.20.v_proj.bias', 'model.transformer.blocks.7.ori_layer.ff_out.weight', 'model.transformer.blocks.24.ff_proj.bias', 'model.transformer.blocks.25.ori_layer.attn_norm.weight', 'model.transformer.blocks.7.qkv_smooth_shift', 'model.transformer.blocks.7.out_smooth_shift', 'model.transformer.blocks.4.k_proj.bias', 'model.transformer.blocks.2.k_proj.bias', 'model.transformer.blocks.21.up_proj.bias', 'model.transformer.blocks.28.out_smooth_shift', 'model.transformer.blocks.27.ori_layer.v_proj.weight', 'model.transformer.blocks.7.ff_norm.bias', 'model.transformer.blocks.0.ff_norm.bias', 'model.transformer.blocks.10.attn_out.bias', 'model.transformer.blocks.14.attn_out.bias', 'model.transformer.blocks.21.ff_norm.bias', 'model.transformer.blocks.10.k_proj.bias', 'model.transformer.blocks.0.attn_out.bias', 'model.transformer.blocks.11.ff_norm.bias', 'model.transformer.blocks.13.attn_out.bias', 'model.transformer.blocks.20.attn_out.bias', 'model.transformer.blocks.26.ff_proj.bias', 'model.transformer.blocks.30.v_proj.bias', 'model.transformer.blocks.27.v_proj.bias', 'model.transformer.blocks.17.ff_proj.bias', 'model.transformer.blocks.5.k_proj.bias', 'model.transformer.blocks.26.ori_layer.ff_norm.weight', 'model.transformer.blocks.10.ff_out.bias', 'model.transformer.blocks.3.down_smooth_shift', 'model.transformer.blocks.25.ori_layer.ff_norm.weight', 'model.transformer.blocks.22.v_proj.bias', 'model.transformer.blocks.25.ori_layer.ff_proj.weight', 'model.transformer.blocks.19.ori_layer.ff_norm.weight', 'model.transformer.blocks.11.q_proj.bias', 'model.transformer.blocks.2.ff_out.bias', 'model.transformer.blocks.21.ori_layer.attn_norm.weight', 'model.transformer.blocks.11.down_smooth_shift', 'model.transformer.blocks.13.down_smooth_shift', 'model.transformer.blocks.16.down_smooth_shift', 'model.transformer.blocks.0.ori_layer.q_proj.weight', 'model.transformer.blocks.10.v_proj.bias', 'model.transformer.blocks.11.ori_layer.attn_norm.weight', 'model.transformer.blocks.19.attn_norm.bias', 'model.transformer.blocks.22.ori_layer.v_proj.weight', 'model.transformer.blocks.23.ori_layer.ff_out.weight', 'model.transformer.blocks.14.ori_layer.up_proj.weight', 'model.transformer.blocks.23.ori_layer.up_proj.weight', 'model.transformer.blocks.1.attn_norm.bias', 'model.transformer.blocks.16.v_proj.bias', 'model.transformer.blocks.22.fc1_smooth_shift', 'model.transformer.blocks.28.attn_out.bias', 'model.transformer.blocks.27.ori_layer.attn_norm.weight', 'model.transformer.blocks.15.out_smooth_shift', 'model.transformer.blocks.21.ff_out.bias', 'model.transformer.blocks.7.attn_norm.bias', 'model.transformer.blocks.10.ori_layer.v_proj.weight', 'model.transformer.blocks.16.ori_layer.v_proj.weight', 'model.transformer.blocks.9.ori_layer.k_proj.weight', 'model.transformer.blocks.20.ori_layer.attn_norm.weight', 'model.transformer.blocks.4.ori_layer.up_proj.weight', 'model.transformer.blocks.4.attn_norm.bias', 'model.transformer.blocks.5.ori_layer.v_proj.weight', 'model.transformer.blocks.1.ori_layer.ff_norm.weight', 'model.transformer.blocks.23.v_proj.bias', 'model.transformer.blocks.29.ff_out.bias', 'model.transformer.blocks.2.ff_proj.bias', 'model.transformer.blocks.7.up_proj.bias', 'model.transformer.blocks.17.ori_layer.up_proj.weight', 'model.transformer.blocks.7.ff_proj.bias', 'model.transformer.blocks.6.ori_layer.v_proj.weight', 'model.transformer.blocks.2.ori_layer.v_proj.weight', 'model.transformer.blocks.30.out_smooth_shift', 'model.transformer.blocks.5.out_smooth_shift', 'model.transformer.blocks.18.out_smooth_shift', 'model.transformer.blocks.10.ori_layer.up_proj.weight', 'model.transformer.blocks.21.ori_layer.ff_proj.weight', 'model.transformer.blocks.24.out_smooth_shift', 'model.transformer.blocks.19.ori_layer.ff_proj.weight', 'model.transformer.blocks.21.ori_layer.v_proj.weight', 'model.transformer.blocks.12.k_proj.bias', 'model.transformer.blocks.25.up_proj.bias', 'model.transformer.blocks.13.qkv_smooth_shift', 'model.transformer.blocks.4.ori_layer.ff_norm.weight', 'model.transformer.blocks.16.attn_norm.bias', 'model.transformer.blocks.9.up_proj.bias', 'model.transformer.blocks.9.ori_layer.ff_proj.weight', 'model.transformer.blocks.22.ori_layer.ff_out.weight', 'model.transformer.blocks.30.ori_layer.ff_out.weight', 'model.transformer.blocks.25.k_proj.bias', 'model.transformer.blocks.24.attn_out.bias', 'model.transformer.blocks.11.ori_layer.ff_norm.weight', 'model.transformer.blocks.14.ori_layer.attn_out.weight', 'model.transformer.blocks.6.ori_layer.ff_norm.weight', 'model.transformer.blocks.25.fc1_smooth_shift', 'model.transformer.blocks.20.k_proj.bias', 'model.transformer.blocks.4.ori_layer.ff_proj.weight', 'model.transformer.blocks.28.ori_layer.k_proj.weight', 'model.transformer.blocks.12.ori_layer.attn_norm.weight', 'model.transformer.blocks.10.ff_proj.bias', 'model.transformer.blocks.29.q_proj.bias', 'model.transformer.blocks.15.ori_layer.attn_out.weight', 'model.transformer.blocks.3.qkv_smooth_shift', 'model.transformer.blocks.23.out_smooth_shift', 'model.transformer.blocks.19.fc1_smooth_shift', 'model.transformer.blocks.25.v_proj.bias', 'model.transformer.blocks.2.ori_layer.attn_out.weight', 'model.transformer.blocks.12.qkv_smooth_shift', 'model.transformer.blocks.24.ori_layer.ff_proj.weight', 'model.transformer.blocks.8.ori_layer.attn_norm.weight', 'model.transformer.blocks.13.attn_norm.bias', 'model.transformer.blocks.27.down_smooth_shift', 'model.transformer.blocks.15.ori_layer.ff_out.weight', 'model.transformer.blocks.20.ff_out.bias', 'model.transformer.blocks.4.ori_layer.attn_out.weight', 'model.transformer.blocks.6.qkv_smooth_shift', 'model.transformer.blocks.10.up_proj.bias', 'model.transformer.blocks.0.ff_out.bias'}\n",
      "Layer Name                                    | MSE        | Cos Sim    | Max Diff  \n",
      "-------------------------------------------------------------------------------------\n",
      "model.transformer.blocks.15.ff_out.weight_quantizer.permutation_list | 25632394.0000 | 0.7453     | 12216.0000\n",
      "model.transformer.blocks.15.ff_out.act_quantizer.permutation_list | 25632394.0000 | 0.7453     | 12216.0000\n",
      "model.transformer.blocks.13.ff_out.weight_quantizer.permutation_list | 25630362.0000 | 0.7454     | 12007.0000\n",
      "model.transformer.blocks.13.ff_out.act_quantizer.permutation_list | 25630362.0000 | 0.7454     | 12007.0000\n",
      "model.transformer.blocks.16.ff_out.weight_quantizer.permutation_list | 25566310.0000 | 0.7460     | 12175.0000\n",
      "model.transformer.blocks.16.ff_out.act_quantizer.permutation_list | 25566310.0000 | 0.7460     | 12175.0000\n",
      "model.transformer.blocks.21.ff_out.act_quantizer.permutation_list | 25545954.0000 | 0.7462     | 12261.0000\n",
      "model.transformer.blocks.21.ff_out.weight_quantizer.permutation_list | 25545954.0000 | 0.7462     | 12261.0000\n",
      "model.transformer.blocks.18.ff_out.act_quantizer.permutation_list | 25455280.0000 | 0.7471     | 12234.0000\n",
      "model.transformer.blocks.18.ff_out.weight_quantizer.permutation_list | 25455280.0000 | 0.7471     | 12234.0000\n",
      "model.transformer.blocks.17.ff_out.weight_quantizer.permutation_list | 25454048.0000 | 0.7471     | 12170.0000\n",
      "model.transformer.blocks.17.ff_out.act_quantizer.permutation_list | 25454048.0000 | 0.7471     | 12170.0000\n",
      "model.transformer.blocks.7.ff_out.weight_quantizer.permutation_list | 25443630.0000 | 0.7472     | 12236.0000\n",
      "model.transformer.blocks.7.ff_out.act_quantizer.permutation_list | 25443630.0000 | 0.7472     | 12236.0000\n",
      "model.transformer.blocks.19.ff_out.weight_quantizer.permutation_list | 25435408.0000 | 0.7473     | 12130.0000\n",
      "model.transformer.blocks.19.ff_out.act_quantizer.permutation_list | 25435408.0000 | 0.7473     | 12130.0000\n",
      "model.transformer.blocks.29.ff_out.act_quantizer.permutation_list | 25384104.0000 | 0.7478     | 12230.0000\n",
      "model.transformer.blocks.29.ff_out.weight_quantizer.permutation_list | 25384104.0000 | 0.7478     | 12230.0000\n",
      "model.transformer.blocks.20.ff_out.act_quantizer.permutation_list | 25383720.0000 | 0.7478     | 12178.0000\n",
      "model.transformer.blocks.20.ff_out.weight_quantizer.permutation_list | 25383720.0000 | 0.7478     | 12178.0000\n",
      "model.transformer.blocks.4.ff_out.weight_quantizer.permutation_list | 25340774.0000 | 0.7482     | 12102.0000\n",
      "model.transformer.blocks.4.ff_out.act_quantizer.permutation_list | 25340774.0000 | 0.7482     | 12102.0000\n",
      "model.transformer.blocks.11.ff_out.weight_quantizer.permutation_list | 25290694.0000 | 0.7487     | 12214.0000\n",
      "model.transformer.blocks.11.ff_out.act_quantizer.permutation_list | 25290694.0000 | 0.7487     | 12214.0000\n",
      "model.transformer.blocks.26.ff_out.act_quantizer.permutation_list | 25279040.0000 | 0.7488     | 12201.0000\n",
      "model.transformer.blocks.26.ff_out.weight_quantizer.permutation_list | 25279040.0000 | 0.7488     | 12201.0000\n",
      "model.transformer.blocks.12.ff_out.weight_quantizer.permutation_list | 25247456.0000 | 0.7492     | 12241.0000\n",
      "model.transformer.blocks.12.ff_out.act_quantizer.permutation_list | 25247456.0000 | 0.7492     | 12241.0000\n",
      "model.transformer.blocks.9.ff_out.act_quantizer.permutation_list | 25224346.0000 | 0.7494     | 12148.0000\n",
      "model.transformer.blocks.9.ff_out.weight_quantizer.permutation_list | 25224346.0000 | 0.7494     | 12148.0000\n",
      "model.transformer.blocks.30.ff_out.weight_quantizer.permutation_list | 25148104.0000 | 0.7501     | 12151.0000\n",
      "model.transformer.blocks.30.ff_out.act_quantizer.permutation_list | 25148104.0000 | 0.7501     | 12151.0000\n",
      "model.transformer.blocks.10.ff_out.act_quantizer.permutation_list | 25126936.0000 | 0.7504     | 12221.0000\n",
      "model.transformer.blocks.10.ff_out.weight_quantizer.permutation_list | 25126936.0000 | 0.7504     | 12221.0000\n",
      "model.transformer.blocks.25.ff_out.weight_quantizer.permutation_list | 25118954.0000 | 0.7504     | 12137.0000\n",
      "model.transformer.blocks.25.ff_out.act_quantizer.permutation_list | 25118954.0000 | 0.7504     | 12137.0000\n",
      "model.transformer.blocks.22.ff_out.weight_quantizer.permutation_list | 25113904.0000 | 0.7505     | 12116.0000\n",
      "model.transformer.blocks.22.ff_out.act_quantizer.permutation_list | 25113904.0000 | 0.7505     | 12116.0000\n",
      "model.transformer.blocks.28.ff_out.weight_quantizer.permutation_list | 25095722.0000 | 0.7507     | 12196.0000\n",
      "model.transformer.blocks.28.ff_out.act_quantizer.permutation_list | 25095722.0000 | 0.7507     | 12196.0000\n",
      "model.transformer.blocks.1.ff_out.weight_quantizer.permutation_list | 25076886.0000 | 0.7509     | 12141.0000\n",
      "model.transformer.blocks.1.ff_out.act_quantizer.permutation_list | 25076886.0000 | 0.7509     | 12141.0000\n",
      "model.transformer.blocks.6.ff_out.weight_quantizer.permutation_list | 25021630.0000 | 0.7514     | 12093.0000\n",
      "model.transformer.blocks.6.ff_out.act_quantizer.permutation_list | 25021630.0000 | 0.7514     | 12093.0000\n",
      "model.transformer.blocks.23.ff_out.weight_quantizer.permutation_list | 25004590.0000 | 0.7516     | 12154.0000\n",
      "model.transformer.blocks.23.ff_out.act_quantizer.permutation_list | 25004590.0000 | 0.7516     | 12154.0000\n",
      "model.transformer.blocks.31.ff_out.act_quantizer.permutation_list | 24973074.0000 | 0.7519     | 12243.0000\n",
      "model.transformer.blocks.31.ff_out.weight_quantizer.permutation_list | 24973074.0000 | 0.7519     | 12243.0000\n",
      "model.transformer.blocks.0.ff_out.weight_quantizer.permutation_list | 24965738.0000 | 0.7520     | 12268.0000\n",
      "model.transformer.blocks.0.ff_out.act_quantizer.permutation_list | 24965738.0000 | 0.7520     | 12268.0000\n",
      "model.transformer.blocks.8.ff_out.act_quantizer.permutation_list | 24960736.0000 | 0.7520     | 12259.0000\n",
      "model.transformer.blocks.8.ff_out.weight_quantizer.permutation_list | 24960736.0000 | 0.7520     | 12259.0000\n",
      "model.transformer.blocks.2.ff_out.act_quantizer.permutation_list | 24957438.0000 | 0.7520     | 12204.0000\n",
      "model.transformer.blocks.2.ff_out.weight_quantizer.permutation_list | 24957438.0000 | 0.7520     | 12204.0000\n",
      "model.transformer.blocks.14.ff_out.act_quantizer.permutation_list | 24906606.0000 | 0.7525     | 12235.0000\n",
      "model.transformer.blocks.14.ff_out.weight_quantizer.permutation_list | 24906606.0000 | 0.7525     | 12235.0000\n",
      "model.transformer.blocks.27.ff_out.act_quantizer.permutation_list | 24894310.0000 | 0.7527     | 12086.0000\n",
      "model.transformer.blocks.27.ff_out.weight_quantizer.permutation_list | 24894310.0000 | 0.7527     | 12086.0000\n",
      "model.transformer.blocks.3.ff_out.weight_quantizer.permutation_list | 24868274.0000 | 0.7529     | 12242.0000\n",
      "model.transformer.blocks.3.ff_out.act_quantizer.permutation_list | 24868274.0000 | 0.7529     | 12242.0000\n",
      "model.transformer.blocks.5.ff_out.act_quantizer.permutation_list | 24857096.0000 | 0.7530     | 12106.0000\n",
      "model.transformer.blocks.5.ff_out.weight_quantizer.permutation_list | 24857096.0000 | 0.7530     | 12106.0000\n",
      "model.transformer.blocks.24.ff_out.weight_quantizer.permutation_list | 24549198.0000 | 0.7561     | 11968.0000\n",
      "model.transformer.blocks.24.ff_out.act_quantizer.permutation_list | 24549198.0000 | 0.7561     | 11968.0000\n",
      "model.transformer.blocks.15.q_proj.weight_quantizer.permutation_list | 2927243.5000 | 0.7382     | 4043.0000 \n",
      "model.transformer.blocks.15.q_proj.act_quantizer.permutation_list | 2927243.5000 | 0.7382     | 4043.0000 \n",
      "model.transformer.blocks.15.v_proj.weight_quantizer.permutation_list | 2927243.5000 | 0.7382     | 4043.0000 \n",
      "model.transformer.blocks.15.k_proj.act_quantizer.permutation_list | 2927243.5000 | 0.7382     | 4043.0000 \n",
      "model.transformer.blocks.15.v_proj.act_quantizer.permutation_list | 2927243.5000 | 0.7382     | 4043.0000 \n",
      "model.transformer.blocks.15.k_proj.weight_quantizer.permutation_list | 2927243.5000 | 0.7382     | 4043.0000 \n",
      "model.transformer.blocks.1.k_proj.act_quantizer.permutation_list | 2908591.0000 | 0.7399     | 4043.0000 \n",
      "model.transformer.blocks.1.q_proj.act_quantizer.permutation_list | 2908591.0000 | 0.7399     | 4043.0000 \n",
      "model.transformer.blocks.1.k_proj.weight_quantizer.permutation_list | 2908591.0000 | 0.7399     | 4043.0000 \n",
      "model.transformer.blocks.1.v_proj.weight_quantizer.permutation_list | 2908591.0000 | 0.7399     | 4043.0000 \n",
      "model.transformer.blocks.1.v_proj.act_quantizer.permutation_list | 2908591.0000 | 0.7399     | 4043.0000 \n",
      "model.transformer.blocks.1.q_proj.weight_quantizer.permutation_list | 2908591.0000 | 0.7399     | 4043.0000 \n",
      "model.transformer.blocks.2.up_proj.weight_quantizer.permutation_list | 2897400.0000 | 0.7409     | 4086.0000 \n",
      "model.transformer.blocks.2.up_proj.act_quantizer.permutation_list | 2897400.0000 | 0.7409     | 4086.0000 \n",
      "model.transformer.blocks.2.ff_proj.act_quantizer.permutation_list | 2897400.0000 | 0.7409     | 4086.0000 \n",
      "model.transformer.blocks.2.ff_proj.weight_quantizer.permutation_list | 2897400.0000 | 0.7409     | 4086.0000 \n",
      "model.transformer.blocks.28.v_proj.act_quantizer.permutation_list | 2887829.0000 | 0.7417     | 4039.0000 \n",
      "model.transformer.blocks.28.q_proj.weight_quantizer.permutation_list | 2887829.0000 | 0.7417     | 4039.0000 \n",
      "model.transformer.blocks.28.v_proj.weight_quantizer.permutation_list | 2887829.0000 | 0.7417     | 4039.0000 \n",
      "model.transformer.blocks.28.k_proj.act_quantizer.permutation_list | 2887829.0000 | 0.7417     | 4039.0000 \n",
      "model.transformer.blocks.28.q_proj.act_quantizer.permutation_list | 2887829.0000 | 0.7417     | 4039.0000 \n",
      "model.transformer.blocks.28.k_proj.weight_quantizer.permutation_list | 2887829.0000 | 0.7417     | 4039.0000 \n",
      "model.transformer.blocks.0.up_proj.weight_quantizer.permutation_list | 2882175.0000 | 0.7422     | 4009.0000 \n",
      "model.transformer.blocks.0.up_proj.act_quantizer.permutation_list | 2882175.0000 | 0.7422     | 4009.0000 \n",
      "model.transformer.blocks.0.ff_proj.weight_quantizer.permutation_list | 2882175.0000 | 0.7422     | 4009.0000 \n",
      "model.transformer.blocks.0.ff_proj.act_quantizer.permutation_list | 2882175.0000 | 0.7422     | 4009.0000 \n",
      "model.transformer.blocks.11.attn_out.act_quantizer.permutation_list | 2869332.5000 | 0.7434     | 4016.0000 \n",
      "model.transformer.blocks.11.attn_out.weight_quantizer.permutation_list | 2869332.5000 | 0.7434     | 4016.0000 \n",
      "model.transformer.blocks.26.q_proj.act_quantizer.permutation_list | 2862026.5000 | 0.7440     | 4003.0000 \n",
      "model.transformer.blocks.26.v_proj.act_quantizer.permutation_list | 2862026.5000 | 0.7440     | 4003.0000 \n",
      "model.transformer.blocks.26.k_proj.weight_quantizer.permutation_list | 2862026.5000 | 0.7440     | 4003.0000 \n",
      "model.transformer.blocks.26.v_proj.weight_quantizer.permutation_list | 2862026.5000 | 0.7440     | 4003.0000 \n",
      "model.transformer.blocks.26.k_proj.act_quantizer.permutation_list | 2862026.5000 | 0.7440     | 4003.0000 \n",
      "model.transformer.blocks.26.q_proj.weight_quantizer.permutation_list | 2862026.5000 | 0.7440     | 4003.0000 \n",
      "model.transformer.blocks.24.q_proj.weight_quantizer.permutation_list | 2860703.7500 | 0.7441     | 4039.0000 \n",
      "model.transformer.blocks.24.q_proj.act_quantizer.permutation_list | 2860703.7500 | 0.7441     | 4039.0000 \n",
      "model.transformer.blocks.24.v_proj.weight_quantizer.permutation_list | 2860703.7500 | 0.7441     | 4039.0000 \n",
      "model.transformer.blocks.24.k_proj.weight_quantizer.permutation_list | 2860703.7500 | 0.7441     | 4039.0000 \n",
      "model.transformer.blocks.24.k_proj.act_quantizer.permutation_list | 2860703.7500 | 0.7441     | 4039.0000 \n",
      "model.transformer.blocks.24.v_proj.act_quantizer.permutation_list | 2860703.7500 | 0.7441     | 4039.0000 \n",
      "model.transformer.blocks.28.ff_proj.act_quantizer.permutation_list | 2859098.5000 | 0.7443     | 4067.0000 \n",
      "model.transformer.blocks.28.up_proj.act_quantizer.permutation_list | 2859098.5000 | 0.7443     | 4067.0000 \n",
      "model.transformer.blocks.28.ff_proj.weight_quantizer.permutation_list | 2859098.5000 | 0.7443     | 4067.0000 \n",
      "model.transformer.blocks.28.up_proj.weight_quantizer.permutation_list | 2859098.5000 | 0.7443     | 4067.0000 \n",
      "model.transformer.blocks.25.q_proj.weight_quantizer.permutation_list | 2851048.5000 | 0.7450     | 4083.0000 \n",
      "model.transformer.blocks.25.v_proj.weight_quantizer.permutation_list | 2851048.5000 | 0.7450     | 4083.0000 \n",
      "model.transformer.blocks.25.k_proj.weight_quantizer.permutation_list | 2851048.5000 | 0.7450     | 4083.0000 \n",
      "model.transformer.blocks.25.q_proj.act_quantizer.permutation_list | 2851048.5000 | 0.7450     | 4083.0000 \n",
      "model.transformer.blocks.25.k_proj.act_quantizer.permutation_list | 2851048.5000 | 0.7450     | 4083.0000 \n",
      "model.transformer.blocks.25.v_proj.act_quantizer.permutation_list | 2851048.5000 | 0.7450     | 4083.0000 \n",
      "model.transformer.blocks.17.ff_proj.weight_quantizer.permutation_list | 2850467.0000 | 0.7451     | 4074.0000 \n",
      "model.transformer.blocks.17.ff_proj.act_quantizer.permutation_list | 2850467.0000 | 0.7451     | 4074.0000 \n",
      "model.transformer.blocks.17.up_proj.act_quantizer.permutation_list | 2850467.0000 | 0.7451     | 4074.0000 \n",
      "model.transformer.blocks.17.up_proj.weight_quantizer.permutation_list | 2850467.0000 | 0.7451     | 4074.0000 \n",
      "model.transformer.blocks.16.k_proj.weight_quantizer.permutation_list | 2847023.7500 | 0.7454     | 4088.0000 \n",
      "model.transformer.blocks.16.v_proj.weight_quantizer.permutation_list | 2847023.7500 | 0.7454     | 4088.0000 \n",
      "model.transformer.blocks.16.k_proj.act_quantizer.permutation_list | 2847023.7500 | 0.7454     | 4088.0000 \n",
      "model.transformer.blocks.16.q_proj.act_quantizer.permutation_list | 2847023.7500 | 0.7454     | 4088.0000 \n",
      "model.transformer.blocks.16.q_proj.weight_quantizer.permutation_list | 2847023.7500 | 0.7454     | 4088.0000 \n",
      "model.transformer.blocks.16.v_proj.act_quantizer.permutation_list | 2847023.7500 | 0.7454     | 4088.0000 \n",
      "model.transformer.blocks.10.attn_out.weight_quantizer.permutation_list | 2845642.7500 | 0.7455     | 4035.0000 \n",
      "model.transformer.blocks.10.attn_out.act_quantizer.permutation_list | 2845642.7500 | 0.7455     | 4035.0000 \n",
      "model.transformer.blocks.30.ff_proj.weight_quantizer.permutation_list | 2844116.7500 | 0.7456     | 4024.0000 \n",
      "model.transformer.blocks.30.up_proj.act_quantizer.permutation_list | 2844116.7500 | 0.7456     | 4024.0000 \n",
      "model.transformer.blocks.30.up_proj.weight_quantizer.permutation_list | 2844116.7500 | 0.7456     | 4024.0000 \n",
      "model.transformer.blocks.30.ff_proj.act_quantizer.permutation_list | 2844116.7500 | 0.7456     | 4024.0000 \n",
      "model.transformer.blocks.19.k_proj.weight_quantizer.permutation_list | 2842041.7500 | 0.7458     | 4081.0000 \n",
      "model.transformer.blocks.19.v_proj.act_quantizer.permutation_list | 2842041.7500 | 0.7458     | 4081.0000 \n",
      "model.transformer.blocks.19.q_proj.weight_quantizer.permutation_list | 2842041.7500 | 0.7458     | 4081.0000 \n",
      "model.transformer.blocks.19.k_proj.act_quantizer.permutation_list | 2842041.7500 | 0.7458     | 4081.0000 \n",
      "model.transformer.blocks.19.q_proj.act_quantizer.permutation_list | 2842041.7500 | 0.7458     | 4081.0000 \n",
      "model.transformer.blocks.19.v_proj.weight_quantizer.permutation_list | 2842041.7500 | 0.7458     | 4081.0000 \n",
      "model.transformer.blocks.11.ff_proj.weight_quantizer.permutation_list | 2840743.0000 | 0.7459     | 4044.0000 \n",
      "model.transformer.blocks.11.ff_proj.act_quantizer.permutation_list | 2840743.0000 | 0.7459     | 4044.0000 \n",
      "model.transformer.blocks.11.up_proj.weight_quantizer.permutation_list | 2840743.0000 | 0.7459     | 4044.0000 \n",
      "model.transformer.blocks.11.up_proj.act_quantizer.permutation_list | 2840743.0000 | 0.7459     | 4044.0000 \n",
      "model.transformer.blocks.17.k_proj.act_quantizer.permutation_list | 2839216.5000 | 0.7461     | 4077.0000 \n",
      "model.transformer.blocks.17.q_proj.weight_quantizer.permutation_list | 2839216.5000 | 0.7461     | 4077.0000 \n",
      "model.transformer.blocks.17.q_proj.act_quantizer.permutation_list | 2839216.5000 | 0.7461     | 4077.0000 \n",
      "model.transformer.blocks.17.k_proj.weight_quantizer.permutation_list | 2839216.5000 | 0.7461     | 4077.0000 \n",
      "model.transformer.blocks.17.v_proj.act_quantizer.permutation_list | 2839216.5000 | 0.7461     | 4077.0000 \n",
      "model.transformer.blocks.17.v_proj.weight_quantizer.permutation_list | 2839216.5000 | 0.7461     | 4077.0000 \n",
      "model.transformer.blocks.9.k_proj.weight_quantizer.permutation_list | 2838439.0000 | 0.7461     | 4027.0000 \n",
      "model.transformer.blocks.9.k_proj.act_quantizer.permutation_list | 2838439.0000 | 0.7461     | 4027.0000 \n",
      "model.transformer.blocks.9.v_proj.act_quantizer.permutation_list | 2838439.0000 | 0.7461     | 4027.0000 \n",
      "model.transformer.blocks.9.q_proj.weight_quantizer.permutation_list | 2838439.0000 | 0.7461     | 4027.0000 \n",
      "model.transformer.blocks.9.q_proj.act_quantizer.permutation_list | 2838439.0000 | 0.7461     | 4027.0000 \n",
      "model.transformer.blocks.9.v_proj.weight_quantizer.permutation_list | 2838439.0000 | 0.7461     | 4027.0000 \n",
      "model.transformer.blocks.24.up_proj.weight_quantizer.permutation_list | 2836474.2500 | 0.7463     | 4077.0000 \n",
      "model.transformer.blocks.24.up_proj.act_quantizer.permutation_list | 2836474.2500 | 0.7463     | 4077.0000 \n",
      "model.transformer.blocks.24.ff_proj.weight_quantizer.permutation_list | 2836474.2500 | 0.7463     | 4077.0000 \n",
      "model.transformer.blocks.24.ff_proj.act_quantizer.permutation_list | 2836474.2500 | 0.7463     | 4077.0000 \n",
      "model.transformer.blocks.30.v_proj.weight_quantizer.permutation_list | 2833242.5000 | 0.7466     | 4044.0000 \n",
      "model.transformer.blocks.30.k_proj.weight_quantizer.permutation_list | 2833242.5000 | 0.7466     | 4044.0000 \n",
      "model.transformer.blocks.30.q_proj.weight_quantizer.permutation_list | 2833242.5000 | 0.7466     | 4044.0000 \n",
      "model.transformer.blocks.30.q_proj.act_quantizer.permutation_list | 2833242.5000 | 0.7466     | 4044.0000 \n",
      "model.transformer.blocks.30.v_proj.act_quantizer.permutation_list | 2833242.5000 | 0.7466     | 4044.0000 \n",
      "model.transformer.blocks.30.k_proj.act_quantizer.permutation_list | 2833242.5000 | 0.7466     | 4044.0000 \n",
      "model.transformer.blocks.21.k_proj.weight_quantizer.permutation_list | 2830392.7500 | 0.7468     | 4060.0000 \n",
      "model.transformer.blocks.21.k_proj.act_quantizer.permutation_list | 2830392.7500 | 0.7468     | 4060.0000 \n",
      "model.transformer.blocks.21.q_proj.act_quantizer.permutation_list | 2830392.7500 | 0.7468     | 4060.0000 \n",
      "model.transformer.blocks.21.q_proj.weight_quantizer.permutation_list | 2830392.7500 | 0.7468     | 4060.0000 \n",
      "model.transformer.blocks.21.v_proj.act_quantizer.permutation_list | 2830392.7500 | 0.7468     | 4060.0000 \n",
      "model.transformer.blocks.21.v_proj.weight_quantizer.permutation_list | 2830392.7500 | 0.7468     | 4060.0000 \n",
      "model.transformer.blocks.12.attn_out.weight_quantizer.permutation_list | 2830027.0000 | 0.7469     | 3955.0000 \n",
      "model.transformer.blocks.12.attn_out.act_quantizer.permutation_list | 2830027.0000 | 0.7469     | 3955.0000 \n",
      "model.transformer.blocks.20.v_proj.act_quantizer.permutation_list | 2826608.2500 | 0.7472     | 4070.0000 \n",
      "model.transformer.blocks.20.k_proj.act_quantizer.permutation_list | 2826608.2500 | 0.7472     | 4070.0000 \n",
      "model.transformer.blocks.20.q_proj.act_quantizer.permutation_list | 2826608.2500 | 0.7472     | 4070.0000 \n",
      "model.transformer.blocks.20.v_proj.weight_quantizer.permutation_list | 2826608.2500 | 0.7472     | 4070.0000 \n",
      "model.transformer.blocks.20.q_proj.weight_quantizer.permutation_list | 2826608.2500 | 0.7472     | 4070.0000 \n",
      "model.transformer.blocks.20.k_proj.weight_quantizer.permutation_list | 2826608.2500 | 0.7472     | 4070.0000 \n",
      "model.transformer.blocks.17.attn_out.weight_quantizer.permutation_list | 2824959.7500 | 0.7473     | 3994.0000 \n",
      "model.transformer.blocks.17.attn_out.act_quantizer.permutation_list | 2824959.7500 | 0.7473     | 3994.0000 \n",
      "model.transformer.blocks.28.attn_out.act_quantizer.permutation_list | 2824889.7500 | 0.7473     | 3983.0000 \n",
      "model.transformer.blocks.28.attn_out.weight_quantizer.permutation_list | 2824889.7500 | 0.7473     | 3983.0000 \n",
      "model.transformer.blocks.5.attn_out.act_quantizer.permutation_list | 2822178.2500 | 0.7476     | 3987.0000 \n",
      "model.transformer.blocks.5.attn_out.weight_quantizer.permutation_list | 2822178.2500 | 0.7476     | 3987.0000 \n",
      "model.transformer.blocks.2.k_proj.act_quantizer.permutation_list | 2820732.0000 | 0.7477     | 4047.0000 \n",
      "model.transformer.blocks.2.q_proj.weight_quantizer.permutation_list | 2820732.0000 | 0.7477     | 4047.0000 \n",
      "model.transformer.blocks.2.v_proj.weight_quantizer.permutation_list | 2820732.0000 | 0.7477     | 4047.0000 \n",
      "model.transformer.blocks.2.k_proj.weight_quantizer.permutation_list | 2820732.0000 | 0.7477     | 4047.0000 \n",
      "model.transformer.blocks.2.q_proj.act_quantizer.permutation_list | 2820732.0000 | 0.7477     | 4047.0000 \n",
      "model.transformer.blocks.2.v_proj.act_quantizer.permutation_list | 2820732.0000 | 0.7477     | 4047.0000 \n",
      "model.transformer.blocks.18.q_proj.weight_quantizer.permutation_list | 2819533.2500 | 0.7478     | 4030.0000 \n",
      "model.transformer.blocks.18.v_proj.weight_quantizer.permutation_list | 2819533.2500 | 0.7478     | 4030.0000 \n",
      "model.transformer.blocks.18.k_proj.act_quantizer.permutation_list | 2819533.2500 | 0.7478     | 4030.0000 \n",
      "model.transformer.blocks.18.k_proj.weight_quantizer.permutation_list | 2819533.2500 | 0.7478     | 4030.0000 \n",
      "model.transformer.blocks.18.v_proj.act_quantizer.permutation_list | 2819533.2500 | 0.7478     | 4030.0000 \n",
      "model.transformer.blocks.18.q_proj.act_quantizer.permutation_list | 2819533.2500 | 0.7478     | 4030.0000 \n",
      "model.transformer.blocks.12.ff_proj.act_quantizer.permutation_list | 2816375.5000 | 0.7481     | 4023.0000 \n",
      "model.transformer.blocks.12.up_proj.act_quantizer.permutation_list | 2816375.5000 | 0.7481     | 4023.0000 \n",
      "model.transformer.blocks.12.ff_proj.weight_quantizer.permutation_list | 2816375.5000 | 0.7481     | 4023.0000 \n",
      "model.transformer.blocks.12.up_proj.weight_quantizer.permutation_list | 2816375.5000 | 0.7481     | 4023.0000 \n",
      "model.transformer.blocks.24.attn_out.act_quantizer.permutation_list | 2816055.0000 | 0.7481     | 3984.0000 \n",
      "model.transformer.blocks.24.attn_out.weight_quantizer.permutation_list | 2816055.0000 | 0.7481     | 3984.0000 \n",
      "model.transformer.blocks.25.ff_proj.act_quantizer.permutation_list | 2815748.2500 | 0.7482     | 4060.0000 \n",
      "model.transformer.blocks.25.ff_proj.weight_quantizer.permutation_list | 2815748.2500 | 0.7482     | 4060.0000 \n",
      "model.transformer.blocks.25.up_proj.weight_quantizer.permutation_list | 2815748.2500 | 0.7482     | 4060.0000 \n",
      "model.transformer.blocks.25.up_proj.act_quantizer.permutation_list | 2815748.2500 | 0.7482     | 4060.0000 \n",
      "model.transformer.blocks.8.ff_proj.act_quantizer.permutation_list | 2813901.5000 | 0.7483     | 4062.0000 \n",
      "model.transformer.blocks.8.ff_proj.weight_quantizer.permutation_list | 2813901.5000 | 0.7483     | 4062.0000 \n",
      "model.transformer.blocks.8.up_proj.weight_quantizer.permutation_list | 2813901.5000 | 0.7483     | 4062.0000 \n",
      "model.transformer.blocks.8.up_proj.act_quantizer.permutation_list | 2813901.5000 | 0.7483     | 4062.0000 \n",
      "model.transformer.blocks.14.up_proj.act_quantizer.permutation_list | 2813045.0000 | 0.7484     | 4012.0000 \n",
      "model.transformer.blocks.14.up_proj.weight_quantizer.permutation_list | 2813045.0000 | 0.7484     | 4012.0000 \n",
      "model.transformer.blocks.14.ff_proj.weight_quantizer.permutation_list | 2813045.0000 | 0.7484     | 4012.0000 \n",
      "model.transformer.blocks.14.ff_proj.act_quantizer.permutation_list | 2813045.0000 | 0.7484     | 4012.0000 \n",
      "model.transformer.blocks.27.q_proj.act_quantizer.permutation_list | 2811809.0000 | 0.7485     | 3993.0000 \n",
      "model.transformer.blocks.27.k_proj.act_quantizer.permutation_list | 2811809.0000 | 0.7485     | 3993.0000 \n",
      "model.transformer.blocks.27.v_proj.act_quantizer.permutation_list | 2811809.0000 | 0.7485     | 3993.0000 \n",
      "model.transformer.blocks.27.k_proj.weight_quantizer.permutation_list | 2811809.0000 | 0.7485     | 3993.0000 \n",
      "model.transformer.blocks.27.v_proj.weight_quantizer.permutation_list | 2811809.0000 | 0.7485     | 3993.0000 \n",
      "model.transformer.blocks.27.q_proj.weight_quantizer.permutation_list | 2811809.0000 | 0.7485     | 3993.0000 \n",
      "model.transformer.blocks.11.v_proj.act_quantizer.permutation_list | 2811762.0000 | 0.7485     | 3977.0000 \n",
      "model.transformer.blocks.11.q_proj.act_quantizer.permutation_list | 2811762.0000 | 0.7485     | 3977.0000 \n",
      "model.transformer.blocks.11.q_proj.weight_quantizer.permutation_list | 2811762.0000 | 0.7485     | 3977.0000 \n",
      "model.transformer.blocks.11.v_proj.weight_quantizer.permutation_list | 2811762.0000 | 0.7485     | 3977.0000 \n",
      "model.transformer.blocks.11.k_proj.act_quantizer.permutation_list | 2811762.0000 | 0.7485     | 3977.0000 \n",
      "model.transformer.blocks.11.k_proj.weight_quantizer.permutation_list | 2811762.0000 | 0.7485     | 3977.0000 \n",
      "model.transformer.blocks.19.up_proj.weight_quantizer.permutation_list | 2811157.0000 | 0.7486     | 4037.0000 \n",
      "model.transformer.blocks.19.ff_proj.act_quantizer.permutation_list | 2811157.0000 | 0.7486     | 4037.0000 \n",
      "model.transformer.blocks.19.ff_proj.weight_quantizer.permutation_list | 2811157.0000 | 0.7486     | 4037.0000 \n",
      "model.transformer.blocks.19.up_proj.act_quantizer.permutation_list | 2811157.0000 | 0.7486     | 4037.0000 \n",
      "model.transformer.blocks.15.ff_proj.weight_quantizer.permutation_list | 2810927.5000 | 0.7486     | 4016.0000 \n",
      "model.transformer.blocks.15.up_proj.weight_quantizer.permutation_list | 2810927.5000 | 0.7486     | 4016.0000 \n",
      "model.transformer.blocks.15.up_proj.act_quantizer.permutation_list | 2810927.5000 | 0.7486     | 4016.0000 \n",
      "model.transformer.blocks.15.ff_proj.act_quantizer.permutation_list | 2810927.5000 | 0.7486     | 4016.0000 \n",
      "model.transformer.blocks.7.k_proj.weight_quantizer.permutation_list | 2809856.5000 | 0.7487     | 4028.0000 \n",
      "model.transformer.blocks.7.k_proj.act_quantizer.permutation_list | 2809856.5000 | 0.7487     | 4028.0000 \n",
      "model.transformer.blocks.7.v_proj.weight_quantizer.permutation_list | 2809856.5000 | 0.7487     | 4028.0000 \n",
      "model.transformer.blocks.7.q_proj.weight_quantizer.permutation_list | 2809856.5000 | 0.7487     | 4028.0000 \n",
      "model.transformer.blocks.7.q_proj.act_quantizer.permutation_list | 2809856.5000 | 0.7487     | 4028.0000 \n",
      "model.transformer.blocks.7.v_proj.act_quantizer.permutation_list | 2809856.5000 | 0.7487     | 4028.0000 \n",
      "model.transformer.blocks.10.up_proj.act_quantizer.permutation_list | 2808786.7500 | 0.7488     | 4005.0000 \n",
      "model.transformer.blocks.10.ff_proj.act_quantizer.permutation_list | 2808786.7500 | 0.7488     | 4005.0000 \n",
      "model.transformer.blocks.10.up_proj.weight_quantizer.permutation_list | 2808786.7500 | 0.7488     | 4005.0000 \n",
      "model.transformer.blocks.10.ff_proj.weight_quantizer.permutation_list | 2808786.7500 | 0.7488     | 4005.0000 \n",
      "model.transformer.blocks.29.q_proj.weight_quantizer.permutation_list | 2808510.7500 | 0.7488     | 4016.0000 \n",
      "model.transformer.blocks.29.v_proj.act_quantizer.permutation_list | 2808510.7500 | 0.7488     | 4016.0000 \n",
      "model.transformer.blocks.29.q_proj.act_quantizer.permutation_list | 2808510.7500 | 0.7488     | 4016.0000 \n",
      "model.transformer.blocks.29.k_proj.act_quantizer.permutation_list | 2808510.7500 | 0.7488     | 4016.0000 \n",
      "model.transformer.blocks.29.k_proj.weight_quantizer.permutation_list | 2808510.7500 | 0.7488     | 4016.0000 \n",
      "model.transformer.blocks.29.v_proj.weight_quantizer.permutation_list | 2808510.7500 | 0.7488     | 4016.0000 \n",
      "model.transformer.blocks.13.up_proj.act_quantizer.permutation_list | 2807543.0000 | 0.7489     | 4033.0000 \n",
      "model.transformer.blocks.13.up_proj.weight_quantizer.permutation_list | 2807543.0000 | 0.7489     | 4033.0000 \n",
      "model.transformer.blocks.13.ff_proj.act_quantizer.permutation_list | 2807543.0000 | 0.7489     | 4033.0000 \n",
      "model.transformer.blocks.13.ff_proj.weight_quantizer.permutation_list | 2807543.0000 | 0.7489     | 4033.0000 \n",
      "model.transformer.blocks.16.ff_proj.act_quantizer.permutation_list | 2805635.0000 | 0.7491     | 4063.0000 \n",
      "model.transformer.blocks.16.up_proj.weight_quantizer.permutation_list | 2805635.0000 | 0.7491     | 4063.0000 \n",
      "model.transformer.blocks.16.ff_proj.weight_quantizer.permutation_list | 2805635.0000 | 0.7491     | 4063.0000 \n",
      "model.transformer.blocks.16.up_proj.act_quantizer.permutation_list | 2805635.0000 | 0.7491     | 4063.0000 \n",
      "model.transformer.blocks.22.attn_out.act_quantizer.permutation_list | 2803393.5000 | 0.7493     | 4032.0000 \n",
      "model.transformer.blocks.22.attn_out.weight_quantizer.permutation_list | 2803393.5000 | 0.7493     | 4032.0000 \n",
      "model.transformer.blocks.31.attn_out.weight_quantizer.permutation_list | 2802865.2500 | 0.7493     | 3923.0000 \n",
      "model.transformer.blocks.31.attn_out.act_quantizer.permutation_list | 2802865.2500 | 0.7493     | 3923.0000 \n",
      "model.transformer.blocks.4.ff_proj.act_quantizer.permutation_list | 2802769.5000 | 0.7493     | 4023.0000 \n",
      "model.transformer.blocks.4.ff_proj.weight_quantizer.permutation_list | 2802769.5000 | 0.7493     | 4023.0000 \n",
      "model.transformer.blocks.4.up_proj.act_quantizer.permutation_list | 2802769.5000 | 0.7493     | 4023.0000 \n",
      "model.transformer.blocks.4.up_proj.weight_quantizer.permutation_list | 2802769.5000 | 0.7493     | 4023.0000 \n",
      "model.transformer.blocks.6.k_proj.act_quantizer.permutation_list | 2801560.7500 | 0.7494     | 4013.0000 \n",
      "model.transformer.blocks.6.k_proj.weight_quantizer.permutation_list | 2801560.7500 | 0.7494     | 4013.0000 \n",
      "model.transformer.blocks.6.v_proj.act_quantizer.permutation_list | 2801560.7500 | 0.7494     | 4013.0000 \n",
      "model.transformer.blocks.6.v_proj.weight_quantizer.permutation_list | 2801560.7500 | 0.7494     | 4013.0000 \n",
      "model.transformer.blocks.6.q_proj.act_quantizer.permutation_list | 2801560.7500 | 0.7494     | 4013.0000 \n",
      "model.transformer.blocks.6.q_proj.weight_quantizer.permutation_list | 2801560.7500 | 0.7494     | 4013.0000 \n",
      "model.transformer.blocks.13.k_proj.act_quantizer.permutation_list | 2796031.5000 | 0.7499     | 4074.0000 \n",
      "model.transformer.blocks.13.q_proj.act_quantizer.permutation_list | 2796031.5000 | 0.7499     | 4074.0000 \n",
      "model.transformer.blocks.13.k_proj.weight_quantizer.permutation_list | 2796031.5000 | 0.7499     | 4074.0000 \n",
      "model.transformer.blocks.13.q_proj.weight_quantizer.permutation_list | 2796031.5000 | 0.7499     | 4074.0000 \n",
      "model.transformer.blocks.13.v_proj.act_quantizer.permutation_list | 2796031.5000 | 0.7499     | 4074.0000 \n",
      "model.transformer.blocks.13.v_proj.weight_quantizer.permutation_list | 2796031.5000 | 0.7499     | 4074.0000 \n",
      "model.transformer.blocks.29.attn_out.weight_quantizer.permutation_list | 2795535.0000 | 0.7500     | 4077.0000 \n",
      "model.transformer.blocks.29.attn_out.act_quantizer.permutation_list | 2795535.0000 | 0.7500     | 4077.0000 \n",
      "model.transformer.blocks.15.attn_out.weight_quantizer.permutation_list | 2795064.5000 | 0.7500     | 4018.0000 \n",
      "model.transformer.blocks.15.attn_out.act_quantizer.permutation_list | 2795064.5000 | 0.7500     | 4018.0000 \n",
      "model.transformer.blocks.2.attn_out.weight_quantizer.permutation_list | 2794986.5000 | 0.7500     | 4079.0000 \n",
      "model.transformer.blocks.2.attn_out.act_quantizer.permutation_list | 2794986.5000 | 0.7500     | 4079.0000 \n",
      "model.transformer.blocks.4.k_proj.act_quantizer.permutation_list | 2790432.0000 | 0.7504     | 4076.0000 \n",
      "model.transformer.blocks.4.v_proj.weight_quantizer.permutation_list | 2790432.0000 | 0.7504     | 4076.0000 \n",
      "model.transformer.blocks.4.q_proj.act_quantizer.permutation_list | 2790432.0000 | 0.7504     | 4076.0000 \n",
      "model.transformer.blocks.4.v_proj.act_quantizer.permutation_list | 2790432.0000 | 0.7504     | 4076.0000 \n",
      "model.transformer.blocks.4.q_proj.weight_quantizer.permutation_list | 2790432.0000 | 0.7504     | 4076.0000 \n",
      "model.transformer.blocks.4.k_proj.weight_quantizer.permutation_list | 2790432.0000 | 0.7504     | 4076.0000 \n",
      "model.transformer.blocks.1.attn_out.weight_quantizer.permutation_list | 2787201.2500 | 0.7507     | 4028.0000 \n",
      "model.transformer.blocks.1.attn_out.act_quantizer.permutation_list | 2787201.2500 | 0.7507     | 4028.0000 \n",
      "model.transformer.blocks.31.ff_proj.act_quantizer.permutation_list | 2785022.5000 | 0.7509     | 4064.0000 \n",
      "model.transformer.blocks.31.ff_proj.weight_quantizer.permutation_list | 2785022.5000 | 0.7509     | 4064.0000 \n",
      "model.transformer.blocks.31.up_proj.act_quantizer.permutation_list | 2785022.5000 | 0.7509     | 4064.0000 \n",
      "model.transformer.blocks.31.up_proj.weight_quantizer.permutation_list | 2785022.5000 | 0.7509     | 4064.0000 \n",
      "model.transformer.blocks.22.ff_proj.weight_quantizer.permutation_list | 2782844.7500 | 0.7511     | 4030.0000 \n",
      "model.transformer.blocks.22.up_proj.act_quantizer.permutation_list | 2782844.7500 | 0.7511     | 4030.0000 \n",
      "model.transformer.blocks.22.up_proj.weight_quantizer.permutation_list | 2782844.7500 | 0.7511     | 4030.0000 \n",
      "model.transformer.blocks.22.ff_proj.act_quantizer.permutation_list | 2782844.7500 | 0.7511     | 4030.0000 \n",
      "model.transformer.blocks.9.attn_out.act_quantizer.permutation_list | 2778748.5000 | 0.7515     | 4007.0000 \n",
      "model.transformer.blocks.9.attn_out.weight_quantizer.permutation_list | 2778748.5000 | 0.7515     | 4007.0000 \n",
      "model.transformer.blocks.20.up_proj.act_quantizer.permutation_list | 2777506.5000 | 0.7516     | 4039.0000 \n",
      "model.transformer.blocks.20.ff_proj.act_quantizer.permutation_list | 2777506.5000 | 0.7516     | 4039.0000 \n",
      "model.transformer.blocks.20.ff_proj.weight_quantizer.permutation_list | 2777506.5000 | 0.7516     | 4039.0000 \n",
      "model.transformer.blocks.20.up_proj.weight_quantizer.permutation_list | 2777506.5000 | 0.7516     | 4039.0000 \n",
      "model.transformer.blocks.3.up_proj.act_quantizer.permutation_list | 2777504.7500 | 0.7516     | 4046.0000 \n",
      "model.transformer.blocks.3.ff_proj.act_quantizer.permutation_list | 2777504.7500 | 0.7516     | 4046.0000 \n",
      "model.transformer.blocks.3.ff_proj.weight_quantizer.permutation_list | 2777504.7500 | 0.7516     | 4046.0000 \n",
      "model.transformer.blocks.3.up_proj.weight_quantizer.permutation_list | 2777504.7500 | 0.7516     | 4046.0000 \n",
      "model.transformer.blocks.0.attn_out.act_quantizer.permutation_list | 2776616.2500 | 0.7517     | 3997.0000 \n",
      "model.transformer.blocks.0.attn_out.weight_quantizer.permutation_list | 2776616.2500 | 0.7517     | 3997.0000 \n",
      "model.transformer.blocks.26.up_proj.weight_quantizer.permutation_list | 2776268.5000 | 0.7517     | 4067.0000 \n",
      "model.transformer.blocks.26.ff_proj.act_quantizer.permutation_list | 2776268.5000 | 0.7517     | 4067.0000 \n",
      "model.transformer.blocks.26.up_proj.act_quantizer.permutation_list | 2776268.5000 | 0.7517     | 4067.0000 \n",
      "model.transformer.blocks.26.ff_proj.weight_quantizer.permutation_list | 2776268.5000 | 0.7517     | 4067.0000 \n",
      "model.transformer.blocks.0.v_proj.act_quantizer.permutation_list | 2775869.2500 | 0.7517     | 4016.0000 \n",
      "model.transformer.blocks.0.q_proj.act_quantizer.permutation_list | 2775869.2500 | 0.7517     | 4016.0000 \n",
      "model.transformer.blocks.0.k_proj.weight_quantizer.permutation_list | 2775869.2500 | 0.7517     | 4016.0000 \n",
      "model.transformer.blocks.0.v_proj.weight_quantizer.permutation_list | 2775869.2500 | 0.7517     | 4016.0000 \n",
      "model.transformer.blocks.0.q_proj.weight_quantizer.permutation_list | 2775869.2500 | 0.7517     | 4016.0000 \n",
      "model.transformer.blocks.0.k_proj.act_quantizer.permutation_list | 2775869.2500 | 0.7517     | 4016.0000 \n",
      "model.transformer.blocks.8.attn_out.act_quantizer.permutation_list | 2773909.5000 | 0.7519     | 3994.0000 \n",
      "model.transformer.blocks.8.attn_out.weight_quantizer.permutation_list | 2773909.5000 | 0.7519     | 3994.0000 \n",
      "model.transformer.blocks.14.attn_out.weight_quantizer.permutation_list | 2766096.2500 | 0.7526     | 3997.0000 \n",
      "model.transformer.blocks.14.attn_out.act_quantizer.permutation_list | 2766096.2500 | 0.7526     | 3997.0000 \n",
      "model.transformer.blocks.27.up_proj.weight_quantizer.permutation_list | 2765167.0000 | 0.7527     | 4049.0000 \n",
      "model.transformer.blocks.27.ff_proj.act_quantizer.permutation_list | 2765167.0000 | 0.7527     | 4049.0000 \n",
      "model.transformer.blocks.27.up_proj.act_quantizer.permutation_list | 2765167.0000 | 0.7527     | 4049.0000 \n",
      "model.transformer.blocks.27.ff_proj.weight_quantizer.permutation_list | 2765167.0000 | 0.7527     | 4049.0000 \n",
      "model.transformer.blocks.27.attn_out.weight_quantizer.permutation_list | 2764514.5000 | 0.7527     | 4066.0000 \n",
      "model.transformer.blocks.27.attn_out.act_quantizer.permutation_list | 2764514.5000 | 0.7527     | 4066.0000 \n",
      "model.transformer.blocks.6.up_proj.act_quantizer.permutation_list | 2760833.0000 | 0.7531     | 4038.0000 \n",
      "model.transformer.blocks.6.ff_proj.weight_quantizer.permutation_list | 2760833.0000 | 0.7531     | 4038.0000 \n",
      "model.transformer.blocks.6.up_proj.weight_quantizer.permutation_list | 2760833.0000 | 0.7531     | 4038.0000 \n",
      "model.transformer.blocks.6.ff_proj.act_quantizer.permutation_list | 2760833.0000 | 0.7531     | 4038.0000 \n",
      "model.transformer.blocks.8.v_proj.act_quantizer.permutation_list | 2760681.0000 | 0.7531     | 4087.0000 \n",
      "model.transformer.blocks.8.k_proj.act_quantizer.permutation_list | 2760681.0000 | 0.7531     | 4087.0000 \n",
      "model.transformer.blocks.8.q_proj.weight_quantizer.permutation_list | 2760681.0000 | 0.7531     | 4087.0000 \n",
      "model.transformer.blocks.8.q_proj.act_quantizer.permutation_list | 2760681.0000 | 0.7531     | 4087.0000 \n",
      "model.transformer.blocks.8.v_proj.weight_quantizer.permutation_list | 2760681.0000 | 0.7531     | 4087.0000 \n",
      "model.transformer.blocks.8.k_proj.weight_quantizer.permutation_list | 2760681.0000 | 0.7531     | 4087.0000 \n",
      "model.transformer.blocks.9.ff_proj.act_quantizer.permutation_list | 2759426.5000 | 0.7532     | 4042.0000 \n",
      "model.transformer.blocks.9.up_proj.weight_quantizer.permutation_list | 2759426.5000 | 0.7532     | 4042.0000 \n",
      "model.transformer.blocks.9.ff_proj.weight_quantizer.permutation_list | 2759426.5000 | 0.7532     | 4042.0000 \n",
      "model.transformer.blocks.9.up_proj.act_quantizer.permutation_list | 2759426.5000 | 0.7532     | 4042.0000 \n",
      "model.transformer.blocks.13.attn_out.act_quantizer.permutation_list | 2758524.0000 | 0.7533     | 3983.0000 \n",
      "model.transformer.blocks.13.attn_out.weight_quantizer.permutation_list | 2758524.0000 | 0.7533     | 3983.0000 \n",
      "model.transformer.blocks.29.ff_proj.weight_quantizer.permutation_list | 2758123.0000 | 0.7533     | 4063.0000 \n",
      "model.transformer.blocks.29.up_proj.act_quantizer.permutation_list | 2758123.0000 | 0.7533     | 4063.0000 \n",
      "model.transformer.blocks.29.ff_proj.act_quantizer.permutation_list | 2758123.0000 | 0.7533     | 4063.0000 \n",
      "model.transformer.blocks.29.up_proj.weight_quantizer.permutation_list | 2758123.0000 | 0.7533     | 4063.0000 \n",
      "model.transformer.blocks.23.v_proj.weight_quantizer.permutation_list | 2756962.7500 | 0.7534     | 4049.0000 \n",
      "model.transformer.blocks.23.v_proj.act_quantizer.permutation_list | 2756962.7500 | 0.7534     | 4049.0000 \n",
      "model.transformer.blocks.23.k_proj.act_quantizer.permutation_list | 2756962.7500 | 0.7534     | 4049.0000 \n",
      "model.transformer.blocks.23.q_proj.weight_quantizer.permutation_list | 2756962.7500 | 0.7534     | 4049.0000 \n",
      "model.transformer.blocks.23.q_proj.act_quantizer.permutation_list | 2756962.7500 | 0.7534     | 4049.0000 \n",
      "model.transformer.blocks.23.k_proj.weight_quantizer.permutation_list | 2756962.7500 | 0.7534     | 4049.0000 \n",
      "model.transformer.blocks.3.q_proj.act_quantizer.permutation_list | 2756625.2500 | 0.7534     | 4030.0000 \n",
      "model.transformer.blocks.3.v_proj.weight_quantizer.permutation_list | 2756625.2500 | 0.7534     | 4030.0000 \n",
      "model.transformer.blocks.3.k_proj.act_quantizer.permutation_list | 2756625.2500 | 0.7534     | 4030.0000 \n",
      "model.transformer.blocks.3.q_proj.weight_quantizer.permutation_list | 2756625.2500 | 0.7534     | 4030.0000 \n",
      "model.transformer.blocks.3.v_proj.act_quantizer.permutation_list | 2756625.2500 | 0.7534     | 4030.0000 \n",
      "model.transformer.blocks.3.k_proj.weight_quantizer.permutation_list | 2756625.2500 | 0.7534     | 4030.0000 \n",
      "model.transformer.blocks.23.attn_out.act_quantizer.permutation_list | 2752926.0000 | 0.7538     | 4067.0000 \n",
      "model.transformer.blocks.23.attn_out.weight_quantizer.permutation_list | 2752926.0000 | 0.7538     | 4067.0000 \n",
      "model.transformer.blocks.12.k_proj.act_quantizer.permutation_list | 2752636.2500 | 0.7538     | 4018.0000 \n",
      "model.transformer.blocks.12.v_proj.weight_quantizer.permutation_list | 2752636.2500 | 0.7538     | 4018.0000 \n",
      "model.transformer.blocks.12.v_proj.act_quantizer.permutation_list | 2752636.2500 | 0.7538     | 4018.0000 \n",
      "model.transformer.blocks.12.q_proj.act_quantizer.permutation_list | 2752636.2500 | 0.7538     | 4018.0000 \n",
      "model.transformer.blocks.12.q_proj.weight_quantizer.permutation_list | 2752636.2500 | 0.7538     | 4018.0000 \n",
      "model.transformer.blocks.12.k_proj.weight_quantizer.permutation_list | 2752636.2500 | 0.7538     | 4018.0000 \n",
      "model.transformer.blocks.31.k_proj.weight_quantizer.permutation_list | 2750708.5000 | 0.7540     | 4074.0000 \n",
      "model.transformer.blocks.31.v_proj.act_quantizer.permutation_list | 2750708.5000 | 0.7540     | 4074.0000 \n",
      "model.transformer.blocks.31.q_proj.weight_quantizer.permutation_list | 2750708.5000 | 0.7540     | 4074.0000 \n",
      "model.transformer.blocks.31.k_proj.act_quantizer.permutation_list | 2750708.5000 | 0.7540     | 4074.0000 \n",
      "model.transformer.blocks.31.v_proj.weight_quantizer.permutation_list | 2750708.5000 | 0.7540     | 4074.0000 \n",
      "model.transformer.blocks.31.q_proj.act_quantizer.permutation_list | 2750708.5000 | 0.7540     | 4074.0000 \n",
      "model.transformer.blocks.3.attn_out.weight_quantizer.permutation_list | 2750021.5000 | 0.7540     | 3970.0000 \n",
      "model.transformer.blocks.3.attn_out.act_quantizer.permutation_list | 2750021.5000 | 0.7540     | 3970.0000 \n",
      "model.transformer.blocks.1.ff_proj.weight_quantizer.permutation_list | 2747309.0000 | 0.7543     | 4029.0000 \n",
      "model.transformer.blocks.1.up_proj.weight_quantizer.permutation_list | 2747309.0000 | 0.7543     | 4029.0000 \n",
      "model.transformer.blocks.1.up_proj.act_quantizer.permutation_list | 2747309.0000 | 0.7543     | 4029.0000 \n",
      "model.transformer.blocks.1.ff_proj.act_quantizer.permutation_list | 2747309.0000 | 0.7543     | 4029.0000 \n",
      "model.transformer.blocks.20.attn_out.weight_quantizer.permutation_list | 2746737.0000 | 0.7543     | 4065.0000 \n",
      "model.transformer.blocks.20.attn_out.act_quantizer.permutation_list | 2746737.0000 | 0.7543     | 4065.0000 \n",
      "model.transformer.blocks.7.up_proj.act_quantizer.permutation_list | 2746591.5000 | 0.7543     | 4057.0000 \n",
      "model.transformer.blocks.7.ff_proj.weight_quantizer.permutation_list | 2746591.5000 | 0.7543     | 4057.0000 \n",
      "model.transformer.blocks.7.ff_proj.act_quantizer.permutation_list | 2746591.5000 | 0.7543     | 4057.0000 \n",
      "model.transformer.blocks.7.up_proj.weight_quantizer.permutation_list | 2746591.5000 | 0.7543     | 4057.0000 \n",
      "model.transformer.blocks.16.attn_out.weight_quantizer.permutation_list | 2745564.2500 | 0.7544     | 4001.0000 \n",
      "model.transformer.blocks.16.attn_out.act_quantizer.permutation_list | 2745564.2500 | 0.7544     | 4001.0000 \n",
      "model.transformer.blocks.19.attn_out.weight_quantizer.permutation_list | 2743525.0000 | 0.7546     | 4040.0000 \n",
      "model.transformer.blocks.19.attn_out.act_quantizer.permutation_list | 2743525.0000 | 0.7546     | 4040.0000 \n",
      "model.transformer.blocks.5.v_proj.act_quantizer.permutation_list | 2742140.0000 | 0.7547     | 4044.0000 \n",
      "model.transformer.blocks.5.k_proj.act_quantizer.permutation_list | 2742140.0000 | 0.7547     | 4044.0000 \n",
      "model.transformer.blocks.5.v_proj.weight_quantizer.permutation_list | 2742140.0000 | 0.7547     | 4044.0000 \n",
      "model.transformer.blocks.5.q_proj.weight_quantizer.permutation_list | 2742140.0000 | 0.7547     | 4044.0000 \n",
      "model.transformer.blocks.5.q_proj.act_quantizer.permutation_list | 2742140.0000 | 0.7547     | 4044.0000 \n",
      "model.transformer.blocks.5.k_proj.weight_quantizer.permutation_list | 2742140.0000 | 0.7547     | 4044.0000 \n",
      "model.transformer.blocks.18.attn_out.weight_quantizer.permutation_list | 2740324.5000 | 0.7549     | 3988.0000 \n",
      "model.transformer.blocks.18.attn_out.act_quantizer.permutation_list | 2740324.5000 | 0.7549     | 3988.0000 \n",
      "model.transformer.blocks.23.up_proj.act_quantizer.permutation_list | 2738752.0000 | 0.7550     | 4072.0000 \n",
      "model.transformer.blocks.23.up_proj.weight_quantizer.permutation_list | 2738752.0000 | 0.7550     | 4072.0000 \n",
      "model.transformer.blocks.23.ff_proj.act_quantizer.permutation_list | 2738752.0000 | 0.7550     | 4072.0000 \n",
      "model.transformer.blocks.23.ff_proj.weight_quantizer.permutation_list | 2738752.0000 | 0.7550     | 4072.0000 \n",
      "model.transformer.blocks.21.attn_out.weight_quantizer.permutation_list | 2737899.5000 | 0.7551     | 4043.0000 \n",
      "model.transformer.blocks.21.attn_out.act_quantizer.permutation_list | 2737899.5000 | 0.7551     | 4043.0000 \n",
      "model.transformer.blocks.6.attn_out.weight_quantizer.permutation_list | 2736547.0000 | 0.7552     | 4026.0000 \n",
      "model.transformer.blocks.6.attn_out.act_quantizer.permutation_list | 2736547.0000 | 0.7552     | 4026.0000 \n",
      "model.transformer.blocks.14.v_proj.act_quantizer.permutation_list | 2734353.0000 | 0.7554     | 4050.0000 \n",
      "model.transformer.blocks.14.v_proj.weight_quantizer.permutation_list | 2734353.0000 | 0.7554     | 4050.0000 \n",
      "model.transformer.blocks.14.q_proj.weight_quantizer.permutation_list | 2734353.0000 | 0.7554     | 4050.0000 \n",
      "model.transformer.blocks.14.k_proj.weight_quantizer.permutation_list | 2734353.0000 | 0.7554     | 4050.0000 \n",
      "model.transformer.blocks.14.q_proj.act_quantizer.permutation_list | 2734353.0000 | 0.7554     | 4050.0000 \n",
      "model.transformer.blocks.14.k_proj.act_quantizer.permutation_list | 2734353.0000 | 0.7554     | 4050.0000 \n",
      "model.transformer.blocks.22.v_proj.act_quantizer.permutation_list | 2725406.7500 | 0.7562     | 4082.0000 \n",
      "model.transformer.blocks.22.q_proj.weight_quantizer.permutation_list | 2725406.7500 | 0.7562     | 4082.0000 \n",
      "model.transformer.blocks.22.k_proj.act_quantizer.permutation_list | 2725406.7500 | 0.7562     | 4082.0000 \n",
      "model.transformer.blocks.22.q_proj.act_quantizer.permutation_list | 2725406.7500 | 0.7562     | 4082.0000 \n",
      "model.transformer.blocks.22.v_proj.weight_quantizer.permutation_list | 2725406.7500 | 0.7562     | 4082.0000 \n",
      "model.transformer.blocks.22.k_proj.weight_quantizer.permutation_list | 2725406.7500 | 0.7562     | 4082.0000 \n",
      "model.transformer.blocks.18.up_proj.weight_quantizer.permutation_list | 2724429.2500 | 0.7563     | 4011.0000 \n",
      "model.transformer.blocks.18.up_proj.act_quantizer.permutation_list | 2724429.2500 | 0.7563     | 4011.0000 \n",
      "model.transformer.blocks.18.ff_proj.weight_quantizer.permutation_list | 2724429.2500 | 0.7563     | 4011.0000 \n",
      "model.transformer.blocks.18.ff_proj.act_quantizer.permutation_list | 2724429.2500 | 0.7563     | 4011.0000 \n",
      "model.transformer.blocks.7.attn_out.weight_quantizer.permutation_list | 2723749.7500 | 0.7564     | 4019.0000 \n",
      "model.transformer.blocks.7.attn_out.act_quantizer.permutation_list | 2723749.7500 | 0.7564     | 4019.0000 \n",
      "model.transformer.blocks.10.v_proj.act_quantizer.permutation_list | 2721379.0000 | 0.7566     | 4042.0000 \n",
      "model.transformer.blocks.10.q_proj.act_quantizer.permutation_list | 2721379.0000 | 0.7566     | 4042.0000 \n",
      "model.transformer.blocks.10.v_proj.weight_quantizer.permutation_list | 2721379.0000 | 0.7566     | 4042.0000 \n",
      "model.transformer.blocks.10.q_proj.weight_quantizer.permutation_list | 2721379.0000 | 0.7566     | 4042.0000 \n",
      "model.transformer.blocks.10.k_proj.act_quantizer.permutation_list | 2721379.0000 | 0.7566     | 4042.0000 \n",
      "model.transformer.blocks.10.k_proj.weight_quantizer.permutation_list | 2721379.0000 | 0.7566     | 4042.0000 \n",
      "model.transformer.blocks.5.up_proj.weight_quantizer.permutation_list | 2711707.5000 | 0.7575     | 4033.0000 \n",
      "model.transformer.blocks.5.ff_proj.weight_quantizer.permutation_list | 2711707.5000 | 0.7575     | 4033.0000 \n",
      "model.transformer.blocks.5.up_proj.act_quantizer.permutation_list | 2711707.5000 | 0.7575     | 4033.0000 \n",
      "model.transformer.blocks.5.ff_proj.act_quantizer.permutation_list | 2711707.5000 | 0.7575     | 4033.0000 \n",
      "model.transformer.blocks.25.attn_out.weight_quantizer.permutation_list | 2696192.5000 | 0.7589     | 4027.0000 \n",
      "model.transformer.blocks.25.attn_out.act_quantizer.permutation_list | 2696192.5000 | 0.7589     | 4027.0000 \n",
      "model.transformer.blocks.21.ff_proj.weight_quantizer.permutation_list | 2664015.5000 | 0.7617     | 4073.0000 \n",
      "model.transformer.blocks.21.ff_proj.act_quantizer.permutation_list | 2664015.5000 | 0.7617     | 4073.0000 \n",
      "model.transformer.blocks.21.up_proj.act_quantizer.permutation_list | 2664015.5000 | 0.7617     | 4073.0000 \n",
      "model.transformer.blocks.21.up_proj.weight_quantizer.permutation_list | 2664015.5000 | 0.7617     | 4073.0000 \n",
      "model.transformer.blocks.4.attn_out.act_quantizer.permutation_list | 2659511.5000 | 0.7621     | 4052.0000 \n",
      "model.transformer.blocks.4.attn_out.weight_quantizer.permutation_list | 2659511.5000 | 0.7621     | 4052.0000 \n",
      "model.transformer.blocks.30.attn_out.act_quantizer.permutation_list | 2631134.0000 | 0.7647     | 4031.0000 \n",
      "model.transformer.blocks.30.attn_out.weight_quantizer.permutation_list | 2631134.0000 | 0.7647     | 4031.0000 \n",
      "model.transformer.blocks.26.attn_out.act_quantizer.permutation_list | 2608415.5000 | 0.7667     | 4093.0000 \n",
      "model.transformer.blocks.26.attn_out.weight_quantizer.permutation_list | 2608415.5000 | 0.7667     | 4093.0000 \n",
      "model.transformer.blocks.31.down_smooth_scale | 17.0616    | 0.9841     | 43.2188   \n",
      "model.transformer.blocks.27.down_smooth_scale | 16.3091    | 0.9819     | 30.9375   \n",
      "model.transformer.blocks.28.down_smooth_scale | 15.7108    | 0.9818     | 36.3125   \n",
      "model.transformer.blocks.26.down_smooth_scale | 14.5479    | 0.9817     | 37.4688   \n",
      "model.transformer.blocks.30.down_smooth_scale | 14.1916    | 0.9846     | 38.0000   \n",
      "model.transformer.blocks.29.down_smooth_scale | 13.4729    | 0.9832     | 29.4688   \n",
      "model.transformer.blocks.25.down_smooth_scale | 12.0951    | 0.9806     | 25.5000   \n",
      "model.transformer.blocks.24.down_smooth_scale | 9.4437     | 0.9821     | 21.6562   \n",
      "model.transformer.blocks.8.down_smooth_scale | 8.2559     | 0.9583     | 17.4219   \n",
      "model.transformer.blocks.9.down_smooth_scale | 8.0482     | 0.9617     | 20.0000   \n",
      "model.transformer.blocks.10.down_smooth_scale | 7.6857     | 0.9670     | 20.8594   \n",
      "model.transformer.blocks.23.down_smooth_scale | 7.3419     | 0.9832     | 19.8750   \n",
      "model.transformer.blocks.7.down_smooth_scale | 6.5421     | 0.9618     | 16.1094   \n",
      "model.transformer.blocks.11.down_smooth_scale | 6.2046     | 0.9722     | 17.9688   \n",
      "model.transformer.blocks.13.down_smooth_scale | 5.6388     | 0.9761     | 16.7031   \n",
      "model.transformer.blocks.22.down_smooth_scale | 5.4641     | 0.9836     | 16.2969   \n",
      "model.transformer.blocks.6.down_smooth_scale | 5.4049     | 0.9669     | 16.6562   \n",
      "model.transformer.blocks.12.down_smooth_scale | 5.1148     | 0.9762     | 16.0156   \n",
      "model.transformer.blocks.1.q_proj.weight_quantizer.zeros | 4.9644     | 0.9586     | 6.0000    \n",
      "model.transformer.blocks.14.down_smooth_scale | 4.9577     | 0.9781     | 15.7344   \n",
      "model.transformer.blocks.1.k_proj.weight_quantizer.zeros | 4.8408     | 0.9597     | 7.0000    \n",
      "model.transformer.blocks.21.down_smooth_scale | 4.6751     | 0.9832     | 17.9219   \n",
      "model.transformer.blocks.3.k_proj.weight_quantizer.zeros | 4.5491     | 0.9612     | 7.0000    \n",
      "model.transformer.blocks.5.k_proj.weight_quantizer.zeros | 4.2773     | 0.9634     | 6.0000    \n",
      "model.transformer.blocks.16.down_smooth_scale | 4.1913     | 0.9797     | 14.6875   \n",
      "model.transformer.blocks.17.down_smooth_scale | 4.0684     | 0.9814     | 15.1875   \n",
      "model.transformer.blocks.4.k_proj.weight_quantizer.zeros | 3.9397     | 0.9666     | 7.0000    \n",
      "model.transformer.blocks.19.down_smooth_scale | 3.8543     | 0.9846     | 18.0312   \n",
      "model.transformer.blocks.20.down_smooth_scale | 3.8421     | 0.9848     | 13.4688   \n",
      "model.transformer.blocks.18.down_smooth_scale | 3.8297     | 0.9831     | 12.8125   \n",
      "model.transformer.blocks.15.down_smooth_scale | 3.4847     | 0.9822     | 19.4844   \n",
      "model.transformer.blocks.5.down_smooth_scale | 3.3892     | 0.9705     | 13.4688   \n",
      "model.transformer.blocks.2.q_proj.weight_quantizer.zeros | 3.2668     | 0.9721     | 6.0000    \n",
      "model.transformer.blocks.3.q_proj.weight_quantizer.zeros | 3.1523     | 0.9729     | 6.0000    \n",
      "model.transformer.blocks.6.k_proj.weight_quantizer.zeros | 2.9941     | 0.9744     | 6.0000    \n",
      "model.transformer.blocks.8.k_proj.weight_quantizer.zeros | 2.7930     | 0.9761     | 7.0000    \n",
      "model.transformer.blocks.5.q_proj.weight_quantizer.zeros | 2.7717     | 0.9760     | 7.0000    \n",
      "model.transformer.blocks.11.k_proj.weight_quantizer.zeros | 2.6726     | 0.9770     | 7.0000    \n",
      "model.transformer.blocks.4.q_proj.weight_quantizer.zeros | 2.6553     | 0.9771     | 5.0000    \n",
      "model.transformer.blocks.7.k_proj.weight_quantizer.zeros | 2.5417     | 0.9781     | 7.0000    \n",
      "model.transformer.blocks.4.down_smooth_scale | 2.4873     | 0.9716     | 13.4531   \n",
      "model.transformer.blocks.0.k_proj.weight_quantizer.zeros | 2.4592     | 0.9785     | 6.0000    \n",
      "model.transformer.blocks.25.k_proj.weight_quantizer.zeros | 2.4390     | 0.9790     | 6.0000    \n",
      "model.transformer.blocks.2.k_proj.weight_quantizer.zeros | 2.4209     | 0.9791     | 6.0000    \n",
      "model.transformer.blocks.0.q_proj.weight_quantizer.zeros | 2.4099     | 0.9790     | 6.0000    \n",
      "model.transformer.blocks.15.k_proj.weight_quantizer.zeros | 2.3396     | 0.9797     | 7.0000    \n",
      "model.transformer.blocks.12.k_proj.weight_quantizer.zeros | 2.3196     | 0.9798     | 7.0000    \n",
      "model.transformer.blocks.24.k_proj.weight_quantizer.zeros | 2.3071     | 0.9801     | 6.0000    \n",
      "model.transformer.blocks.21.v_proj.weight_quantizer.zeros | 2.2468     | 0.9805     | 6.0000    \n",
      "model.transformer.blocks.23.k_proj.weight_quantizer.zeros | 2.2417     | 0.9805     | 6.0000    \n",
      "model.transformer.blocks.26.k_proj.weight_quantizer.zeros | 2.2346     | 0.9806     | 6.0000    \n",
      "model.transformer.blocks.14.k_proj.weight_quantizer.zeros | 2.1731     | 0.9812     | 7.0000    \n",
      "model.transformer.blocks.9.k_proj.weight_quantizer.zeros | 2.0559     | 0.9822     | 7.0000    \n",
      "model.transformer.blocks.21.k_proj.weight_quantizer.zeros | 2.0317     | 0.9823     | 6.0000    \n",
      "model.transformer.blocks.6.q_proj.weight_quantizer.zeros | 1.9204     | 0.9832     | 6.0000    \n",
      "model.transformer.blocks.22.k_proj.weight_quantizer.zeros | 1.9175     | 0.9832     | 7.0000    \n",
      "model.transformer.blocks.22.v_proj.weight_quantizer.zeros | 1.9163     | 0.9834     | 6.0000    \n",
      "model.transformer.blocks.20.k_proj.weight_quantizer.zeros | 1.9102     | 0.9835     | 6.0000    \n",
      "model.transformer.blocks.25.q_proj.weight_quantizer.zeros | 1.9089     | 0.9834     | 5.0000    \n",
      "model.transformer.blocks.30.k_proj.weight_quantizer.zeros | 1.8401     | 0.9838     | 5.0000    \n",
      "model.transformer.blocks.10.k_proj.weight_quantizer.zeros | 1.7566     | 0.9847     | 7.0000    \n",
      "model.transformer.blocks.18.k_proj.weight_quantizer.zeros | 1.7439     | 0.9850     | 7.0000    \n",
      "model.transformer.blocks.13.k_proj.weight_quantizer.zeros | 1.7104     | 0.9852     | 6.0000    \n",
      "model.transformer.blocks.17.k_proj.weight_quantizer.zeros | 1.7085     | 0.9850     | 6.0000    \n",
      "model.transformer.blocks.8.q_proj.weight_quantizer.zeros | 1.7083     | 0.9851     | 5.0000    \n",
      "model.transformer.blocks.15.q_proj.weight_quantizer.zeros | 1.6902     | 0.9852     | 5.0000    \n",
      "model.transformer.blocks.7.q_proj.weight_quantizer.zeros | 1.6860     | 0.9853     | 6.0000    \n",
      "model.transformer.blocks.25.v_proj.weight_quantizer.zeros | 1.6804     | 0.9853     | 6.0000    \n",
      "model.transformer.blocks.20.v_proj.weight_quantizer.zeros | 1.6421     | 0.9857     | 6.0000    \n",
      "model.transformer.blocks.12.q_proj.weight_quantizer.zeros | 1.6174     | 0.9859     | 5.0000    \n",
      "model.transformer.blocks.16.k_proj.weight_quantizer.zeros | 1.6125     | 0.9859     | 6.0000    \n",
      "model.transformer.blocks.30.q_proj.weight_quantizer.zeros | 1.6091     | 0.9860     | 5.0000    \n",
      "model.transformer.blocks.26.q_proj.weight_quantizer.zeros | 1.5989     | 0.9860     | 6.0000    \n",
      "model.transformer.blocks.11.q_proj.weight_quantizer.zeros | 1.5823     | 0.9863     | 5.0000    \n",
      "model.transformer.blocks.19.k_proj.weight_quantizer.zeros | 1.5806     | 0.9862     | 6.0000    \n",
      "model.transformer.blocks.19.v_proj.weight_quantizer.zeros | 1.5730     | 0.9862     | 5.0000    \n",
      "model.transformer.blocks.23.v_proj.weight_quantizer.zeros | 1.5593     | 0.9864     | 5.0000    \n",
      "model.transformer.blocks.14.q_proj.weight_quantizer.zeros | 1.5347     | 0.9866     | 5.0000    \n",
      "model.transformer.blocks.3.down_smooth_scale | 1.5168     | 0.9722     | 10.5625   \n",
      "model.transformer.blocks.20.q_proj.weight_quantizer.zeros | 1.5142     | 0.9868     | 5.0000    \n",
      "model.transformer.blocks.27.k_proj.weight_quantizer.zeros | 1.5010     | 0.9869     | 5.0000    \n",
      "model.transformer.blocks.21.q_proj.weight_quantizer.zeros | 1.4797     | 0.9870     | 5.0000    \n",
      "model.transformer.blocks.9.q_proj.weight_quantizer.zeros | 1.4573     | 0.9872     | 5.0000    \n",
      "model.transformer.blocks.17.q_proj.weight_quantizer.zeros | 1.4050     | 0.9876     | 5.0000    \n",
      "model.transformer.blocks.18.q_proj.weight_quantizer.zeros | 1.3687     | 0.9880     | 5.0000    \n",
      "model.transformer.blocks.22.q_proj.weight_quantizer.zeros | 1.3625     | 0.9881     | 5.0000    \n",
      "model.transformer.blocks.23.q_proj.weight_quantizer.zeros | 1.3552     | 0.9881     | 5.0000    \n",
      "model.transformer.blocks.19.q_proj.weight_quantizer.zeros | 1.3289     | 0.9883     | 5.0000    \n",
      "model.transformer.blocks.24.q_proj.weight_quantizer.zeros | 1.3232     | 0.9884     | 5.0000    \n",
      "model.transformer.blocks.0.ff_out.weight_quantizer.zeros | 1.2788     | 0.9888     | 4.0000    \n",
      "model.transformer.blocks.10.q_proj.weight_quantizer.zeros | 1.2742     | 0.9888     | 5.0000    \n",
      "model.transformer.blocks.13.q_proj.weight_quantizer.zeros | 1.2617     | 0.9889     | 5.0000    \n",
      "model.transformer.blocks.16.q_proj.weight_quantizer.zeros | 1.2512     | 0.9891     | 5.0000    \n",
      "model.transformer.blocks.18.v_proj.weight_quantizer.zeros | 1.2295     | 0.9893     | 5.0000    \n",
      "model.transformer.blocks.26.v_proj.weight_quantizer.zeros | 1.1838     | 0.9896     | 6.0000    \n",
      "model.transformer.blocks.28.k_proj.weight_quantizer.zeros | 1.1472     | 0.9899     | 4.0000    \n",
      "model.transformer.blocks.17.ff_proj.weight_quantizer.zeros | 1.1442     | 0.9902     | 4.0000    \n",
      "model.transformer.blocks.1.v_proj.weight_quantizer.zeros | 1.1309     | 0.9901     | 5.0000    \n",
      "model.transformer.blocks.31.k_proj.weight_quantizer.zeros | 1.1272     | 0.9901     | 5.0000    \n",
      "model.transformer.blocks.0.ff_proj.weight_quantizer.zeros | 1.1235     | 0.9904     | 4.0000    \n",
      "model.transformer.blocks.24.v_proj.weight_quantizer.zeros | 1.1106     | 0.9903     | 6.0000    \n",
      "model.transformer.blocks.29.k_proj.weight_quantizer.zeros | 1.0972     | 0.9903     | 5.0000    \n",
      "model.transformer.blocks.2.attn_out.weight_quantizer.zeros | 1.0911     | 0.9904     | 4.0000    \n",
      "model.transformer.blocks.1.attn_out.weight_quantizer.zeros | 1.0903     | 0.9904     | 4.0000    \n",
      "model.transformer.blocks.31.ff_out.weight_quantizer.zeros | 1.0891     | 0.9904     | 4.0000    \n",
      "model.transformer.blocks.24.ff_proj.weight_quantizer.zeros | 1.0862     | 0.9904     | 5.0000    \n",
      "model.transformer.blocks.30.ff_proj.weight_quantizer.zeros | 1.0852     | 0.9906     | 6.0000    \n",
      "model.transformer.blocks.0.attn_out.weight_quantizer.zeros | 1.0759     | 0.9905     | 3.0000    \n",
      "model.transformer.blocks.0.up_proj.weight_quantizer.zeros | 1.0571     | 0.9907     | 4.0000    \n",
      "model.transformer.blocks.27.q_proj.weight_quantizer.zeros | 1.0447     | 0.9908     | 5.0000    \n",
      "model.transformer.blocks.16.v_proj.weight_quantizer.zeros | 1.0308     | 0.9909     | 6.0000    \n",
      "model.transformer.blocks.17.v_proj.weight_quantizer.zeros | 1.0237     | 0.9910     | 5.0000    \n",
      "model.transformer.blocks.22.ff_proj.weight_quantizer.zeros | 1.0176     | 0.9910     | 6.0000    \n",
      "model.transformer.blocks.31.q_proj.weight_quantizer.zeros | 0.9980     | 0.9912     | 6.0000    \n",
      "model.transformer.blocks.3.v_proj.weight_quantizer.zeros | 0.9978     | 0.9912     | 4.0000    \n",
      "model.transformer.blocks.31.ff_proj.weight_quantizer.zeros | 0.9912     | 0.9912     | 5.0000    \n",
      "model.transformer.blocks.3.attn_out.weight_quantizer.zeros | 0.9907     | 0.9913     | 3.0000    \n",
      "model.transformer.blocks.20.ff_proj.weight_quantizer.zeros | 0.9876     | 0.9918     | 5.0000    \n",
      "model.transformer.blocks.30.ff_out.weight_quantizer.zeros | 0.9849     | 0.9914     | 4.0000    \n",
      "model.transformer.blocks.1.ff_out.weight_quantizer.zeros | 0.9756     | 0.9914     | 3.0000    \n",
      "model.transformer.blocks.14.ff_out.weight_quantizer.zeros | 0.9626     | 0.9915     | 5.0000    \n",
      "model.transformer.blocks.15.ff_out.weight_quantizer.zeros | 0.9612     | 0.9915     | 5.0000    \n",
      "model.transformer.blocks.8.ff_out.weight_quantizer.zeros | 0.9607     | 0.9915     | 4.0000    \n",
      "model.transformer.blocks.31.up_proj.weight_quantizer.zeros | 0.9602     | 0.9916     | 5.0000    \n",
      "model.transformer.blocks.25.ff_proj.weight_quantizer.zeros | 0.9504     | 0.9916     | 5.0000    \n",
      "model.transformer.blocks.28.ff_out.weight_quantizer.zeros | 0.9475     | 0.9916     | 3.0000    \n",
      "model.transformer.blocks.5.attn_out.weight_quantizer.zeros | 0.9377     | 0.9917     | 3.0000    \n",
      "model.transformer.blocks.2.v_proj.weight_quantizer.zeros | 0.9333     | 0.9918     | 4.0000    \n",
      "model.transformer.blocks.17.ff_out.weight_quantizer.zeros | 0.9224     | 0.9919     | 5.0000    \n",
      "model.transformer.blocks.29.ff_out.weight_quantizer.zeros | 0.9141     | 0.9920     | 4.0000    \n",
      "model.transformer.blocks.28.q_proj.weight_quantizer.zeros | 0.9126     | 0.9920     | 4.0000    \n",
      "model.transformer.blocks.11.ff_out.weight_quantizer.zeros | 0.9038     | 0.9920     | 4.0000    \n",
      "model.transformer.blocks.29.q_proj.weight_quantizer.zeros | 0.9006     | 0.9921     | 4.0000    \n",
      "model.transformer.blocks.12.ff_proj.weight_quantizer.zeros | 0.8868     | 0.9922     | 5.0000    \n",
      "model.transformer.blocks.12.ff_out.weight_quantizer.zeros | 0.8813     | 0.9923     | 3.0000    \n",
      "model.transformer.blocks.21.ff_proj.weight_quantizer.zeros | 0.8801     | 0.9924     | 5.0000    \n",
      "model.transformer.blocks.13.ff_out.weight_quantizer.zeros | 0.8743     | 0.9923     | 4.0000    \n",
      "model.transformer.blocks.19.ff_out.weight_quantizer.zeros | 0.8706     | 0.9923     | 5.0000    \n",
      "model.transformer.blocks.4.v_proj.weight_quantizer.zeros | 0.8704     | 0.9924     | 4.0000    \n",
      "model.transformer.blocks.11.ff_proj.weight_quantizer.zeros | 0.8695     | 0.9923     | 4.0000    \n",
      "model.transformer.blocks.2.ff_out.weight_quantizer.zeros | 0.8638     | 0.9924     | 3.0000    \n",
      "model.transformer.blocks.20.ff_out.weight_quantizer.zeros | 0.8618     | 0.9925     | 3.0000    \n",
      "model.transformer.blocks.30.up_proj.weight_quantizer.zeros | 0.8602     | 0.9924     | 6.0000    \n",
      "model.transformer.blocks.1.ff_proj.weight_quantizer.zeros | 0.8596     | 0.9925     | 4.0000    \n",
      "model.transformer.blocks.23.ff_proj.weight_quantizer.zeros | 0.8586     | 0.9926     | 5.0000    \n",
      "model.transformer.blocks.10.ff_out.weight_quantizer.zeros | 0.8547     | 0.9925     | 4.0000    \n",
      "model.transformer.blocks.19.ff_proj.weight_quantizer.zeros | 0.8492     | 0.9925     | 4.0000    \n",
      "model.transformer.blocks.4.attn_out.weight_quantizer.zeros | 0.8464     | 0.9926     | 4.0000    \n",
      "model.transformer.blocks.29.ff_proj.weight_quantizer.zeros | 0.8464     | 0.9925     | 4.0000    \n",
      "model.transformer.blocks.24.up_proj.weight_quantizer.zeros | 0.8443     | 0.9926     | 6.0000    \n",
      "model.transformer.blocks.9.ff_out.weight_quantizer.zeros | 0.8420     | 0.9926     | 3.0000    \n",
      "model.transformer.blocks.18.ff_out.weight_quantizer.zeros | 0.8416     | 0.9926     | 4.0000    \n",
      "model.transformer.blocks.6.ff_out.weight_quantizer.zeros | 0.8389     | 0.9926     | 4.0000    \n",
      "model.transformer.blocks.16.ff_out.weight_quantizer.zeros | 0.8350     | 0.9926     | 3.0000    \n",
      "model.transformer.blocks.26.ff_proj.weight_quantizer.zeros | 0.8341     | 0.9926     | 5.0000    \n",
      "model.transformer.blocks.18.ff_proj.weight_quantizer.zeros | 0.8328     | 0.9929     | 4.0000    \n",
      "model.transformer.blocks.16.ff_proj.weight_quantizer.zeros | 0.8321     | 0.9926     | 4.0000    \n",
      "model.transformer.blocks.5.v_proj.weight_quantizer.zeros | 0.8298     | 0.9927     | 5.0000    \n",
      "model.transformer.blocks.23.ff_out.weight_quantizer.zeros | 0.8289     | 0.9927     | 4.0000    \n",
      "model.transformer.blocks.6.v_proj.weight_quantizer.zeros | 0.8284     | 0.9927     | 5.0000    \n",
      "model.transformer.blocks.15.ff_proj.weight_quantizer.zeros | 0.8226     | 0.9928     | 5.0000    \n",
      "model.transformer.blocks.7.ff_out.weight_quantizer.zeros | 0.8201     | 0.9928     | 3.0000    \n",
      "model.transformer.blocks.27.ff_out.weight_quantizer.zeros | 0.8186     | 0.9928     | 3.0000    \n",
      "model.transformer.blocks.21.ff_out.weight_quantizer.zeros | 0.8147     | 0.9928     | 4.0000    \n",
      "model.transformer.blocks.1.up_proj.weight_quantizer.zeros | 0.8128     | 0.9928     | 4.0000    \n",
      "model.transformer.blocks.24.ff_out.weight_quantizer.zeros | 0.8076     | 0.9929     | 5.0000    \n",
      "model.transformer.blocks.25.ff_out.weight_quantizer.zeros | 0.8035     | 0.9929     | 3.0000    \n",
      "model.transformer.blocks.26.ff_out.weight_quantizer.zeros | 0.8032     | 0.9929     | 3.0000    \n",
      "model.transformer.blocks.4.ff_out.weight_quantizer.zeros | 0.8003     | 0.9930     | 3.0000    \n",
      "model.transformer.blocks.6.attn_out.weight_quantizer.zeros | 0.7991     | 0.9930     | 4.0000    \n",
      "model.transformer.blocks.2.ff_proj.weight_quantizer.zeros | 0.7960     | 0.9931     | 5.0000    \n",
      "model.transformer.blocks.5.ff_out.weight_quantizer.zeros | 0.7954     | 0.9930     | 3.0000    \n",
      "model.transformer.blocks.7.v_proj.weight_quantizer.zeros | 0.7917     | 0.9930     | 5.0000    \n",
      "model.transformer.blocks.3.ff_proj.weight_quantizer.zeros | 0.7882     | 0.9931     | 5.0000    \n",
      "model.transformer.blocks.2.down_smooth_scale | 0.7873     | 0.9729     | 10.1719   \n",
      "model.transformer.blocks.22.ff_out.weight_quantizer.zeros | 0.7844     | 0.9931     | 3.0000    \n",
      "model.transformer.blocks.9.attn_out.weight_quantizer.zeros | 0.7834     | 0.9931     | 4.0000    \n",
      "model.transformer.blocks.8.attn_out.weight_quantizer.zeros | 0.7776     | 0.9931     | 3.0000    \n",
      "model.transformer.blocks.15.v_proj.weight_quantizer.zeros | 0.7751     | 0.9932     | 4.0000    \n",
      "model.transformer.blocks.3.ff_out.weight_quantizer.zeros | 0.7710     | 0.9932     | 3.0000    \n",
      "model.transformer.blocks.7.attn_out.weight_quantizer.zeros | 0.7671     | 0.9932     | 3.0000    \n",
      "model.transformer.blocks.22.up_proj.weight_quantizer.zeros | 0.7625     | 0.9933     | 5.0000    \n",
      "model.transformer.blocks.27.ff_proj.weight_quantizer.zeros | 0.7588     | 0.9933     | 4.0000    \n",
      "model.transformer.blocks.11.v_proj.weight_quantizer.zeros | 0.7585     | 0.9933     | 4.0000    \n",
      "model.transformer.blocks.14.ff_proj.weight_quantizer.zeros | 0.7580     | 0.9933     | 4.0000    \n",
      "model.transformer.blocks.10.v_proj.weight_quantizer.zeros | 0.7578     | 0.9933     | 4.0000    \n",
      "model.transformer.blocks.13.attn_out.weight_quantizer.zeros | 0.7566     | 0.9933     | 3.0000    \n",
      "model.transformer.blocks.14.v_proj.weight_quantizer.zeros | 0.7512     | 0.9934     | 5.0000    \n",
      "model.transformer.blocks.28.ff_proj.weight_quantizer.zeros | 0.7494     | 0.9934     | 5.0000    \n",
      "model.transformer.blocks.25.up_proj.weight_quantizer.zeros | 0.7477     | 0.9934     | 6.0000    \n",
      "model.transformer.blocks.17.up_proj.weight_quantizer.zeros | 0.7461     | 0.9934     | 5.0000    \n",
      "model.transformer.blocks.8.v_proj.weight_quantizer.zeros | 0.7393     | 0.9935     | 4.0000    \n",
      "model.transformer.blocks.13.ff_proj.weight_quantizer.zeros | 0.7387     | 0.9934     | 4.0000    \n",
      "model.transformer.blocks.13.v_proj.weight_quantizer.zeros | 0.7380     | 0.9935     | 5.0000    \n",
      "model.transformer.blocks.9.v_proj.weight_quantizer.zeros | 0.7351     | 0.9935     | 3.0000    \n",
      "model.transformer.blocks.2.up_proj.weight_quantizer.zeros | 0.7350     | 0.9935     | 5.0000    \n",
      "model.transformer.blocks.20.up_proj.weight_quantizer.zeros | 0.7331     | 0.9935     | 6.0000    \n",
      "model.transformer.blocks.4.ff_proj.weight_quantizer.zeros | 0.7289     | 0.9936     | 5.0000    \n",
      "model.transformer.blocks.0.v_proj.weight_quantizer.zeros | 0.7280     | 0.9936     | 4.0000    \n",
      "model.transformer.blocks.23.up_proj.weight_quantizer.zeros | 0.7248     | 0.9936     | 5.0000    \n",
      "model.transformer.blocks.10.attn_out.weight_quantizer.zeros | 0.7227     | 0.9936     | 3.0000    \n",
      "model.transformer.blocks.11.attn_out.weight_quantizer.zeros | 0.7222     | 0.9936     | 3.0000    \n",
      "model.transformer.blocks.31.v_proj.weight_quantizer.zeros | 0.7202     | 0.9937     | 4.0000    \n",
      "model.transformer.blocks.12.v_proj.weight_quantizer.zeros | 0.7180     | 0.9937     | 3.0000    \n",
      "model.transformer.blocks.10.ff_proj.weight_quantizer.zeros | 0.7170     | 0.9937     | 4.0000    \n",
      "model.transformer.blocks.14.attn_out.weight_quantizer.zeros | 0.7122     | 0.9937     | 3.0000    \n",
      "model.transformer.blocks.6.ff_proj.weight_quantizer.zeros | 0.7104     | 0.9937     | 4.0000    \n",
      "model.transformer.blocks.5.ff_proj.weight_quantizer.zeros | 0.7069     | 0.9938     | 4.0000    \n",
      "model.transformer.blocks.26.up_proj.weight_quantizer.zeros | 0.7038     | 0.9938     | 4.0000    \n",
      "model.transformer.blocks.12.attn_out.weight_quantizer.zeros | 0.7021     | 0.9938     | 3.0000    \n",
      "model.transformer.blocks.21.up_proj.weight_quantizer.zeros | 0.7008     | 0.9938     | 4.0000    \n",
      "model.transformer.blocks.19.up_proj.weight_quantizer.zeros | 0.6991     | 0.9938     | 5.0000    \n",
      "model.transformer.blocks.16.up_proj.weight_quantizer.zeros | 0.6984     | 0.9939     | 5.0000    \n",
      "model.transformer.blocks.15.attn_out.weight_quantizer.zeros | 0.6965     | 0.9939     | 3.0000    \n",
      "model.transformer.blocks.15.up_proj.weight_quantizer.zeros | 0.6927     | 0.9939     | 5.0000    \n",
      "model.transformer.blocks.29.up_proj.weight_quantizer.zeros | 0.6923     | 0.9939     | 5.0000    \n",
      "model.transformer.blocks.9.ff_proj.weight_quantizer.zeros | 0.6895     | 0.9939     | 4.0000    \n",
      "model.transformer.blocks.18.up_proj.weight_quantizer.zeros | 0.6863     | 0.9940     | 4.0000    \n",
      "model.transformer.blocks.16.attn_out.weight_quantizer.zeros | 0.6846     | 0.9939     | 3.0000    \n",
      "model.transformer.blocks.30.attn_out.weight_quantizer.zeros | 0.6812     | 0.9940     | 3.0000    \n",
      "model.transformer.blocks.31.attn_out.weight_quantizer.zeros | 0.6804     | 0.9940     | 3.0000    \n",
      "model.transformer.blocks.27.v_proj.weight_quantizer.zeros | 0.6802     | 0.9940     | 3.0000    \n",
      "model.transformer.blocks.27.attn_out.weight_quantizer.zeros | 0.6792     | 0.9940     | 3.0000    \n",
      "model.transformer.blocks.17.attn_out.weight_quantizer.zeros | 0.6790     | 0.9940     | 3.0000    \n",
      "model.transformer.blocks.3.up_proj.weight_quantizer.zeros | 0.6789     | 0.9940     | 4.0000    \n",
      "model.transformer.blocks.7.ff_proj.weight_quantizer.zeros | 0.6777     | 0.9940     | 4.0000    \n",
      "model.transformer.blocks.14.up_proj.weight_quantizer.zeros | 0.6751     | 0.9940     | 4.0000    \n",
      "model.transformer.blocks.28.v_proj.weight_quantizer.zeros | 0.6748     | 0.9941     | 3.0000    \n",
      "model.transformer.blocks.8.ff_proj.weight_quantizer.zeros | 0.6746     | 0.9941     | 4.0000    \n",
      "model.transformer.blocks.19.attn_out.weight_quantizer.zeros | 0.6731     | 0.9941     | 3.0000    \n",
      "model.transformer.blocks.23.attn_out.weight_quantizer.zeros | 0.6729     | 0.9941     | 3.0000    \n",
      "model.transformer.blocks.12.up_proj.weight_quantizer.zeros | 0.6726     | 0.9941     | 4.0000    \n",
      "model.transformer.blocks.21.attn_out.weight_quantizer.zeros | 0.6714     | 0.9941     | 3.0000    \n",
      "model.transformer.blocks.11.up_proj.weight_quantizer.zeros | 0.6711     | 0.9941     | 4.0000    \n",
      "model.transformer.blocks.29.v_proj.weight_quantizer.zeros | 0.6709     | 0.9941     | 5.0000    \n",
      "model.transformer.blocks.18.attn_out.weight_quantizer.zeros | 0.6707     | 0.9941     | 3.0000    \n",
      "model.transformer.blocks.24.attn_out.weight_quantizer.zeros | 0.6694     | 0.9941     | 3.0000    \n",
      "model.transformer.blocks.30.v_proj.weight_quantizer.zeros | 0.6621     | 0.9942     | 3.0000    \n",
      "model.transformer.blocks.28.attn_out.weight_quantizer.zeros | 0.6584     | 0.9942     | 3.0000    \n",
      "model.transformer.blocks.20.attn_out.weight_quantizer.zeros | 0.6567     | 0.9942     | 3.0000    \n",
      "model.transformer.blocks.29.attn_out.weight_quantizer.zeros | 0.6558     | 0.9942     | 3.0000    \n",
      "model.transformer.blocks.7.up_proj.weight_quantizer.zeros | 0.6546     | 0.9942     | 4.0000    \n",
      "model.transformer.blocks.25.attn_out.weight_quantizer.zeros | 0.6521     | 0.9942     | 3.0000    \n",
      "model.transformer.blocks.4.up_proj.weight_quantizer.zeros | 0.6516     | 0.9942     | 4.0000    \n",
      "model.transformer.blocks.10.up_proj.weight_quantizer.zeros | 0.6513     | 0.9943     | 4.0000    \n",
      "model.transformer.blocks.9.up_proj.weight_quantizer.zeros | 0.6501     | 0.9943     | 5.0000    \n",
      "model.transformer.blocks.6.up_proj.weight_quantizer.zeros | 0.6485     | 0.9943     | 4.0000    \n",
      "model.transformer.blocks.8.up_proj.weight_quantizer.zeros | 0.6475     | 0.9943     | 4.0000    \n",
      "model.transformer.blocks.26.attn_out.weight_quantizer.zeros | 0.6472     | 0.9943     | 3.0000    \n",
      "model.transformer.blocks.13.up_proj.weight_quantizer.zeros | 0.6466     | 0.9943     | 4.0000    \n",
      "model.transformer.blocks.27.up_proj.weight_quantizer.zeros | 0.6457     | 0.9943     | 4.0000    \n",
      "model.transformer.blocks.22.attn_out.weight_quantizer.zeros | 0.6443     | 0.9943     | 3.0000    \n",
      "model.transformer.blocks.28.up_proj.weight_quantizer.zeros | 0.6426     | 0.9943     | 3.0000    \n",
      "model.transformer.blocks.5.up_proj.weight_quantizer.zeros | 0.6340     | 0.9944     | 4.0000    \n",
      "model.transformer.blocks.31.out_smooth_scale | 0.6336     | 0.9976     | 4.4219    \n",
      "model.transformer.blocks.30.out_smooth_scale | 0.5580     | 0.9972     | 2.9492    \n",
      "model.transformer.blocks.23.out_smooth_scale | 0.4692     | 0.9972     | 2.5234    \n",
      "model.transformer.blocks.29.out_smooth_scale | 0.4680     | 0.9973     | 3.0469    \n",
      "model.transformer.blocks.27.out_smooth_scale | 0.4497     | 0.9972     | 2.9375    \n",
      "model.transformer.blocks.28.out_smooth_scale | 0.4238     | 0.9975     | 3.0078    \n",
      "model.transformer.blocks.19.out_smooth_scale | 0.4213     | 0.9971     | 2.5195    \n",
      "model.transformer.blocks.22.out_smooth_scale | 0.4183     | 0.9971     | 2.5156    \n",
      "model.transformer.blocks.21.out_smooth_scale | 0.4140     | 0.9971     | 2.3828    \n",
      "model.transformer.blocks.25.out_smooth_scale | 0.4088     | 0.9974     | 2.4453    \n",
      "model.transformer.blocks.13.out_smooth_scale | 0.3984     | 0.9968     | 3.4648    \n",
      "model.transformer.blocks.26.out_smooth_scale | 0.3964     | 0.9975     | 2.5469    \n",
      "model.transformer.blocks.24.out_smooth_scale | 0.3907     | 0.9974     | 2.5547    \n",
      "model.transformer.blocks.16.out_smooth_scale | 0.3717     | 0.9969     | 2.2344    \n",
      "model.transformer.blocks.20.out_smooth_scale | 0.3647     | 0.9972     | 2.3750    \n",
      "model.transformer.blocks.10.out_smooth_scale | 0.3617     | 0.9959     | 2.8750    \n",
      "model.transformer.blocks.18.out_smooth_scale | 0.3343     | 0.9973     | 2.3320    \n",
      "model.transformer.blocks.15.out_smooth_scale | 0.3249     | 0.9968     | 3.1719    \n",
      "model.transformer.blocks.17.out_smooth_scale | 0.3170     | 0.9974     | 2.4883    \n",
      "model.transformer.blocks.14.out_smooth_scale | 0.3088     | 0.9967     | 2.6250    \n",
      "model.transformer.blocks.31.qkv_smooth_scale | 0.2852     | 0.9987     | 4.2188    \n",
      "model.transformer.blocks.12.out_smooth_scale | 0.2789     | 0.9967     | 2.4141    \n",
      "model.transformer.blocks.27.ff_out.weight | 0.2602     | 0.0000     | 4.6396    \n",
      "model.transformer.blocks.1.down_smooth_scale | 0.2493     | 0.9801     | 7.2812    \n",
      "model.transformer.blocks.30.qkv_smooth_scale | 0.2451     | 0.9989     | 2.4219    \n",
      "model.transformer.blocks.28.ff_out.weight | 0.2400     | 0.0002     | 5.0264    \n",
      "model.transformer.blocks.30.ff_out.weight | 0.2333     | 0.0004     | 5.1709    \n",
      "model.transformer.blocks.31.ff_out.weight | 0.2293     | -0.0003    | 12.9407   \n",
      "model.transformer.blocks.29.ff_out.weight | 0.2278     | -0.0000    | 6.1329    \n",
      "model.transformer.blocks.26.ff_out.weight | 0.2278     | -0.0003    | 4.5938    \n",
      "model.transformer.blocks.7.out_smooth_scale | 0.2275     | 0.9960     | 2.7695    \n",
      "model.transformer.blocks.11.out_smooth_scale | 0.2266     | 0.9965     | 2.1328    \n",
      "model.transformer.blocks.31.fc1_smooth_scale | 0.2020     | 0.9987     | 3.8867    \n",
      "model.transformer.blocks.9.out_smooth_scale | 0.1950     | 0.9962     | 2.0078    \n",
      "model.transformer.blocks.29.qkv_smooth_scale | 0.1896     | 0.9989     | 1.7031    \n",
      "model.transformer.blocks.28.qkv_smooth_scale | 0.1801     | 0.9990     | 1.8516    \n",
      "model.transformer.blocks.25.ff_out.weight | 0.1761     | -0.0001    | 4.5723    \n",
      "model.transformer.blocks.30.fc1_smooth_scale | 0.1742     | 0.9988     | 1.6562    \n",
      "model.transformer.blocks.29.fc1_smooth_scale | 0.1598     | 0.9988     | 1.3984    \n",
      "model.transformer.blocks.8.out_smooth_scale | 0.1572     | 0.9962     | 1.8398    \n",
      "model.transformer.blocks.25.qkv_smooth_scale | 0.1568     | 0.9991     | 1.5000    \n",
      "model.transformer.blocks.27.qkv_smooth_scale | 0.1557     | 0.9992     | 1.8594    \n",
      "model.transformer.blocks.6.out_smooth_scale | 0.1528     | 0.9953     | 2.4141    \n",
      "model.transformer.blocks.24.ff_out.weight | 0.1468     | -0.0002    | 5.6328    \n",
      "model.transformer.blocks.26.qkv_smooth_scale | 0.1457     | 0.9991     | 1.6172    \n",
      "model.transformer.blocks.28.fc1_smooth_scale | 0.1386     | 0.9990     | 1.5703    \n",
      "model.transformer.blocks.23.qkv_smooth_scale | 0.1347     | 0.9991     | 1.5781    \n",
      "model.transformer.blocks.24.qkv_smooth_scale | 0.1334     | 0.9991     | 1.2969    \n",
      "model.transformer.blocks.22.qkv_smooth_scale | 0.1327     | 0.9991     | 1.5781    \n",
      "model.transformer.blocks.0.out_smooth_scale | 0.1223     | 0.9857     | 2.9277    \n",
      "model.transformer.blocks.23.ff_out.weight | 0.1202     | 0.0003     | 4.6992    \n",
      "model.transformer.blocks.19.qkv_smooth_scale | 0.1160     | 0.9990     | 1.5000    \n",
      "model.transformer.blocks.13.qkv_smooth_scale | 0.1156     | 0.9988     | 1.5938    \n",
      "model.transformer.blocks.10.qkv_smooth_scale | 0.1149     | 0.9987     | 1.2969    \n",
      "model.transformer.blocks.27.fc1_smooth_scale | 0.1138     | 0.9991     | 1.2539    \n",
      "model.transformer.blocks.21.qkv_smooth_scale | 0.1134     | 0.9991     | 1.2539    \n",
      "model.transformer.blocks.5.out_smooth_scale | 0.1122     | 0.9956     | 2.6367    \n",
      "model.transformer.blocks.9.fc1_smooth_scale | 0.1120     | 0.9985     | 1.2227    \n",
      "model.transformer.blocks.8.fc1_smooth_scale | 0.1111     | 0.9985     | 1.3750    \n",
      "model.transformer.blocks.16.qkv_smooth_scale | 0.1103     | 0.9990     | 1.3555    \n",
      "model.transformer.blocks.17.qkv_smooth_scale | 0.1081     | 0.9990     | 1.4375    \n",
      "model.transformer.blocks.20.qkv_smooth_scale | 0.1077     | 0.9991     | 1.1992    \n",
      "model.transformer.blocks.26.fc1_smooth_scale | 0.1077     | 0.9991     | 1.1406    \n",
      "model.transformer.blocks.10.fc1_smooth_scale | 0.1075     | 0.9986     | 1.6406    \n",
      "model.transformer.blocks.11.fc1_smooth_scale | 0.1048     | 0.9987     | 1.4141    \n",
      "model.transformer.blocks.25.fc1_smooth_scale | 0.0994     | 0.9991     | 1.2383    \n",
      "model.transformer.blocks.12.fc1_smooth_scale | 0.0975     | 0.9987     | 1.6328    \n",
      "model.transformer.blocks.24.fc1_smooth_scale | 0.0975     | 0.9991     | 1.2617    \n",
      "model.transformer.blocks.18.qkv_smooth_scale | 0.0972     | 0.9990     | 1.0859    \n",
      "model.transformer.blocks.13.fc1_smooth_scale | 0.0968     | 0.9988     | 1.3477    \n",
      "model.transformer.blocks.7.fc1_smooth_scale | 0.0958     | 0.9986     | 1.2227    \n",
      "model.transformer.blocks.15.qkv_smooth_scale | 0.0927     | 0.9989     | 1.3672    \n",
      "model.transformer.blocks.14.qkv_smooth_scale | 0.0921     | 0.9989     | 1.2734    \n",
      "model.transformer.blocks.23.fc1_smooth_scale | 0.0911     | 0.9991     | 1.1758    \n",
      "model.transformer.blocks.14.fc1_smooth_scale | 0.0907     | 0.9988     | 1.1172    \n",
      "model.transformer.blocks.12.qkv_smooth_scale | 0.0902     | 0.9987     | 1.5430    \n",
      "model.transformer.blocks.22.ff_out.weight | 0.0894     | 0.0003     | 3.6367    \n",
      "model.transformer.blocks.31.attn_out.weight | 0.0886     | -0.0000    | 3.6152    \n",
      "model.transformer.blocks.6.fc1_smooth_scale | 0.0879     | 0.9985     | 1.2969    \n",
      "model.transformer.blocks.22.fc1_smooth_scale | 0.0851     | 0.9991     | 1.3047    \n",
      "model.transformer.blocks.16.fc1_smooth_scale | 0.0849     | 0.9989     | 1.1602    \n",
      "model.transformer.blocks.19.fc1_smooth_scale | 0.0837     | 0.9990     | 1.1250    \n",
      "model.transformer.blocks.15.fc1_smooth_scale | 0.0837     | 0.9989     | 1.1602    \n",
      "model.transformer.blocks.21.fc1_smooth_scale | 0.0829     | 0.9990     | 1.1562    \n",
      "model.transformer.blocks.17.fc1_smooth_scale | 0.0813     | 0.9990     | 1.4141    \n",
      "model.transformer.blocks.20.fc1_smooth_scale | 0.0812     | 0.9990     | 1.2578    \n",
      "model.transformer.blocks.18.fc1_smooth_scale | 0.0803     | 0.9990     | 1.2773    \n",
      "model.transformer.blocks.7.qkv_smooth_scale | 0.0791     | 0.9987     | 1.2500    \n",
      "model.transformer.blocks.11.qkv_smooth_scale | 0.0768     | 0.9987     | 1.3633    \n",
      "model.transformer.blocks.30.attn_out.weight | 0.0760     | 0.0002     | 2.9209    \n",
      "model.transformer.blocks.21.ff_out.weight | 0.0760     | 0.0001     | 3.4902    \n",
      "model.transformer.blocks.9.qkv_smooth_scale | 0.0730     | 0.9986     | 1.0664    \n",
      "model.transformer.blocks.5.fc1_smooth_scale | 0.0703     | 0.9986     | 1.1953    \n",
      "model.transformer.blocks.2.out_smooth_scale | 0.0687     | 0.9923     | 1.8242    \n",
      "model.transformer.blocks.20.ff_out.weight | 0.0650     | 0.0003     | 3.2607    \n",
      "model.transformer.blocks.8.qkv_smooth_scale | 0.0648     | 0.9986     | 0.8906    \n",
      "model.transformer.blocks.19.ff_out.weight | 0.0642     | 0.0000     | 4.3491    \n",
      "model.transformer.blocks.29.attn_out.weight | 0.0592     | 0.0000     | 2.9727    \n",
      "model.transformer.blocks.18.ff_out.weight | 0.0586     | -0.0002    | 3.1016    \n",
      "model.transformer.blocks.13.ff_out.weight | 0.0572     | 0.0003     | 3.3750    \n",
      "model.transformer.blocks.17.ff_out.weight | 0.0571     | 0.0001     | 5.2634    \n",
      "model.transformer.blocks.14.ff_out.weight | 0.0560     | 0.0002     | 6.7856    \n",
      "model.transformer.blocks.10.ff_out.weight | 0.0545     | -0.0001    | 2.3838    \n",
      "model.transformer.blocks.16.ff_out.weight | 0.0532     | -0.0001    | 4.1764    \n",
      "model.transformer.blocks.11.ff_out.weight | 0.0531     | 0.0000     | 2.6455    \n",
      "model.transformer.blocks.4.out_smooth_scale | 0.0524     | 0.9965     | 1.1094    \n",
      "model.transformer.blocks.12.ff_out.weight | 0.0514     | 0.0000     | 3.2427    \n",
      "model.transformer.blocks.28.attn_out.weight | 0.0511     | -0.0002    | 2.9434    \n",
      "model.transformer.blocks.9.ff_out.weight | 0.0503     | 0.0002     | 4.0286    \n",
      "model.transformer.blocks.27.attn_out.weight | 0.0494     | -0.0005    | 2.7363    \n",
      "model.transformer.blocks.15.ff_out.weight | 0.0490     | -0.0005    | 9.0054    \n",
      "model.transformer.blocks.8.ff_out.weight | 0.0482     | 0.0002     | 2.7184    \n",
      "model.transformer.blocks.4.fc1_smooth_scale | 0.0465     | 0.9988     | 0.9805    \n",
      "model.transformer.blocks.26.attn_out.weight | 0.0458     | 0.0002     | 2.5693    \n",
      "model.transformer.blocks.6.qkv_smooth_scale | 0.0443     | 0.9987     | 0.9570    \n",
      "model.transformer.blocks.7.ff_out.weight | 0.0403     | -0.0000    | 2.3125    \n",
      "model.transformer.blocks.25.attn_out.weight | 0.0383     | -0.0000    | 2.3018    \n",
      "model.transformer.blocks.6.ff_out.weight | 0.0379     | 0.0002     | 4.9062    \n",
      "model.transformer.blocks.0.down_smooth_scale | 0.0372     | 0.9917     | 3.7148    \n",
      "model.transformer.blocks.5.qkv_smooth_scale | 0.0351     | 0.9988     | 0.7852    \n",
      "model.transformer.blocks.31.ff_proj.weight | 0.0337     | 0.0007     | 4.2420    \n",
      "model.transformer.blocks.24.attn_out.weight | 0.0327     | -0.0003    | 2.2695    \n",
      "model.transformer.blocks.30.ff_proj.weight | 0.0323     | -0.0012    | 2.7905    \n",
      "model.transformer.blocks.23.attn_out.weight | 0.0305     | -0.0002    | 2.0420    \n",
      "model.transformer.blocks.22.attn_out.weight | 0.0304     | 0.0000     | 1.6006    \n",
      "model.transformer.blocks.29.ff_proj.weight | 0.0300     | 0.0006     | 2.4290    \n",
      "model.transformer.blocks.3.out_smooth_scale | 0.0289     | 0.9964     | 1.3340    \n",
      "model.transformer.blocks.28.ff_proj.weight | 0.0285     | -0.0013    | 1.5375    \n",
      "model.transformer.blocks.5.ff_out.weight | 0.0275     | 0.0001     | 2.2896    \n",
      "model.transformer.blocks.21.attn_out.weight | 0.0265     | -0.0007    | 1.7275    \n",
      "model.transformer.blocks.31.q_proj.weight | 0.0265     | 0.0000     | 1.7743    \n",
      "model.transformer.blocks.31.k_proj.weight | 0.0264     | 0.0001     | 1.8939    \n",
      "model.transformer.blocks.30.k_proj.weight | 0.0260     | 0.0002     | 2.5607    \n",
      "model.transformer.blocks.30.q_proj.weight | 0.0258     | -0.0002    | 1.7109    \n",
      "model.transformer.blocks.27.ff_proj.weight | 0.0255     | 0.0002     | 2.2776    \n",
      "model.transformer.blocks.28.k_proj.weight | 0.0255     | -0.0004    | 2.0073    \n",
      "model.transformer.blocks.28.q_proj.weight | 0.0254     | -0.0003    | 1.5175    \n",
      "model.transformer.blocks.1.out_smooth_scale | 0.0252     | 0.9957     | 0.8564    \n",
      "model.transformer.blocks.29.k_proj.weight | 0.0251     | 0.0007     | 1.7324    \n",
      "model.transformer.blocks.29.q_proj.weight | 0.0249     | 0.0003     | 1.4092    \n",
      "model.transformer.blocks.20.attn_out.weight | 0.0247     | -0.0000    | 1.9126    \n",
      "model.transformer.blocks.27.k_proj.weight | 0.0245     | -0.0001    | 2.1242    \n",
      "model.transformer.blocks.27.q_proj.weight | 0.0242     | 0.0001     | 1.4790    \n",
      "model.transformer.blocks.19.attn_out.weight | 0.0241     | 0.0003     | 2.0254    \n",
      "model.transformer.blocks.3.fc1_smooth_scale | 0.0239     | 0.9990     | 0.9238    \n",
      "model.transformer.blocks.25.k_proj.weight | 0.0234     | 0.0000     | 3.0044    \n",
      "model.transformer.blocks.26.k_proj.weight | 0.0232     | -0.0004    | 2.8118    \n",
      "model.transformer.blocks.26.ff_proj.weight | 0.0232     | 0.0005     | 3.1228    \n",
      "model.transformer.blocks.25.q_proj.weight | 0.0232     | -0.0003    | 1.7125    \n",
      "model.transformer.blocks.26.q_proj.weight | 0.0230     | -0.0003    | 2.0364    \n",
      "model.transformer.blocks.4.ff_out.weight | 0.0225     | 0.0001     | 2.3457    \n",
      "model.transformer.blocks.22.k_proj.weight | 0.0221     | 0.0002     | 2.5334    \n",
      "model.transformer.blocks.18.attn_out.weight | 0.0220     | 0.0007     | 1.4331    \n",
      "model.transformer.blocks.22.q_proj.weight | 0.0218     | 0.0007     | 1.3191    \n",
      "model.transformer.blocks.23.k_proj.weight | 0.0217     | -0.0004    | 3.0503    \n",
      "model.transformer.blocks.19.k_proj.weight | 0.0217     | 0.0011     | 2.5710    \n",
      "model.transformer.blocks.24.k_proj.weight | 0.0217     | -0.0006    | 2.6739    \n",
      "model.transformer.blocks.16.attn_out.weight | 0.0215     | -0.0003    | 1.8315    \n",
      "model.transformer.blocks.23.q_proj.weight | 0.0214     | -0.0000    | 1.4114    \n",
      "model.transformer.blocks.19.q_proj.weight | 0.0214     | 0.0004     | 1.3463    \n",
      "model.transformer.blocks.24.q_proj.weight | 0.0214     | -0.0000    | 1.3712    \n",
      "model.transformer.blocks.17.attn_out.weight | 0.0213     | 0.0001     | 1.5420    \n",
      "model.transformer.blocks.21.k_proj.weight | 0.0213     | -0.0005    | 2.4850    \n",
      "model.transformer.blocks.16.k_proj.weight | 0.0210     | 0.0009     | 2.4907    \n",
      "model.transformer.blocks.21.q_proj.weight | 0.0210     | -0.0002    | 1.3969    \n",
      "model.transformer.blocks.16.q_proj.weight | 0.0208     | 0.0016     | 1.3013    \n",
      "model.transformer.blocks.17.k_proj.weight | 0.0206     | -0.0001    | 2.9688    \n",
      "model.transformer.blocks.13.k_proj.weight | 0.0206     | -0.0006    | 2.8528    \n",
      "model.transformer.blocks.25.ff_proj.weight | 0.0205     | 0.0001     | 2.4785    \n",
      "model.transformer.blocks.20.k_proj.weight | 0.0204     | -0.0011    | 2.7939    \n",
      "model.transformer.blocks.13.q_proj.weight | 0.0203     | -0.0005    | 1.7266    \n",
      "model.transformer.blocks.17.q_proj.weight | 0.0203     | 0.0005     | 1.3508    \n",
      "model.transformer.blocks.20.q_proj.weight | 0.0201     | -0.0008    | 1.4840    \n",
      "model.transformer.blocks.18.k_proj.weight | 0.0197     | -0.0003    | 2.4436    \n",
      "model.transformer.blocks.18.q_proj.weight | 0.0192     | 0.0000     | 1.3574    \n",
      "model.transformer.blocks.13.attn_out.weight | 0.0190     | -0.0001    | 1.8413    \n",
      "model.transformer.blocks.10.k_proj.weight | 0.0187     | 0.0000     | 3.8781    \n",
      "model.transformer.blocks.15.k_proj.weight | 0.0186     | -0.0004    | 3.6596    \n",
      "model.transformer.blocks.10.q_proj.weight | 0.0186     | 0.0003     | 1.8895    \n",
      "model.transformer.blocks.15.q_proj.weight | 0.0183     | -0.0001    | 1.8323    \n",
      "model.transformer.blocks.24.ff_proj.weight | 0.0182     | -0.0002    | 2.3236    \n",
      "model.transformer.blocks.14.k_proj.weight | 0.0180     | -0.0006    | 3.3520    \n",
      "model.transformer.blocks.14.q_proj.weight | 0.0177     | -0.0003    | 1.7857    \n",
      "model.transformer.blocks.23.ff_proj.weight | 0.0177     | -0.0006    | 2.4688    \n",
      "model.transformer.blocks.14.ff_proj.weight | 0.0175     | 0.0001     | 2.1406    \n",
      "model.transformer.blocks.13.ff_proj.weight | 0.0175     | 0.0002     | 1.8180    \n",
      "model.transformer.blocks.15.attn_out.weight | 0.0174     | -0.0003    | 1.4719    \n",
      "model.transformer.blocks.16.ff_proj.weight | 0.0173     | 0.0006     | 1.9287    \n",
      "model.transformer.blocks.22.ff_proj.weight | 0.0171     | -0.0009    | 2.3527    \n",
      "model.transformer.blocks.17.ff_proj.weight | 0.0170     | -0.0002    | 2.1743    \n",
      "model.transformer.blocks.11.ff_proj.weight | 0.0170     | -0.0003    | 1.5760    \n",
      "model.transformer.blocks.4.qkv_smooth_scale | 0.0169     | 0.9990     | 0.8320    \n",
      "model.transformer.blocks.18.ff_proj.weight | 0.0168     | -0.0001    | 1.6447    \n",
      "model.transformer.blocks.21.ff_proj.weight | 0.0167     | -0.0001    | 2.9364    \n",
      "model.transformer.blocks.10.ff_proj.weight | 0.0167     | -0.0003    | 1.4518    \n",
      "model.transformer.blocks.19.ff_proj.weight | 0.0166     | 0.0004     | 1.8036    \n",
      "model.transformer.blocks.14.attn_out.weight | 0.0163     | -0.0002    | 1.3677    \n",
      "model.transformer.blocks.20.ff_proj.weight | 0.0162     | 0.0001     | 1.7109    \n",
      "model.transformer.blocks.12.ff_proj.weight | 0.0162     | 0.0004     | 1.7389    \n",
      "model.transformer.blocks.15.ff_proj.weight | 0.0161     | -0.0002    | 2.0940    \n",
      "model.transformer.blocks.9.ff_proj.weight | 0.0161     | -0.0003    | 1.3308    \n",
      "model.transformer.blocks.24.ff_out.act_quantizer.R | 0.0161     | -0.0298    | 1.2961    \n",
      "model.transformer.blocks.24.ff_out.weight_quantizer.R | 0.0161     | -0.0298    | 1.2961    \n",
      "model.transformer.blocks.12.v_proj.weight_quantizer.R | 0.0161     | -0.0266    | 1.2435    \n",
      "model.transformer.blocks.12.v_proj.act_quantizer.R | 0.0161     | -0.0266    | 1.2435    \n",
      "model.transformer.blocks.12.q_proj.weight_quantizer.R | 0.0161     | -0.0266    | 1.2435    \n",
      "model.transformer.blocks.12.k_proj.act_quantizer.R | 0.0161     | -0.0266    | 1.2435    \n",
      "model.transformer.blocks.12.q_proj.act_quantizer.R | 0.0161     | -0.0266    | 1.2435    \n",
      "model.transformer.blocks.12.k_proj.weight_quantizer.R | 0.0161     | -0.0266    | 1.2435    \n",
      "model.transformer.blocks.15.ff_out.act_quantizer.R | 0.0161     | -0.0267    | 1.2798    \n",
      "model.transformer.blocks.15.ff_out.weight_quantizer.R | 0.0161     | -0.0267    | 1.2798    \n",
      "model.transformer.blocks.25.k_proj.act_quantizer.R | 0.0160     | -0.0212    | 1.2494    \n",
      "model.transformer.blocks.25.q_proj.act_quantizer.R | 0.0160     | -0.0212    | 1.2494    \n",
      "model.transformer.blocks.25.k_proj.weight_quantizer.R | 0.0160     | -0.0212    | 1.2494    \n",
      "model.transformer.blocks.25.v_proj.weight_quantizer.R | 0.0160     | -0.0212    | 1.2494    \n",
      "model.transformer.blocks.25.v_proj.act_quantizer.R | 0.0160     | -0.0212    | 1.2494    \n",
      "model.transformer.blocks.25.q_proj.weight_quantizer.R | 0.0160     | -0.0212    | 1.2494    \n",
      "model.transformer.blocks.16.ff_out.weight_quantizer.R | 0.0160     | -0.0196    | 1.2812    \n",
      "model.transformer.blocks.16.ff_out.act_quantizer.R | 0.0160     | -0.0196    | 1.2812    \n",
      "model.transformer.blocks.4.attn_out.act_quantizer.R | 0.0160     | -0.0182    | 1.2369    \n",
      "model.transformer.blocks.4.attn_out.weight_quantizer.R | 0.0160     | -0.0182    | 1.2369    \n",
      "model.transformer.blocks.5.up_proj.weight_quantizer.R | 0.0159     | -0.0189    | 1.2440    \n",
      "model.transformer.blocks.5.up_proj.act_quantizer.R | 0.0159     | -0.0189    | 1.2440    \n",
      "model.transformer.blocks.5.ff_proj.weight_quantizer.R | 0.0159     | -0.0189    | 1.2440    \n",
      "model.transformer.blocks.5.ff_proj.act_quantizer.R | 0.0159     | -0.0189    | 1.2440    \n",
      "model.transformer.blocks.4.up_proj.act_quantizer.R | 0.0159     | -0.0180    | 1.3359    \n",
      "model.transformer.blocks.4.up_proj.weight_quantizer.R | 0.0159     | -0.0180    | 1.3359    \n",
      "model.transformer.blocks.4.ff_proj.act_quantizer.R | 0.0159     | -0.0180    | 1.3359    \n",
      "model.transformer.blocks.4.ff_proj.weight_quantizer.R | 0.0159     | -0.0180    | 1.3359    \n",
      "model.transformer.blocks.1.k_proj.weight_quantizer.R | 0.0159     | -0.0156    | 1.3140    \n",
      "model.transformer.blocks.1.v_proj.weight_quantizer.R | 0.0159     | -0.0156    | 1.3140    \n",
      "model.transformer.blocks.1.q_proj.weight_quantizer.R | 0.0159     | -0.0156    | 1.3140    \n",
      "model.transformer.blocks.1.q_proj.act_quantizer.R | 0.0159     | -0.0156    | 1.3140    \n",
      "model.transformer.blocks.1.v_proj.act_quantizer.R | 0.0159     | -0.0156    | 1.3140    \n",
      "model.transformer.blocks.1.k_proj.act_quantizer.R | 0.0159     | -0.0156    | 1.3140    \n",
      "model.transformer.blocks.9.attn_out.act_quantizer.R | 0.0159     | -0.0136    | 1.2463    \n",
      "model.transformer.blocks.9.attn_out.weight_quantizer.R | 0.0159     | -0.0136    | 1.2463    \n",
      "model.transformer.blocks.28.ff_proj.act_quantizer.R | 0.0159     | -0.0147    | 1.2678    \n",
      "model.transformer.blocks.28.ff_proj.weight_quantizer.R | 0.0159     | -0.0147    | 1.2678    \n",
      "model.transformer.blocks.28.up_proj.act_quantizer.R | 0.0159     | -0.0147    | 1.2678    \n",
      "model.transformer.blocks.28.up_proj.weight_quantizer.R | 0.0159     | -0.0147    | 1.2678    \n",
      "model.transformer.blocks.31.up_proj.weight_quantizer.R | 0.0159     | -0.0138    | 1.2534    \n",
      "model.transformer.blocks.31.ff_proj.weight_quantizer.R | 0.0159     | -0.0138    | 1.2534    \n",
      "model.transformer.blocks.31.ff_proj.act_quantizer.R | 0.0159     | -0.0138    | 1.2534    \n",
      "model.transformer.blocks.31.up_proj.act_quantizer.R | 0.0159     | -0.0138    | 1.2534    \n",
      "model.transformer.blocks.25.ff_out.act_quantizer.R | 0.0159     | -0.0151    | 1.2563    \n",
      "model.transformer.blocks.25.ff_out.weight_quantizer.R | 0.0159     | -0.0151    | 1.2563    \n",
      "model.transformer.blocks.6.ff_proj.weight_quantizer.R | 0.0159     | -0.0152    | 1.2788    \n",
      "model.transformer.blocks.6.ff_proj.act_quantizer.R | 0.0159     | -0.0152    | 1.2788    \n",
      "model.transformer.blocks.6.up_proj.act_quantizer.R | 0.0159     | -0.0152    | 1.2788    \n",
      "model.transformer.blocks.6.up_proj.weight_quantizer.R | 0.0159     | -0.0152    | 1.2788    \n",
      "model.transformer.blocks.7.attn_out.act_quantizer.R | 0.0159     | -0.0119    | 1.3604    \n",
      "model.transformer.blocks.7.attn_out.weight_quantizer.R | 0.0159     | -0.0119    | 1.3604    \n",
      "model.transformer.blocks.14.attn_out.act_quantizer.R | 0.0159     | -0.0122    | 1.2866    \n",
      "model.transformer.blocks.14.attn_out.weight_quantizer.R | 0.0159     | -0.0122    | 1.2866    \n",
      "model.transformer.blocks.18.ff_proj.act_quantizer.R | 0.0159     | -0.0109    | 1.2268    \n",
      "model.transformer.blocks.18.up_proj.act_quantizer.R | 0.0159     | -0.0109    | 1.2268    \n",
      "model.transformer.blocks.18.up_proj.weight_quantizer.R | 0.0159     | -0.0109    | 1.2268    \n",
      "model.transformer.blocks.18.ff_proj.weight_quantizer.R | 0.0159     | -0.0109    | 1.2268    \n",
      "model.transformer.blocks.16.ff_proj.act_quantizer.R | 0.0159     | -0.0132    | 1.2949    \n",
      "model.transformer.blocks.16.up_proj.weight_quantizer.R | 0.0159     | -0.0132    | 1.2949    \n",
      "model.transformer.blocks.16.up_proj.act_quantizer.R | 0.0159     | -0.0132    | 1.2949    \n",
      "model.transformer.blocks.16.ff_proj.weight_quantizer.R | 0.0159     | -0.0132    | 1.2949    \n",
      "model.transformer.blocks.16.v_proj.act_quantizer.R | 0.0158     | -0.0121    | 1.2186    \n",
      "model.transformer.blocks.16.v_proj.weight_quantizer.R | 0.0158     | -0.0121    | 1.2186    \n",
      "model.transformer.blocks.16.k_proj.weight_quantizer.R | 0.0158     | -0.0121    | 1.2186    \n",
      "model.transformer.blocks.16.q_proj.act_quantizer.R | 0.0158     | -0.0121    | 1.2186    \n",
      "model.transformer.blocks.16.q_proj.weight_quantizer.R | 0.0158     | -0.0121    | 1.2186    \n",
      "model.transformer.blocks.16.k_proj.act_quantizer.R | 0.0158     | -0.0121    | 1.2186    \n",
      "model.transformer.blocks.6.q_proj.act_quantizer.R | 0.0158     | -0.0092    | 1.2173    \n",
      "model.transformer.blocks.6.q_proj.weight_quantizer.R | 0.0158     | -0.0092    | 1.2173    \n",
      "model.transformer.blocks.6.k_proj.weight_quantizer.R | 0.0158     | -0.0092    | 1.2173    \n",
      "model.transformer.blocks.6.k_proj.act_quantizer.R | 0.0158     | -0.0092    | 1.2173    \n",
      "model.transformer.blocks.6.v_proj.weight_quantizer.R | 0.0158     | -0.0092    | 1.2173    \n",
      "model.transformer.blocks.6.v_proj.act_quantizer.R | 0.0158     | -0.0092    | 1.2173    \n",
      "model.transformer.blocks.4.k_proj.weight_quantizer.R | 0.0158     | -0.0106    | 1.2566    \n",
      "model.transformer.blocks.4.q_proj.act_quantizer.R | 0.0158     | -0.0106    | 1.2566    \n",
      "model.transformer.blocks.4.q_proj.weight_quantizer.R | 0.0158     | -0.0106    | 1.2566    \n",
      "model.transformer.blocks.4.k_proj.act_quantizer.R | 0.0158     | -0.0106    | 1.2566    \n",
      "model.transformer.blocks.4.v_proj.weight_quantizer.R | 0.0158     | -0.0106    | 1.2566    \n",
      "model.transformer.blocks.4.v_proj.act_quantizer.R | 0.0158     | -0.0106    | 1.2566    \n",
      "model.transformer.blocks.27.ff_proj.weight_quantizer.R | 0.0158     | -0.0108    | 1.2246    \n",
      "model.transformer.blocks.27.up_proj.act_quantizer.R | 0.0158     | -0.0108    | 1.2246    \n",
      "model.transformer.blocks.27.ff_proj.act_quantizer.R | 0.0158     | -0.0108    | 1.2246    \n",
      "model.transformer.blocks.27.up_proj.weight_quantizer.R | 0.0158     | -0.0108    | 1.2246    \n",
      "model.transformer.blocks.6.attn_out.act_quantizer.R | 0.0158     | -0.0088    | 1.2188    \n",
      "model.transformer.blocks.6.attn_out.weight_quantizer.R | 0.0158     | -0.0088    | 1.2188    \n",
      "model.transformer.blocks.10.q_proj.act_quantizer.R | 0.0158     | -0.0074    | 1.2279    \n",
      "model.transformer.blocks.10.v_proj.weight_quantizer.R | 0.0158     | -0.0074    | 1.2279    \n",
      "model.transformer.blocks.10.k_proj.weight_quantizer.R | 0.0158     | -0.0074    | 1.2279    \n",
      "model.transformer.blocks.10.v_proj.act_quantizer.R | 0.0158     | -0.0074    | 1.2279    \n",
      "model.transformer.blocks.10.k_proj.act_quantizer.R | 0.0158     | -0.0074    | 1.2279    \n",
      "model.transformer.blocks.10.q_proj.weight_quantizer.R | 0.0158     | -0.0074    | 1.2279    \n",
      "model.transformer.blocks.11.k_proj.act_quantizer.R | 0.0158     | -0.0106    | 1.2285    \n",
      "model.transformer.blocks.11.k_proj.weight_quantizer.R | 0.0158     | -0.0106    | 1.2285    \n",
      "model.transformer.blocks.11.v_proj.act_quantizer.R | 0.0158     | -0.0106    | 1.2285    \n",
      "model.transformer.blocks.11.q_proj.weight_quantizer.R | 0.0158     | -0.0106    | 1.2285    \n",
      "model.transformer.blocks.11.q_proj.act_quantizer.R | 0.0158     | -0.0106    | 1.2285    \n",
      "model.transformer.blocks.11.v_proj.weight_quantizer.R | 0.0158     | -0.0106    | 1.2285    \n",
      "model.transformer.blocks.0.up_proj.act_quantizer.R | 0.0158     | -0.0100    | 1.2417    \n",
      "model.transformer.blocks.0.ff_proj.weight_quantizer.R | 0.0158     | -0.0100    | 1.2417    \n",
      "model.transformer.blocks.0.up_proj.weight_quantizer.R | 0.0158     | -0.0100    | 1.2417    \n",
      "model.transformer.blocks.0.ff_proj.act_quantizer.R | 0.0158     | -0.0100    | 1.2417    \n",
      "model.transformer.blocks.22.q_proj.act_quantizer.R | 0.0158     | -0.0075    | 1.1982    \n",
      "model.transformer.blocks.22.k_proj.weight_quantizer.R | 0.0158     | -0.0075    | 1.1982    \n",
      "model.transformer.blocks.22.v_proj.act_quantizer.R | 0.0158     | -0.0075    | 1.1982    \n",
      "model.transformer.blocks.22.v_proj.weight_quantizer.R | 0.0158     | -0.0075    | 1.1982    \n",
      "model.transformer.blocks.22.q_proj.weight_quantizer.R | 0.0158     | -0.0075    | 1.1982    \n",
      "model.transformer.blocks.22.k_proj.act_quantizer.R | 0.0158     | -0.0075    | 1.1982    \n",
      "model.transformer.blocks.1.ff_proj.weight_quantizer.R | 0.0158     | -0.0081    | 1.2391    \n",
      "model.transformer.blocks.1.up_proj.act_quantizer.R | 0.0158     | -0.0081    | 1.2391    \n",
      "model.transformer.blocks.1.up_proj.weight_quantizer.R | 0.0158     | -0.0081    | 1.2391    \n",
      "model.transformer.blocks.1.ff_proj.act_quantizer.R | 0.0158     | -0.0081    | 1.2391    \n",
      "model.transformer.blocks.17.ff_out.act_quantizer.R | 0.0158     | -0.0069    | 1.2690    \n",
      "model.transformer.blocks.17.ff_out.weight_quantizer.R | 0.0158     | -0.0069    | 1.2690    \n",
      "model.transformer.blocks.26.ff_out.weight_quantizer.R | 0.0158     | -0.0077    | 1.3086    \n",
      "model.transformer.blocks.26.ff_out.act_quantizer.R | 0.0158     | -0.0077    | 1.3086    \n",
      "model.transformer.blocks.31.attn_out.weight_quantizer.R | 0.0158     | -0.0084    | 1.2384    \n",
      "model.transformer.blocks.31.attn_out.act_quantizer.R | 0.0158     | -0.0084    | 1.2384    \n",
      "model.transformer.blocks.30.up_proj.act_quantizer.R | 0.0158     | -0.0051    | 1.2583    \n",
      "model.transformer.blocks.30.up_proj.weight_quantizer.R | 0.0158     | -0.0051    | 1.2583    \n",
      "model.transformer.blocks.30.ff_proj.weight_quantizer.R | 0.0158     | -0.0051    | 1.2583    \n",
      "model.transformer.blocks.30.ff_proj.act_quantizer.R | 0.0158     | -0.0051    | 1.2583    \n",
      "model.transformer.blocks.20.ff_out.weight_quantizer.R | 0.0158     | -0.0069    | 1.2019    \n",
      "model.transformer.blocks.20.ff_out.act_quantizer.R | 0.0158     | -0.0069    | 1.2019    \n",
      "model.transformer.blocks.3.up_proj.act_quantizer.R | 0.0158     | -0.0081    | 1.2510    \n",
      "model.transformer.blocks.3.ff_proj.weight_quantizer.R | 0.0158     | -0.0081    | 1.2510    \n",
      "model.transformer.blocks.3.up_proj.weight_quantizer.R | 0.0158     | -0.0081    | 1.2510    \n",
      "model.transformer.blocks.3.ff_proj.act_quantizer.R | 0.0158     | -0.0081    | 1.2510    \n",
      "model.transformer.blocks.12.ff_out.act_quantizer.R | 0.0158     | -0.0055    | 1.2205    \n",
      "model.transformer.blocks.12.ff_out.weight_quantizer.R | 0.0158     | -0.0055    | 1.2205    \n",
      "model.transformer.blocks.30.v_proj.weight_quantizer.R | 0.0158     | -0.0051    | 1.2681    \n",
      "model.transformer.blocks.30.k_proj.act_quantizer.R | 0.0158     | -0.0051    | 1.2681    \n",
      "model.transformer.blocks.30.q_proj.weight_quantizer.R | 0.0158     | -0.0051    | 1.2681    \n",
      "model.transformer.blocks.30.q_proj.act_quantizer.R | 0.0158     | -0.0051    | 1.2681    \n",
      "model.transformer.blocks.30.k_proj.weight_quantizer.R | 0.0158     | -0.0051    | 1.2681    \n",
      "model.transformer.blocks.30.v_proj.act_quantizer.R | 0.0158     | -0.0051    | 1.2681    \n",
      "model.transformer.blocks.27.ff_out.act_quantizer.R | 0.0158     | -0.0085    | 1.2603    \n",
      "model.transformer.blocks.27.ff_out.weight_quantizer.R | 0.0158     | -0.0085    | 1.2603    \n",
      "model.transformer.blocks.14.ff_proj.weight_quantizer.R | 0.0158     | -0.0054    | 1.2600    \n",
      "model.transformer.blocks.14.up_proj.act_quantizer.R | 0.0158     | -0.0054    | 1.2600    \n",
      "model.transformer.blocks.14.up_proj.weight_quantizer.R | 0.0158     | -0.0054    | 1.2600    \n",
      "model.transformer.blocks.14.ff_proj.act_quantizer.R | 0.0158     | -0.0054    | 1.2600    \n",
      "model.transformer.blocks.15.attn_out.act_quantizer.R | 0.0158     | -0.0033    | 1.2949    \n",
      "model.transformer.blocks.15.attn_out.weight_quantizer.R | 0.0158     | -0.0033    | 1.2949    \n",
      "model.transformer.blocks.23.q_proj.weight_quantizer.R | 0.0158     | -0.0037    | 1.2810    \n",
      "model.transformer.blocks.23.k_proj.act_quantizer.R | 0.0158     | -0.0037    | 1.2810    \n",
      "model.transformer.blocks.23.k_proj.weight_quantizer.R | 0.0158     | -0.0037    | 1.2810    \n",
      "model.transformer.blocks.23.v_proj.act_quantizer.R | 0.0158     | -0.0037    | 1.2810    \n",
      "model.transformer.blocks.23.v_proj.weight_quantizer.R | 0.0158     | -0.0037    | 1.2810    \n",
      "model.transformer.blocks.23.q_proj.act_quantizer.R | 0.0158     | -0.0037    | 1.2810    \n",
      "model.transformer.blocks.1.attn_out.weight_quantizer.R | 0.0158     | -0.0052    | 1.2107    \n",
      "model.transformer.blocks.1.attn_out.act_quantizer.R | 0.0158     | -0.0052    | 1.2107    \n",
      "model.transformer.blocks.11.up_proj.weight_quantizer.R | 0.0157     | -0.0041    | 1.2344    \n",
      "model.transformer.blocks.11.up_proj.act_quantizer.R | 0.0157     | -0.0041    | 1.2344    \n",
      "model.transformer.blocks.11.ff_proj.weight_quantizer.R | 0.0157     | -0.0041    | 1.2344    \n",
      "model.transformer.blocks.11.ff_proj.act_quantizer.R | 0.0157     | -0.0041    | 1.2344    \n",
      "model.transformer.blocks.28.attn_out.act_quantizer.R | 0.0157     | -0.0047    | 1.2418    \n",
      "model.transformer.blocks.28.attn_out.weight_quantizer.R | 0.0157     | -0.0047    | 1.2418    \n",
      "model.transformer.blocks.17.attn_out.act_quantizer.R | 0.0157     | -0.0064    | 1.2325    \n",
      "model.transformer.blocks.17.attn_out.weight_quantizer.R | 0.0157     | -0.0064    | 1.2325    \n",
      "model.transformer.blocks.13.attn_out.weight_quantizer.R | 0.0157     | -0.0041    | 1.1840    \n",
      "model.transformer.blocks.13.attn_out.act_quantizer.R | 0.0157     | -0.0041    | 1.1840    \n",
      "model.transformer.blocks.28.ff_out.weight_quantizer.R | 0.0157     | -0.0051    | 1.2646    \n",
      "model.transformer.blocks.28.ff_out.act_quantizer.R | 0.0157     | -0.0051    | 1.2646    \n",
      "model.transformer.blocks.0.attn_out.weight_quantizer.R | 0.0157     | -0.0037    | 1.2408    \n",
      "model.transformer.blocks.0.attn_out.act_quantizer.R | 0.0157     | -0.0037    | 1.2408    \n",
      "model.transformer.blocks.8.ff_proj.weight | 0.0157     | 0.0000     | 1.2171    \n",
      "model.transformer.blocks.14.ff_out.act_quantizer.R | 0.0157     | -0.0058    | 1.2064    \n",
      "model.transformer.blocks.14.ff_out.weight_quantizer.R | 0.0157     | -0.0058    | 1.2064    \n",
      "model.transformer.blocks.22.attn_out.weight_quantizer.R | 0.0157     | -0.0041    | 1.2211    \n",
      "model.transformer.blocks.22.attn_out.act_quantizer.R | 0.0157     | -0.0041    | 1.2211    \n",
      "model.transformer.blocks.19.ff_out.act_quantizer.R | 0.0157     | -0.0034    | 1.2202    \n",
      "model.transformer.blocks.19.ff_out.weight_quantizer.R | 0.0157     | -0.0034    | 1.2202    \n",
      "model.transformer.blocks.3.ff_out.act_quantizer.R | 0.0157     | -0.0027    | 1.2778    \n",
      "model.transformer.blocks.3.ff_out.weight_quantizer.R | 0.0157     | -0.0027    | 1.2778    \n",
      "model.transformer.blocks.2.attn_out.act_quantizer.R | 0.0157     | -0.0051    | 1.2920    \n",
      "model.transformer.blocks.2.attn_out.weight_quantizer.R | 0.0157     | -0.0051    | 1.2920    \n",
      "model.transformer.blocks.2.ff_out.weight_quantizer.R | 0.0157     | -0.0035    | 1.2378    \n",
      "model.transformer.blocks.2.ff_out.act_quantizer.R | 0.0157     | -0.0035    | 1.2378    \n",
      "model.transformer.blocks.18.ff_out.weight_quantizer.R | 0.0157     | -0.0015    | 1.2382    \n",
      "model.transformer.blocks.18.ff_out.act_quantizer.R | 0.0157     | -0.0015    | 1.2382    \n",
      "model.transformer.blocks.19.k_proj.act_quantizer.R | 0.0157     | -0.0019    | 1.2499    \n",
      "model.transformer.blocks.19.q_proj.act_quantizer.R | 0.0157     | -0.0019    | 1.2499    \n",
      "model.transformer.blocks.19.k_proj.weight_quantizer.R | 0.0157     | -0.0019    | 1.2499    \n",
      "model.transformer.blocks.19.v_proj.weight_quantizer.R | 0.0157     | -0.0019    | 1.2499    \n",
      "model.transformer.blocks.19.v_proj.act_quantizer.R | 0.0157     | -0.0019    | 1.2499    \n",
      "model.transformer.blocks.19.q_proj.weight_quantizer.R | 0.0157     | -0.0019    | 1.2499    \n",
      "model.transformer.blocks.21.ff_proj.act_quantizer.R | 0.0157     | -0.0025    | 1.2803    \n",
      "model.transformer.blocks.21.ff_proj.weight_quantizer.R | 0.0157     | -0.0025    | 1.2803    \n",
      "model.transformer.blocks.21.up_proj.weight_quantizer.R | 0.0157     | -0.0025    | 1.2803    \n",
      "model.transformer.blocks.21.up_proj.act_quantizer.R | 0.0157     | -0.0025    | 1.2803    \n",
      "model.transformer.blocks.29.attn_out.act_quantizer.R | 0.0157     | -0.0007    | 1.2561    \n",
      "model.transformer.blocks.29.attn_out.weight_quantizer.R | 0.0157     | -0.0007    | 1.2561    \n",
      "model.transformer.blocks.20.q_proj.weight_quantizer.R | 0.0157     | -0.0013    | 1.2281    \n",
      "model.transformer.blocks.20.k_proj.weight_quantizer.R | 0.0157     | -0.0013    | 1.2281    \n",
      "model.transformer.blocks.20.v_proj.weight_quantizer.R | 0.0157     | -0.0013    | 1.2281    \n",
      "model.transformer.blocks.20.q_proj.act_quantizer.R | 0.0157     | -0.0013    | 1.2281    \n",
      "model.transformer.blocks.20.v_proj.act_quantizer.R | 0.0157     | -0.0013    | 1.2281    \n",
      "model.transformer.blocks.20.k_proj.act_quantizer.R | 0.0157     | -0.0013    | 1.2281    \n",
      "model.transformer.blocks.31.k_proj.weight_quantizer.R | 0.0157     | -0.0011    | 1.2607    \n",
      "model.transformer.blocks.31.q_proj.act_quantizer.R | 0.0157     | -0.0011    | 1.2607    \n",
      "model.transformer.blocks.31.v_proj.weight_quantizer.R | 0.0157     | -0.0011    | 1.2607    \n",
      "model.transformer.blocks.31.v_proj.act_quantizer.R | 0.0157     | -0.0011    | 1.2607    \n",
      "model.transformer.blocks.31.q_proj.weight_quantizer.R | 0.0157     | -0.0011    | 1.2607    \n",
      "model.transformer.blocks.31.k_proj.act_quantizer.R | 0.0157     | -0.0011    | 1.2607    \n",
      "model.transformer.blocks.12.attn_out.act_quantizer.R | 0.0157     | -0.0027    | 1.3137    \n",
      "model.transformer.blocks.12.attn_out.weight_quantizer.R | 0.0157     | -0.0027    | 1.3137    \n",
      "model.transformer.blocks.26.attn_out.weight_quantizer.R | 0.0157     | -0.0037    | 1.2949    \n",
      "model.transformer.blocks.26.attn_out.act_quantizer.R | 0.0157     | -0.0037    | 1.2949    \n",
      "model.transformer.blocks.15.q_proj.act_quantizer.R | 0.0157     | -0.0011    | 1.2013    \n",
      "model.transformer.blocks.15.q_proj.weight_quantizer.R | 0.0157     | -0.0011    | 1.2013    \n",
      "model.transformer.blocks.15.k_proj.act_quantizer.R | 0.0157     | -0.0011    | 1.2013    \n",
      "model.transformer.blocks.15.k_proj.weight_quantizer.R | 0.0157     | -0.0011    | 1.2013    \n",
      "model.transformer.blocks.15.v_proj.weight_quantizer.R | 0.0157     | -0.0011    | 1.2013    \n",
      "model.transformer.blocks.15.v_proj.act_quantizer.R | 0.0157     | -0.0011    | 1.2013    \n",
      "model.transformer.blocks.15.ff_proj.weight_quantizer.R | 0.0157     | -0.0009    | 1.1985    \n",
      "model.transformer.blocks.15.up_proj.act_quantizer.R | 0.0157     | -0.0009    | 1.1985    \n",
      "model.transformer.blocks.15.up_proj.weight_quantizer.R | 0.0157     | -0.0009    | 1.1985    \n",
      "model.transformer.blocks.15.ff_proj.act_quantizer.R | 0.0157     | -0.0009    | 1.1985    \n",
      "model.transformer.blocks.8.attn_out.weight_quantizer.R | 0.0157     | -0.0019    | 1.2228    \n",
      "model.transformer.blocks.8.attn_out.act_quantizer.R | 0.0157     | -0.0019    | 1.2228    \n",
      "model.transformer.blocks.13.ff_out.weight_quantizer.R | 0.0157     | -0.0004    | 1.2651    \n",
      "model.transformer.blocks.13.ff_out.act_quantizer.R | 0.0157     | -0.0004    | 1.2651    \n",
      "model.transformer.blocks.9.k_proj.act_quantizer.R | 0.0157     | -0.0008    | 1.2380    \n",
      "model.transformer.blocks.9.q_proj.weight_quantizer.R | 0.0157     | -0.0008    | 1.2380    \n",
      "model.transformer.blocks.9.v_proj.act_quantizer.R | 0.0157     | -0.0008    | 1.2380    \n",
      "model.transformer.blocks.9.v_proj.weight_quantizer.R | 0.0157     | -0.0008    | 1.2380    \n",
      "model.transformer.blocks.9.k_proj.weight_quantizer.R | 0.0157     | -0.0008    | 1.2380    \n",
      "model.transformer.blocks.9.q_proj.act_quantizer.R | 0.0157     | -0.0008    | 1.2380    \n",
      "model.transformer.blocks.17.v_proj.act_quantizer.R | 0.0157     | 0.0005     | 1.2404    \n",
      "model.transformer.blocks.17.q_proj.act_quantizer.R | 0.0157     | 0.0005     | 1.2404    \n",
      "model.transformer.blocks.17.v_proj.weight_quantizer.R | 0.0157     | 0.0005     | 1.2404    \n",
      "model.transformer.blocks.17.k_proj.weight_quantizer.R | 0.0157     | 0.0005     | 1.2404    \n",
      "model.transformer.blocks.17.k_proj.act_quantizer.R | 0.0157     | 0.0005     | 1.2404    \n",
      "model.transformer.blocks.17.q_proj.weight_quantizer.R | 0.0157     | 0.0005     | 1.2404    \n",
      "model.transformer.blocks.1.ff_out.weight_quantizer.R | 0.0157     | 0.0010     | 1.2532    \n",
      "model.transformer.blocks.1.ff_out.act_quantizer.R | 0.0157     | 0.0010     | 1.2532    \n",
      "model.transformer.blocks.20.attn_out.weight_quantizer.R | 0.0157     | 0.0000     | 1.2449    \n",
      "model.transformer.blocks.20.attn_out.act_quantizer.R | 0.0157     | 0.0000     | 1.2449    \n",
      "model.transformer.blocks.8.k_proj.act_quantizer.R | 0.0157     | 0.0015     | 1.2783    \n",
      "model.transformer.blocks.8.v_proj.weight_quantizer.R | 0.0157     | 0.0015     | 1.2783    \n",
      "model.transformer.blocks.8.v_proj.act_quantizer.R | 0.0157     | 0.0015     | 1.2783    \n",
      "model.transformer.blocks.8.k_proj.weight_quantizer.R | 0.0157     | 0.0015     | 1.2783    \n",
      "model.transformer.blocks.8.q_proj.act_quantizer.R | 0.0157     | 0.0015     | 1.2783    \n",
      "model.transformer.blocks.8.q_proj.weight_quantizer.R | 0.0157     | 0.0015     | 1.2783    \n",
      "model.transformer.blocks.10.attn_out.weight_quantizer.R | 0.0156     | 0.0009     | 1.2274    \n",
      "model.transformer.blocks.10.attn_out.act_quantizer.R | 0.0156     | 0.0009     | 1.2274    \n",
      "model.transformer.blocks.8.up_proj.act_quantizer.R | 0.0156     | 0.0014     | 1.2305    \n",
      "model.transformer.blocks.8.ff_proj.weight_quantizer.R | 0.0156     | 0.0014     | 1.2305    \n",
      "model.transformer.blocks.8.up_proj.weight_quantizer.R | 0.0156     | 0.0014     | 1.2305    \n",
      "model.transformer.blocks.8.ff_proj.act_quantizer.R | 0.0156     | 0.0014     | 1.2305    \n",
      "model.transformer.blocks.2.up_proj.weight_quantizer.R | 0.0156     | 0.0010     | 1.2612    \n",
      "model.transformer.blocks.2.ff_proj.act_quantizer.R | 0.0156     | 0.0010     | 1.2612    \n",
      "model.transformer.blocks.2.ff_proj.weight_quantizer.R | 0.0156     | 0.0010     | 1.2612    \n",
      "model.transformer.blocks.2.up_proj.act_quantizer.R | 0.0156     | 0.0010     | 1.2612    \n",
      "model.transformer.blocks.22.ff_proj.act_quantizer.R | 0.0156     | 0.0014     | 1.2186    \n",
      "model.transformer.blocks.22.ff_proj.weight_quantizer.R | 0.0156     | 0.0014     | 1.2186    \n",
      "model.transformer.blocks.22.up_proj.act_quantizer.R | 0.0156     | 0.0014     | 1.2186    \n",
      "model.transformer.blocks.22.up_proj.weight_quantizer.R | 0.0156     | 0.0014     | 1.2186    \n",
      "model.transformer.blocks.28.q_proj.act_quantizer.R | 0.0156     | 0.0029     | 1.2534    \n",
      "model.transformer.blocks.28.k_proj.weight_quantizer.R | 0.0156     | 0.0029     | 1.2534    \n",
      "model.transformer.blocks.28.q_proj.weight_quantizer.R | 0.0156     | 0.0029     | 1.2534    \n",
      "model.transformer.blocks.28.k_proj.act_quantizer.R | 0.0156     | 0.0029     | 1.2534    \n",
      "model.transformer.blocks.28.v_proj.weight_quantizer.R | 0.0156     | 0.0029     | 1.2534    \n",
      "model.transformer.blocks.28.v_proj.act_quantizer.R | 0.0156     | 0.0029     | 1.2534    \n",
      "model.transformer.blocks.0.k_proj.act_quantizer.R | 0.0156     | 0.0021     | 1.2035    \n",
      "model.transformer.blocks.0.q_proj.act_quantizer.R | 0.0156     | 0.0021     | 1.2035    \n",
      "model.transformer.blocks.0.k_proj.weight_quantizer.R | 0.0156     | 0.0021     | 1.2035    \n",
      "model.transformer.blocks.0.v_proj.act_quantizer.R | 0.0156     | 0.0021     | 1.2035    \n",
      "model.transformer.blocks.0.v_proj.weight_quantizer.R | 0.0156     | 0.0021     | 1.2035    \n",
      "model.transformer.blocks.0.q_proj.weight_quantizer.R | 0.0156     | 0.0021     | 1.2035    \n",
      "model.transformer.blocks.23.ff_proj.act_quantizer.R | 0.0156     | 0.0031     | 1.2095    \n",
      "model.transformer.blocks.23.up_proj.weight_quantizer.R | 0.0156     | 0.0031     | 1.2095    \n",
      "model.transformer.blocks.23.up_proj.act_quantizer.R | 0.0156     | 0.0031     | 1.2095    \n",
      "model.transformer.blocks.23.ff_proj.weight_quantizer.R | 0.0156     | 0.0031     | 1.2095    \n",
      "model.transformer.blocks.27.attn_out.weight_quantizer.R | 0.0156     | 0.0024     | 1.2932    \n",
      "model.transformer.blocks.27.attn_out.act_quantizer.R | 0.0156     | 0.0024     | 1.2932    \n",
      "model.transformer.blocks.7.up_proj.weight_quantizer.R | 0.0156     | 0.0049     | 1.1910    \n",
      "model.transformer.blocks.7.ff_proj.weight_quantizer.R | 0.0156     | 0.0049     | 1.1910    \n",
      "model.transformer.blocks.7.up_proj.act_quantizer.R | 0.0156     | 0.0049     | 1.1910    \n",
      "model.transformer.blocks.7.ff_proj.act_quantizer.R | 0.0156     | 0.0049     | 1.1910    \n",
      "model.transformer.blocks.2.q_proj.act_quantizer.R | 0.0156     | 0.0037     | 1.2490    \n",
      "model.transformer.blocks.2.v_proj.weight_quantizer.R | 0.0156     | 0.0037     | 1.2490    \n",
      "model.transformer.blocks.2.q_proj.weight_quantizer.R | 0.0156     | 0.0037     | 1.2490    \n",
      "model.transformer.blocks.2.k_proj.weight_quantizer.R | 0.0156     | 0.0037     | 1.2490    \n",
      "model.transformer.blocks.2.v_proj.act_quantizer.R | 0.0156     | 0.0037     | 1.2490    \n",
      "model.transformer.blocks.2.k_proj.act_quantizer.R | 0.0156     | 0.0037     | 1.2490    \n",
      "model.transformer.blocks.5.ff_out.weight_quantizer.R | 0.0156     | 0.0040     | 1.2629    \n",
      "model.transformer.blocks.5.ff_out.act_quantizer.R | 0.0156     | 0.0040     | 1.2629    \n",
      "model.transformer.blocks.10.ff_out.act_quantizer.R | 0.0156     | 0.0069     | 1.3127    \n",
      "model.transformer.blocks.10.ff_out.weight_quantizer.R | 0.0156     | 0.0069     | 1.3127    \n",
      "model.transformer.blocks.7.ff_out.act_quantizer.R | 0.0156     | 0.0060     | 1.2079    \n",
      "model.transformer.blocks.7.ff_out.weight_quantizer.R | 0.0156     | 0.0060     | 1.2079    \n",
      "model.transformer.blocks.11.ff_out.act_quantizer.R | 0.0156     | 0.0045     | 1.3047    \n",
      "model.transformer.blocks.11.ff_out.weight_quantizer.R | 0.0156     | 0.0045     | 1.3047    \n",
      "model.transformer.blocks.5.attn_out.weight_quantizer.R | 0.0156     | 0.0050     | 1.2000    \n",
      "model.transformer.blocks.5.attn_out.act_quantizer.R | 0.0156     | 0.0050     | 1.2000    \n",
      "model.transformer.blocks.26.ff_proj.act_quantizer.R | 0.0156     | 0.0061     | 1.2234    \n",
      "model.transformer.blocks.26.up_proj.weight_quantizer.R | 0.0156     | 0.0061     | 1.2234    \n",
      "model.transformer.blocks.26.up_proj.act_quantizer.R | 0.0156     | 0.0061     | 1.2234    \n",
      "model.transformer.blocks.26.ff_proj.weight_quantizer.R | 0.0156     | 0.0061     | 1.2234    \n",
      "model.transformer.blocks.7.v_proj.weight_quantizer.R | 0.0156     | 0.0060     | 1.1997    \n",
      "model.transformer.blocks.7.k_proj.act_quantizer.R | 0.0156     | 0.0060     | 1.1997    \n",
      "model.transformer.blocks.7.k_proj.weight_quantizer.R | 0.0156     | 0.0060     | 1.1997    \n",
      "model.transformer.blocks.7.q_proj.weight_quantizer.R | 0.0156     | 0.0060     | 1.1997    \n",
      "model.transformer.blocks.7.v_proj.act_quantizer.R | 0.0156     | 0.0060     | 1.1997    \n",
      "model.transformer.blocks.7.q_proj.act_quantizer.R | 0.0156     | 0.0060     | 1.1997    \n",
      "model.transformer.blocks.29.q_proj.weight_quantizer.R | 0.0156     | 0.0058     | 1.2025    \n",
      "model.transformer.blocks.29.v_proj.act_quantizer.R | 0.0156     | 0.0058     | 1.2025    \n",
      "model.transformer.blocks.29.k_proj.weight_quantizer.R | 0.0156     | 0.0058     | 1.2025    \n",
      "model.transformer.blocks.29.q_proj.act_quantizer.R | 0.0156     | 0.0058     | 1.2025    \n",
      "model.transformer.blocks.29.k_proj.act_quantizer.R | 0.0156     | 0.0058     | 1.2025    \n",
      "model.transformer.blocks.29.v_proj.weight_quantizer.R | 0.0156     | 0.0058     | 1.2025    \n",
      "model.transformer.blocks.25.attn_out.act_quantizer.R | 0.0156     | 0.0050     | 1.2329    \n",
      "model.transformer.blocks.25.attn_out.weight_quantizer.R | 0.0156     | 0.0050     | 1.2329    \n",
      "model.transformer.blocks.12.ff_proj.act_quantizer.R | 0.0156     | 0.0065     | 1.2233    \n",
      "model.transformer.blocks.12.up_proj.act_quantizer.R | 0.0156     | 0.0065     | 1.2233    \n",
      "model.transformer.blocks.12.ff_proj.weight_quantizer.R | 0.0156     | 0.0065     | 1.2233    \n",
      "model.transformer.blocks.12.up_proj.weight_quantizer.R | 0.0156     | 0.0065     | 1.2233    \n",
      "model.transformer.blocks.11.attn_out.weight_quantizer.R | 0.0156     | 0.0066     | 1.2708    \n",
      "model.transformer.blocks.11.attn_out.act_quantizer.R | 0.0156     | 0.0066     | 1.2708    \n",
      "model.transformer.blocks.6.ff_out.act_quantizer.R | 0.0156     | 0.0070     | 1.2252    \n",
      "model.transformer.blocks.6.ff_out.weight_quantizer.R | 0.0156     | 0.0070     | 1.2252    \n",
      "model.transformer.blocks.27.k_proj.weight_quantizer.R | 0.0155     | 0.0075     | 1.1995    \n",
      "model.transformer.blocks.27.v_proj.weight_quantizer.R | 0.0155     | 0.0075     | 1.1995    \n",
      "model.transformer.blocks.27.q_proj.act_quantizer.R | 0.0155     | 0.0075     | 1.1995    \n",
      "model.transformer.blocks.27.q_proj.weight_quantizer.R | 0.0155     | 0.0075     | 1.1995    \n",
      "model.transformer.blocks.27.k_proj.act_quantizer.R | 0.0155     | 0.0075     | 1.1995    \n",
      "model.transformer.blocks.27.v_proj.act_quantizer.R | 0.0155     | 0.0075     | 1.1995    \n",
      "model.transformer.blocks.22.ff_out.act_quantizer.R | 0.0155     | 0.0077     | 1.2289    \n",
      "model.transformer.blocks.22.ff_out.weight_quantizer.R | 0.0155     | 0.0077     | 1.2289    \n",
      "model.transformer.blocks.29.ff_proj.act_quantizer.R | 0.0155     | 0.0080     | 1.2637    \n",
      "model.transformer.blocks.29.up_proj.weight_quantizer.R | 0.0155     | 0.0080     | 1.2637    \n",
      "model.transformer.blocks.29.ff_proj.weight_quantizer.R | 0.0155     | 0.0080     | 1.2637    \n",
      "model.transformer.blocks.29.up_proj.act_quantizer.R | 0.0155     | 0.0080     | 1.2637    \n",
      "model.transformer.blocks.9.ff_out.act_quantizer.R | 0.0155     | 0.0084     | 1.2074    \n",
      "model.transformer.blocks.9.ff_out.weight_quantizer.R | 0.0155     | 0.0084     | 1.2074    \n",
      "model.transformer.blocks.23.attn_out.weight_quantizer.R | 0.0155     | 0.0080     | 1.2793    \n",
      "model.transformer.blocks.23.attn_out.act_quantizer.R | 0.0155     | 0.0080     | 1.2793    \n",
      "model.transformer.blocks.3.attn_out.weight_quantizer.R | 0.0155     | 0.0079     | 1.2159    \n",
      "model.transformer.blocks.3.attn_out.act_quantizer.R | 0.0155     | 0.0079     | 1.2159    \n",
      "model.transformer.blocks.3.v_proj.act_quantizer.R | 0.0155     | 0.0070     | 1.2673    \n",
      "model.transformer.blocks.3.q_proj.weight_quantizer.R | 0.0155     | 0.0070     | 1.2673    \n",
      "model.transformer.blocks.3.q_proj.act_quantizer.R | 0.0155     | 0.0070     | 1.2673    \n",
      "model.transformer.blocks.3.v_proj.weight_quantizer.R | 0.0155     | 0.0070     | 1.2673    \n",
      "model.transformer.blocks.3.k_proj.weight_quantizer.R | 0.0155     | 0.0070     | 1.2673    \n",
      "model.transformer.blocks.3.k_proj.act_quantizer.R | 0.0155     | 0.0070     | 1.2673    \n",
      "model.transformer.blocks.10.ff_proj.weight_quantizer.R | 0.0155     | 0.0095     | 1.2351    \n",
      "model.transformer.blocks.10.up_proj.act_quantizer.R | 0.0155     | 0.0095     | 1.2351    \n",
      "model.transformer.blocks.10.ff_proj.act_quantizer.R | 0.0155     | 0.0095     | 1.2351    \n",
      "model.transformer.blocks.10.up_proj.weight_quantizer.R | 0.0155     | 0.0095     | 1.2351    \n",
      "model.transformer.blocks.0.ff_out.act_quantizer.R | 0.0155     | 0.0082     | 1.2717    \n",
      "model.transformer.blocks.0.ff_out.weight_quantizer.R | 0.0155     | 0.0082     | 1.2717    \n",
      "model.transformer.blocks.21.attn_out.act_quantizer.R | 0.0155     | 0.0091     | 1.1868    \n",
      "model.transformer.blocks.21.attn_out.weight_quantizer.R | 0.0155     | 0.0091     | 1.1868    \n",
      "model.transformer.blocks.19.attn_out.weight_quantizer.R | 0.0155     | 0.0108     | 1.1896    \n",
      "model.transformer.blocks.19.attn_out.act_quantizer.R | 0.0155     | 0.0108     | 1.1896    \n",
      "model.transformer.blocks.18.q_proj.weight_quantizer.R | 0.0155     | 0.0104     | 1.2479    \n",
      "model.transformer.blocks.18.v_proj.act_quantizer.R | 0.0155     | 0.0104     | 1.2479    \n",
      "model.transformer.blocks.18.q_proj.act_quantizer.R | 0.0155     | 0.0104     | 1.2479    \n",
      "model.transformer.blocks.18.v_proj.weight_quantizer.R | 0.0155     | 0.0104     | 1.2479    \n",
      "model.transformer.blocks.18.k_proj.weight_quantizer.R | 0.0155     | 0.0104     | 1.2479    \n",
      "model.transformer.blocks.18.k_proj.act_quantizer.R | 0.0155     | 0.0104     | 1.2479    \n",
      "model.transformer.blocks.9.up_proj.weight_quantizer.R | 0.0155     | 0.0102     | 1.2211    \n",
      "model.transformer.blocks.9.ff_proj.act_quantizer.R | 0.0155     | 0.0102     | 1.2211    \n",
      "model.transformer.blocks.9.ff_proj.weight_quantizer.R | 0.0155     | 0.0102     | 1.2211    \n",
      "model.transformer.blocks.9.up_proj.act_quantizer.R | 0.0155     | 0.0102     | 1.2211    \n",
      "model.transformer.blocks.14.v_proj.weight_quantizer.R | 0.0155     | 0.0087     | 1.2900    \n",
      "model.transformer.blocks.14.k_proj.act_quantizer.R | 0.0155     | 0.0087     | 1.2900    \n",
      "model.transformer.blocks.14.k_proj.weight_quantizer.R | 0.0155     | 0.0087     | 1.2900    \n",
      "model.transformer.blocks.14.q_proj.act_quantizer.R | 0.0155     | 0.0087     | 1.2900    \n",
      "model.transformer.blocks.14.v_proj.act_quantizer.R | 0.0155     | 0.0087     | 1.2900    \n",
      "model.transformer.blocks.14.q_proj.weight_quantizer.R | 0.0155     | 0.0087     | 1.2900    \n",
      "model.transformer.blocks.18.attn_out.act_quantizer.R | 0.0155     | 0.0100     | 1.2108    \n",
      "model.transformer.blocks.18.attn_out.weight_quantizer.R | 0.0155     | 0.0100     | 1.2108    \n",
      "model.transformer.blocks.17.ff_proj.act_quantizer.R | 0.0155     | 0.0116     | 1.2815    \n",
      "model.transformer.blocks.17.up_proj.weight_quantizer.R | 0.0155     | 0.0116     | 1.2815    \n",
      "model.transformer.blocks.17.up_proj.act_quantizer.R | 0.0155     | 0.0116     | 1.2815    \n",
      "model.transformer.blocks.17.ff_proj.weight_quantizer.R | 0.0155     | 0.0116     | 1.2815    \n",
      "model.transformer.blocks.4.ff_out.act_quantizer.R | 0.0155     | 0.0125     | 1.2563    \n",
      "model.transformer.blocks.4.ff_out.weight_quantizer.R | 0.0155     | 0.0125     | 1.2563    \n",
      "model.transformer.blocks.30.attn_out.weight_quantizer.R | 0.0155     | 0.0127     | 1.2429    \n",
      "model.transformer.blocks.30.attn_out.act_quantizer.R | 0.0155     | 0.0127     | 1.2429    \n",
      "model.transformer.blocks.16.attn_out.act_quantizer.R | 0.0155     | 0.0122     | 1.2417    \n",
      "model.transformer.blocks.16.attn_out.weight_quantizer.R | 0.0155     | 0.0122     | 1.2417    \n",
      "model.transformer.blocks.12.k_proj.weight | 0.0155     | -0.0005    | 3.3113    \n",
      "model.transformer.blocks.26.q_proj.weight_quantizer.R | 0.0155     | 0.0140     | 1.2458    \n",
      "model.transformer.blocks.26.q_proj.act_quantizer.R | 0.0155     | 0.0140     | 1.2458    \n",
      "model.transformer.blocks.26.v_proj.weight_quantizer.R | 0.0155     | 0.0140     | 1.2458    \n",
      "model.transformer.blocks.26.v_proj.act_quantizer.R | 0.0155     | 0.0140     | 1.2458    \n",
      "model.transformer.blocks.26.k_proj.weight_quantizer.R | 0.0155     | 0.0140     | 1.2458    \n",
      "model.transformer.blocks.26.k_proj.act_quantizer.R | 0.0155     | 0.0140     | 1.2458    \n",
      "model.transformer.blocks.24.attn_out.act_quantizer.R | 0.0154     | 0.0133     | 1.2285    \n",
      "model.transformer.blocks.24.attn_out.weight_quantizer.R | 0.0154     | 0.0133     | 1.2285    \n",
      "model.transformer.blocks.2.fc1_smooth_scale | 0.0154     | 0.9990     | 0.6504    \n",
      "model.transformer.blocks.25.up_proj.act_quantizer.R | 0.0154     | 0.0182     | 1.2649    \n",
      "model.transformer.blocks.25.up_proj.weight_quantizer.R | 0.0154     | 0.0182     | 1.2649    \n",
      "model.transformer.blocks.25.ff_proj.act_quantizer.R | 0.0154     | 0.0182     | 1.2649    \n",
      "model.transformer.blocks.25.ff_proj.weight_quantizer.R | 0.0154     | 0.0182     | 1.2649    \n",
      "model.transformer.blocks.21.v_proj.weight_quantizer.R | 0.0154     | 0.0189     | 1.2196    \n",
      "model.transformer.blocks.21.q_proj.act_quantizer.R | 0.0154     | 0.0189     | 1.2196    \n",
      "model.transformer.blocks.21.q_proj.weight_quantizer.R | 0.0154     | 0.0189     | 1.2196    \n",
      "model.transformer.blocks.21.k_proj.weight_quantizer.R | 0.0154     | 0.0189     | 1.2196    \n",
      "model.transformer.blocks.21.v_proj.act_quantizer.R | 0.0154     | 0.0189     | 1.2196    \n",
      "model.transformer.blocks.21.k_proj.act_quantizer.R | 0.0154     | 0.0189     | 1.2196    \n",
      "model.transformer.blocks.5.q_proj.weight_quantizer.R | 0.0154     | 0.0192     | 1.2411    \n",
      "model.transformer.blocks.5.v_proj.weight_quantizer.R | 0.0154     | 0.0192     | 1.2411    \n",
      "model.transformer.blocks.5.k_proj.act_quantizer.R | 0.0154     | 0.0192     | 1.2411    \n",
      "model.transformer.blocks.5.v_proj.act_quantizer.R | 0.0154     | 0.0192     | 1.2411    \n",
      "model.transformer.blocks.5.q_proj.act_quantizer.R | 0.0154     | 0.0192     | 1.2411    \n",
      "model.transformer.blocks.5.k_proj.weight_quantizer.R | 0.0154     | 0.0192     | 1.2411    \n",
      "model.transformer.blocks.19.up_proj.act_quantizer.R | 0.0153     | 0.0202     | 1.2751    \n",
      "model.transformer.blocks.19.up_proj.weight_quantizer.R | 0.0153     | 0.0202     | 1.2751    \n",
      "model.transformer.blocks.19.ff_proj.act_quantizer.R | 0.0153     | 0.0202     | 1.2751    \n",
      "model.transformer.blocks.19.ff_proj.weight_quantizer.R | 0.0153     | 0.0202     | 1.2751    \n",
      "model.transformer.blocks.12.q_proj.weight | 0.0153     | 0.0001     | 1.6971    \n",
      "model.transformer.blocks.24.v_proj.weight_quantizer.R | 0.0153     | 0.0216     | 1.2393    \n",
      "model.transformer.blocks.24.k_proj.weight_quantizer.R | 0.0153     | 0.0216     | 1.2393    \n",
      "model.transformer.blocks.24.q_proj.weight_quantizer.R | 0.0153     | 0.0216     | 1.2393    \n",
      "model.transformer.blocks.24.v_proj.act_quantizer.R | 0.0153     | 0.0216     | 1.2393    \n",
      "model.transformer.blocks.24.q_proj.act_quantizer.R | 0.0153     | 0.0216     | 1.2393    \n",
      "model.transformer.blocks.24.k_proj.act_quantizer.R | 0.0153     | 0.0216     | 1.2393    \n",
      "model.transformer.blocks.13.ff_proj.weight_quantizer.R | 0.0153     | 0.0235     | 1.2546    \n",
      "model.transformer.blocks.13.up_proj.act_quantizer.R | 0.0153     | 0.0235     | 1.2546    \n",
      "model.transformer.blocks.13.up_proj.weight_quantizer.R | 0.0153     | 0.0235     | 1.2546    \n",
      "model.transformer.blocks.13.ff_proj.act_quantizer.R | 0.0153     | 0.0235     | 1.2546    \n",
      "model.transformer.blocks.20.ff_proj.act_quantizer.R | 0.0153     | 0.0246     | 1.2159    \n",
      "model.transformer.blocks.20.ff_proj.weight_quantizer.R | 0.0153     | 0.0246     | 1.2159    \n",
      "model.transformer.blocks.20.up_proj.weight_quantizer.R | 0.0153     | 0.0246     | 1.2159    \n",
      "model.transformer.blocks.20.up_proj.act_quantizer.R | 0.0153     | 0.0246     | 1.2159    \n",
      "model.transformer.blocks.21.ff_out.weight_quantizer.R | 0.0152     | 0.0283     | 1.2272    \n",
      "model.transformer.blocks.21.ff_out.act_quantizer.R | 0.0152     | 0.0283     | 1.2272    \n",
      "model.transformer.blocks.13.k_proj.act_quantizer.R | 0.0152     | 0.0262     | 1.2798    \n",
      "model.transformer.blocks.13.k_proj.weight_quantizer.R | 0.0152     | 0.0262     | 1.2798    \n",
      "model.transformer.blocks.13.q_proj.act_quantizer.R | 0.0152     | 0.0262     | 1.2798    \n",
      "model.transformer.blocks.13.v_proj.act_quantizer.R | 0.0152     | 0.0262     | 1.2798    \n",
      "model.transformer.blocks.13.q_proj.weight_quantizer.R | 0.0152     | 0.0262     | 1.2798    \n",
      "model.transformer.blocks.13.v_proj.weight_quantizer.R | 0.0152     | 0.0262     | 1.2798    \n",
      "model.transformer.blocks.29.ff_out.weight_quantizer.R | 0.0152     | 0.0295     | 1.2336    \n",
      "model.transformer.blocks.29.ff_out.act_quantizer.R | 0.0152     | 0.0295     | 1.2336    \n",
      "model.transformer.blocks.30.ff_out.weight_quantizer.R | 0.0152     | 0.0319     | 1.2563    \n",
      "model.transformer.blocks.30.ff_out.act_quantizer.R | 0.0152     | 0.0319     | 1.2563    \n",
      "model.transformer.blocks.24.up_proj.weight_quantizer.R | 0.0151     | 0.0319     | 1.1719    \n",
      "model.transformer.blocks.24.up_proj.act_quantizer.R | 0.0151     | 0.0319     | 1.1719    \n",
      "model.transformer.blocks.24.ff_proj.weight_quantizer.R | 0.0151     | 0.0319     | 1.1719    \n",
      "model.transformer.blocks.24.ff_proj.act_quantizer.R | 0.0151     | 0.0319     | 1.1719    \n",
      "model.transformer.blocks.8.ff_out.weight_quantizer.R | 0.0151     | 0.0349     | 1.2340    \n",
      "model.transformer.blocks.8.ff_out.act_quantizer.R | 0.0151     | 0.0349     | 1.2340    \n",
      "model.transformer.blocks.23.ff_out.act_quantizer.R | 0.0151     | 0.0383     | 1.2502    \n",
      "model.transformer.blocks.23.ff_out.weight_quantizer.R | 0.0151     | 0.0383     | 1.2502    \n",
      "model.transformer.blocks.3.ff_out.weight | 0.0150     | 0.0004     | 2.8125    \n",
      "model.transformer.blocks.31.ff_out.act_quantizer.R | 0.0148     | 0.0566     | 1.2220    \n",
      "model.transformer.blocks.31.ff_out.weight_quantizer.R | 0.0148     | 0.0566     | 1.2220    \n",
      "model.transformer.blocks.11.k_proj.weight | 0.0143     | 0.0004     | 4.1406    \n",
      "model.transformer.blocks.11.q_proj.weight | 0.0140     | -0.0001    | 1.7186    \n",
      "model.transformer.blocks.7.ff_proj.weight | 0.0136     | -0.0002    | 1.2294    \n",
      "model.transformer.blocks.12.attn_out.weight | 0.0131     | -0.0003    | 1.4824    \n",
      "model.transformer.blocks.0.qkv_smooth_scale | 0.0127     | 0.9992     | 0.8496    \n",
      "model.transformer.blocks.9.k_proj.weight | 0.0127     | 0.0003     | 2.0077    \n",
      "model.transformer.blocks.10.attn_out.weight | 0.0125     | 0.0000     | 1.6655    \n",
      "model.transformer.blocks.9.q_proj.weight | 0.0124     | 0.0003     | 1.2656    \n",
      "model.transformer.blocks.7.k_proj.weight | 0.0121     | -0.0004    | 2.9491    \n",
      "model.transformer.blocks.7.q_proj.weight | 0.0120     | -0.0005    | 1.5408    \n",
      "model.transformer.blocks.6.ff_proj.weight | 0.0113     | -0.0003    | 1.1547    \n",
      "model.transformer.blocks.8.k_proj.weight | 0.0112     | -0.0014    | 3.0538    \n",
      "model.transformer.blocks.8.q_proj.weight | 0.0110     | -0.0009    | 1.6652    \n",
      "model.transformer.blocks.11.attn_out.weight | 0.0106     | -0.0003    | 1.3052    \n",
      "model.transformer.blocks.1.fc1_smooth_scale | 0.0099     | 0.9991     | 0.5117    \n",
      "model.transformer.blocks.5.ff_proj.weight | 0.0099     | 0.0005     | 1.1016    \n",
      "model.transformer.blocks.31.ff_out.weight_quantizer.scales | 0.0088     | 0.9840     | 0.9500    \n",
      "model.transformer.blocks.9.attn_out.weight | 0.0087     | 0.0003     | 1.7646    \n",
      "model.transformer.blocks.29.ff_out.weight_quantizer.scales | 0.0087     | 0.9927     | 0.3632    \n",
      "model.transformer.blocks.28.ff_out.weight_quantizer.scales | 0.0085     | 0.9932     | 0.2668    \n",
      "model.transformer.blocks.6.k_proj.weight | 0.0084     | -0.0004    | 2.2535    \n",
      "model.transformer.blocks.7.attn_out.weight | 0.0080     | 0.0001     | 1.2742    \n",
      "model.transformer.blocks.6.q_proj.weight | 0.0079     | 0.0011     | 2.1078    \n",
      "model.transformer.blocks.2.ff_out.weight | 0.0079     | 0.0000     | 2.6475    \n",
      "model.transformer.blocks.4.ff_proj.weight | 0.0079     | -0.0001    | 1.2867    \n",
      "model.transformer.blocks.2.qkv_smooth_scale | 0.0078     | 0.9992     | 0.6719    \n",
      "model.transformer.blocks.27.ff_out.weight_quantizer.scales | 0.0077     | 0.9942     | 0.2004    \n",
      "model.transformer.blocks.5.k_proj.weight | 0.0076     | -0.0010    | 3.0141    \n",
      "model.transformer.blocks.8.attn_out.weight | 0.0075     | -0.0008    | 1.2725    \n",
      "model.transformer.blocks.0.fc1_smooth_scale | 0.0075     | 0.9991     | 0.5117    \n",
      "model.transformer.blocks.30.ff_out.weight_quantizer.scales | 0.0073     | 0.9925     | 0.2959    \n",
      "model.transformer.blocks.5.q_proj.weight | 0.0073     | 0.0001     | 1.2589    \n",
      "model.transformer.blocks.3.qkv_smooth_scale | 0.0070     | 0.9992     | 0.5195    \n",
      "model.transformer.blocks.3.ff_proj.weight | 0.0056     | -0.0005    | 1.2197    \n",
      "model.transformer.blocks.6.attn_out.weight | 0.0052     | 0.0002     | 1.2451    \n",
      "model.transformer.blocks.26.ff_out.weight_quantizer.scales | 0.0050     | 0.9944     | 0.1527    \n",
      "model.transformer.blocks.4.k_proj.weight | 0.0049     | 0.0003     | 2.1934    \n",
      "model.transformer.blocks.5.attn_out.weight | 0.0047     | -0.0000    | 1.2419    \n",
      "model.transformer.blocks.4.q_proj.weight | 0.0047     | -0.0010    | 1.7062    \n",
      "model.transformer.blocks.0.q_proj.weight | 0.0041     | 0.0011     | 1.5037    \n",
      "model.transformer.blocks.2.ff_proj.weight | 0.0037     | 0.0002     | 0.9053    \n",
      "model.transformer.blocks.0.k_proj.weight | 0.0036     | -0.0023    | 1.1663    \n",
      "model.transformer.blocks.25.ff_out.weight_quantizer.scales | 0.0035     | 0.9944     | 0.1917    \n",
      "model.transformer.blocks.1.ff_out.weight | 0.0034     | -0.0002    | 1.9473    \n",
      "model.transformer.blocks.4.attn_out.weight | 0.0032     | -0.0004    | 0.9133    \n",
      "model.transformer.blocks.1.qkv_smooth_scale | 0.0030     | 0.9992     | 0.7773    \n",
      "model.transformer.blocks.2.k_proj.weight | 0.0027     | -0.0000    | 1.2492    \n",
      "model.transformer.blocks.24.ff_out.weight_quantizer.scales | 0.0026     | 0.9944     | 0.2356    \n",
      "model.transformer.blocks.30.v_proj.weight | 0.0025     | -0.0001    | 0.6162    \n",
      "model.transformer.blocks.2.q_proj.weight | 0.0025     | -0.0007    | 0.8555    \n",
      "model.transformer.blocks.3.k_proj.weight | 0.0023     | -0.0007    | 1.8972    \n",
      "model.transformer.blocks.29.v_proj.weight | 0.0022     | 0.0007     | 0.6868    \n",
      "model.transformer.blocks.1.ff_proj.weight | 0.0022     | -0.0001    | 1.2235    \n",
      "model.transformer.blocks.23.ff_out.weight_quantizer.scales | 0.0022     | 0.9939     | 0.1254    \n",
      "model.transformer.blocks.3.q_proj.weight | 0.0022     | -0.0009    | 1.8984    \n",
      "model.transformer.blocks.31.v_proj.weight | 0.0021     | 0.0000     | 0.4894    \n",
      "model.transformer.blocks.28.v_proj.weight | 0.0020     | -0.0006    | 0.6887    \n",
      "model.transformer.blocks.25.k_proj.weight_quantizer.scales | 0.0019     | 0.8737     | 0.2597    \n",
      "model.transformer.blocks.0.attn_out.weight | 0.0018     | -0.0001    | 1.6084    \n",
      "model.transformer.blocks.26.k_proj.weight_quantizer.scales | 0.0018     | 0.8762     | 0.2469    \n",
      "model.transformer.blocks.3.attn_out.weight | 0.0016     | -0.0007    | 0.7103    \n",
      "model.transformer.blocks.0.ff_proj.weight | 0.0015     | 0.0003     | 0.8508    \n",
      "model.transformer.blocks.5.k_proj.weight_quantizer.scales | 0.0015     | 0.8860     | 0.1998    \n",
      "model.transformer.blocks.0.up_proj.weight | 0.0014     | 0.0004     | 0.7767    \n",
      "model.transformer.blocks.2.attn_out.weight | 0.0014     | 0.0011     | 0.7050    \n",
      "model.transformer.blocks.22.ff_out.weight_quantizer.scales | 0.0013     | 0.9945     | 0.0950    \n",
      "model.transformer.blocks.27.v_proj.weight | 0.0013     | -0.0005    | 0.4590    \n",
      "model.transformer.blocks.30.k_proj.weight_quantizer.scales | 0.0012     | 0.8982     | 0.2228    \n",
      "model.transformer.blocks.14.ff_out.weight_quantizer.scales | 0.0012     | 0.9913     | 0.3270    \n",
      "model.transformer.blocks.15.k_proj.weight_quantizer.scales | 0.0012     | 0.8675     | 0.2682    \n",
      "model.transformer.blocks.11.ff_out.weight_quantizer.scales | 0.0011     | 0.9932     | 0.1341    \n",
      "model.transformer.blocks.0.ff_out.weight | 0.0011     | 0.0003     | 1.4050    \n",
      "model.transformer.blocks.15.ff_out.weight_quantizer.scales | 0.0011     | 0.9884     | 0.5376    \n",
      "model.transformer.blocks.8.ff_out.weight_quantizer.scales | 0.0011     | 0.9930     | 0.1598    \n",
      "model.transformer.blocks.0.v_proj.weight | 0.0011     | 0.0008     | 0.4746    \n",
      "model.transformer.blocks.13.ff_out.weight_quantizer.scales | 0.0011     | 0.9932     | 0.1359    \n",
      "model.transformer.blocks.1.up_proj.weight | 0.0011     | 0.0002     | 0.5234    \n",
      "model.transformer.blocks.24.k_proj.weight_quantizer.scales | 0.0010     | 0.8995     | 0.1953    \n",
      "model.transformer.blocks.12.k_proj.weight_quantizer.scales | 0.0010     | 0.8769     | 0.2434    \n",
      "model.transformer.blocks.1.k_proj.weight | 0.0010     | -0.0013    | 2.2297    \n",
      "model.transformer.blocks.21.ff_out.weight_quantizer.scales | 0.0010     | 0.9935     | 0.1374    \n",
      "model.transformer.blocks.9.ff_out.weight_quantizer.scales | 0.0010     | 0.9933     | 0.3002    \n",
      "model.transformer.blocks.26.v_proj.weight | 0.0010     | -0.0005    | 0.3324    \n",
      "model.transformer.blocks.10.ff_out.weight_quantizer.scales | 0.0010     | 0.9940     | 0.0803    \n",
      "model.transformer.blocks.23.k_proj.weight_quantizer.scales | 0.0010     | 0.9073     | 0.2059    \n",
      "model.transformer.blocks.25.v_proj.weight | 0.0010     | 0.0004     | 0.6386    \n",
      "model.transformer.blocks.17.ff_out.weight_quantizer.scales | 0.0010     | 0.9924     | 0.2717    \n",
      "model.transformer.blocks.12.ff_out.weight_quantizer.scales | 0.0009     | 0.9935     | 0.1669    \n",
      "model.transformer.blocks.27.k_proj.weight_quantizer.scales | 0.0009     | 0.9164     | 0.1713    \n",
      "model.transformer.blocks.14.k_proj.weight_quantizer.scales | 0.0009     | 0.8770     | 0.2166    \n",
      "model.transformer.blocks.11.k_proj.weight_quantizer.scales | 0.0009     | 0.8778     | 0.2852    \n",
      "model.transformer.blocks.16.ff_out.weight_quantizer.scales | 0.0009     | 0.9925     | 0.3010    \n",
      "model.transformer.blocks.7.k_proj.weight_quantizer.scales | 0.0009     | 0.9057     | 0.2022    \n",
      "model.transformer.blocks.4.k_proj.weight_quantizer.scales | 0.0009     | 0.9221     | 0.1412    \n",
      "model.transformer.blocks.20.ff_out.weight_quantizer.scales | 0.0009     | 0.9933     | 0.1504    \n",
      "model.transformer.blocks.24.v_proj.weight | 0.0009     | -0.0009    | 0.2800    \n",
      "model.transformer.blocks.1.q_proj.weight | 0.0009     | -0.0007    | 1.6205    \n",
      "model.transformer.blocks.8.k_proj.weight_quantizer.scales | 0.0008     | 0.9042     | 0.1971    \n",
      "model.transformer.blocks.19.ff_out.weight_quantizer.scales | 0.0008     | 0.9931     | 0.2176    \n",
      "model.transformer.blocks.13.k_proj.weight_quantizer.scales | 0.0008     | 0.8896     | 0.2128    \n",
      "model.transformer.blocks.5.ff_out.weight_quantizer.scales | 0.0008     | 0.9943     | 0.0676    \n",
      "model.transformer.blocks.21.k_proj.weight_quantizer.scales | 0.0008     | 0.8979     | 0.1877    \n",
      "model.transformer.blocks.2.up_proj.weight | 0.0008     | -0.0004    | 0.4326    \n",
      "model.transformer.blocks.22.k_proj.weight_quantizer.scales | 0.0008     | 0.9086     | 0.2266    \n",
      "model.transformer.blocks.22.v_proj.weight | 0.0008     | -0.0003    | 0.7607    \n",
      "model.transformer.blocks.6.k_proj.weight_quantizer.scales | 0.0008     | 0.9190     | 0.1551    \n",
      "model.transformer.blocks.23.v_proj.weight | 0.0008     | -0.0000    | 0.4481    \n",
      "model.transformer.blocks.18.ff_out.weight_quantizer.scales | 0.0008     | 0.9936     | 0.0958    \n",
      "model.transformer.blocks.3.ff_out.weight_quantizer.scales | 0.0007     | 0.9945     | 0.0748    \n",
      "model.transformer.blocks.4.ff_out.weight_quantizer.scales | 0.0007     | 0.9938     | 0.0684    \n",
      "model.transformer.blocks.21.v_proj.weight | 0.0007     | 0.0004     | 0.6615    \n",
      "model.transformer.blocks.10.k_proj.weight_quantizer.scales | 0.0007     | 0.9019     | 0.2309    \n",
      "model.transformer.blocks.31.k_proj.weight_quantizer.scales | 0.0007     | 0.9276     | 0.2016    \n",
      "model.transformer.blocks.0.k_proj.weight_quantizer.scales | 0.0007     | 0.8730     | 0.1143    \n",
      "model.transformer.blocks.8.v_proj.weight | 0.0007     | -0.0003    | 0.4751    \n",
      "model.transformer.blocks.6.ff_out.weight_quantizer.scales | 0.0007     | 0.9939     | 0.1914    \n",
      "model.transformer.blocks.20.k_proj.weight_quantizer.scales | 0.0007     | 0.9025     | 0.1927    \n",
      "model.transformer.blocks.20.v_proj.weight | 0.0007     | -0.0003    | 0.5371    \n",
      "model.transformer.blocks.9.v_proj.weight | 0.0007     | -0.0002    | 0.4828    \n",
      "model.transformer.blocks.3.up_proj.weight | 0.0007     | -0.0003    | 0.7732    \n",
      "model.transformer.blocks.1.attn_out.weight | 0.0007     | 0.0003     | 0.6836    \n",
      "model.transformer.blocks.3.k_proj.weight_quantizer.scales | 0.0007     | 0.9513     | 0.1210    \n",
      "model.transformer.blocks.19.k_proj.weight_quantizer.scales | 0.0007     | 0.9142     | 0.1586    \n",
      "model.transformer.blocks.7.v_proj.weight | 0.0007     | -0.0007    | 0.7734    \n",
      "model.transformer.blocks.14.v_proj.weight | 0.0007     | -0.0002    | 0.4290    \n",
      "model.transformer.blocks.7.ff_out.weight_quantizer.scales | 0.0007     | 0.9941     | 0.0732    \n",
      "model.transformer.blocks.4.v_proj.weight | 0.0007     | -0.0003    | 0.5906    \n",
      "model.transformer.blocks.11.v_proj.weight | 0.0006     | 0.0000     | 0.3426    \n",
      "model.transformer.blocks.12.v_proj.weight | 0.0006     | -0.0002    | 0.5703    \n",
      "model.transformer.blocks.28.k_proj.weight_quantizer.scales | 0.0006     | 0.9247     | 0.1993    \n",
      "model.transformer.blocks.2.k_proj.weight_quantizer.scales | 0.0006     | 0.9640     | 0.0766    \n",
      "model.transformer.blocks.19.v_proj.weight | 0.0006     | 0.0005     | 0.4203    \n",
      "model.transformer.blocks.29.k_proj.weight_quantizer.scales | 0.0006     | 0.9271     | 0.1559    \n",
      "model.transformer.blocks.18.k_proj.weight_quantizer.scales | 0.0006     | 0.9089     | 0.1616    \n",
      "model.transformer.blocks.6.v_proj.weight | 0.0006     | -0.0000    | 0.7039    \n",
      "model.transformer.blocks.16.v_proj.weight | 0.0006     | 0.0006     | 0.4220    \n",
      "model.transformer.blocks.1.k_proj.weight_quantizer.scales | 0.0006     | 0.9604     | 0.1303    \n",
      "model.transformer.blocks.18.v_proj.weight | 0.0006     | -0.0002    | 0.4258    \n",
      "model.transformer.blocks.3.v_proj.weight | 0.0006     | -0.0000    | 0.5074    \n",
      "model.transformer.blocks.17.v_proj.weight | 0.0006     | 0.0004     | 0.4932    \n",
      "model.transformer.blocks.15.v_proj.weight | 0.0006     | -0.0004    | 0.6252    \n",
      "model.transformer.blocks.4.up_proj.weight | 0.0006     | 0.0000     | 0.6553    \n",
      "model.transformer.blocks.10.v_proj.weight | 0.0006     | 0.0003     | 0.4278    \n",
      "model.transformer.blocks.5.v_proj.weight | 0.0005     | -0.0011    | 0.7298    \n",
      "model.transformer.blocks.5.up_proj.weight | 0.0005     | 0.0001     | 0.5389    \n",
      "model.transformer.blocks.17.k_proj.weight_quantizer.scales | 0.0005     | 0.9179     | 0.2076    \n",
      "model.transformer.blocks.4.q_proj.weight_quantizer.scales | 0.0005     | 0.9578     | 0.1221    \n",
      "model.transformer.blocks.5.q_proj.weight_quantizer.scales | 0.0005     | 0.9470     | 0.1007    \n",
      "model.transformer.blocks.16.k_proj.weight_quantizer.scales | 0.0005     | 0.9232     | 0.1587    \n",
      "model.transformer.blocks.2.ff_out.weight_quantizer.scales | 0.0005     | 0.9939     | 0.0435    \n",
      "model.transformer.blocks.13.v_proj.weight | 0.0005     | -0.0002    | 0.3916    \n",
      "model.transformer.blocks.25.q_proj.weight_quantizer.scales | 0.0005     | 0.9381     | 0.1786    \n",
      "model.transformer.blocks.3.q_proj.weight_quantizer.scales | 0.0005     | 0.9669     | 0.1423    \n",
      "model.transformer.blocks.1.q_proj.weight_quantizer.scales | 0.0005     | 0.9701     | 0.1085    \n",
      "model.transformer.blocks.9.k_proj.weight_quantizer.scales | 0.0005     | 0.9398     | 0.1210    \n",
      "model.transformer.blocks.1.ff_out.weight_quantizer.scales | 0.0004     | 0.9927     | 0.0629    \n",
      "model.transformer.blocks.6.up_proj.weight | 0.0004     | -0.0002    | 0.6328    \n",
      "model.transformer.blocks.2.q_proj.weight_quantizer.scales | 0.0004     | 0.9786     | 0.0670    \n",
      "model.transformer.blocks.15.q_proj.weight_quantizer.scales | 0.0004     | 0.9353     | 0.1490    \n",
      "model.transformer.blocks.7.q_proj.weight_quantizer.scales | 0.0004     | 0.9467     | 0.1262    \n",
      "model.transformer.blocks.7.up_proj.weight | 0.0004     | -0.0002    | 0.5766    \n",
      "model.transformer.blocks.16.up_proj.weight | 0.0004     | 0.0008     | 0.5388    \n",
      "model.transformer.blocks.26.q_proj.weight_quantizer.scales | 0.0004     | 0.9416     | 0.1767    \n",
      "model.transformer.blocks.14.q_proj.weight_quantizer.scales | 0.0004     | 0.9349     | 0.1597    \n",
      "model.transformer.blocks.15.up_proj.weight | 0.0004     | -0.0003    | 0.5131    \n",
      "model.transformer.blocks.30.q_proj.weight_quantizer.scales | 0.0004     | 0.9467     | 0.1484    \n",
      "model.transformer.blocks.14.up_proj.weight | 0.0004     | 0.0001     | 0.5004    \n",
      "model.transformer.blocks.11.up_proj.weight | 0.0004     | -0.0003    | 0.4018    \n",
      "model.transformer.blocks.12.up_proj.weight | 0.0004     | 0.0007     | 0.6235    \n",
      "model.transformer.blocks.17.up_proj.weight | 0.0004     | -0.0003    | 0.7947    \n",
      "model.transformer.blocks.6.q_proj.weight_quantizer.scales | 0.0004     | 0.9563     | 0.1664    \n",
      "model.transformer.blocks.9.up_proj.weight | 0.0004     | -0.0003    | 0.5408    \n",
      "model.transformer.blocks.12.q_proj.weight_quantizer.scales | 0.0004     | 0.9406     | 0.1503    \n",
      "model.transformer.blocks.2.v_proj.weight | 0.0004     | -0.0003    | 0.5357    \n",
      "model.transformer.blocks.8.up_proj.weight | 0.0004     | 0.0002     | 0.4602    \n",
      "model.transformer.blocks.10.up_proj.weight | 0.0004     | -0.0007    | 0.6002    \n",
      "model.transformer.blocks.11.q_proj.weight_quantizer.scales | 0.0004     | 0.9415     | 0.1319    \n",
      "model.transformer.blocks.18.up_proj.weight | 0.0004     | -0.0000    | 0.4111    \n",
      "model.transformer.blocks.13.up_proj.weight | 0.0004     | 0.0000     | 0.4297    \n",
      "model.transformer.blocks.10.q_proj.weight_quantizer.scales | 0.0004     | 0.9451     | 0.1354    \n",
      "model.transformer.blocks.20.up_proj.weight | 0.0003     | 0.0002     | 0.4082    \n",
      "model.transformer.blocks.8.q_proj.weight_quantizer.scales | 0.0003     | 0.9483     | 0.1320    \n",
      "model.transformer.blocks.13.q_proj.weight_quantizer.scales | 0.0003     | 0.9412     | 0.1356    \n",
      "model.transformer.blocks.19.up_proj.weight | 0.0003     | 0.0006     | 0.5664    \n",
      "model.transformer.blocks.21.up_proj.weight | 0.0003     | -0.0000    | 0.4216    \n",
      "model.transformer.blocks.0.q_proj.weight_quantizer.scales | 0.0003     | 0.9007     | 0.0928    \n",
      "model.transformer.blocks.22.up_proj.weight | 0.0003     | -0.0002    | 0.4561    \n",
      "model.transformer.blocks.1.v_proj.weight | 0.0003     | -0.0005    | 0.5113    \n",
      "model.transformer.blocks.23.up_proj.weight | 0.0002     | -0.0006    | 0.3621    \n",
      "model.transformer.blocks.9.q_proj.weight_quantizer.scales | 0.0002     | 0.9698     | 0.0847    \n",
      "model.transformer.blocks.27.q_proj.weight_quantizer.scales | 0.0002     | 0.9611     | 0.1194    \n",
      "model.transformer.blocks.24.up_proj.weight | 0.0002     | 0.0004     | 0.4379    \n",
      "model.transformer.blocks.21.q_proj.weight_quantizer.scales | 0.0002     | 0.9607     | 0.0851    \n",
      "model.transformer.blocks.31.up_proj.weight | 0.0002     | 0.0005     | 0.5840    \n",
      "model.transformer.blocks.24.q_proj.weight_quantizer.scales | 0.0002     | 0.9625     | 0.1025    \n",
      "model.transformer.blocks.19.q_proj.weight_quantizer.scales | 0.0002     | 0.9620     | 0.0913    \n",
      "model.transformer.blocks.17.q_proj.weight_quantizer.scales | 0.0002     | 0.9600     | 0.1047    \n",
      "model.transformer.blocks.23.q_proj.weight_quantizer.scales | 0.0002     | 0.9615     | 0.0883    \n",
      "model.transformer.blocks.20.q_proj.weight_quantizer.scales | 0.0002     | 0.9607     | 0.1076    \n",
      "model.transformer.blocks.31.ff_proj.weight_quantizer.scales | 0.0002     | 0.9717     | 0.3592    \n",
      "model.transformer.blocks.31.q_proj.weight_quantizer.scales | 0.0002     | 0.9676     | 0.0946    \n",
      "model.transformer.blocks.22.q_proj.weight_quantizer.scales | 0.0002     | 0.9634     | 0.0992    \n",
      "model.transformer.blocks.30.up_proj.weight | 0.0002     | -0.0005    | 0.8127    \n",
      "model.transformer.blocks.29.q_proj.weight_quantizer.scales | 0.0002     | 0.9650     | 0.1005    \n",
      "model.transformer.blocks.28.q_proj.weight_quantizer.scales | 0.0002     | 0.9643     | 0.1129    \n",
      "model.transformer.blocks.25.up_proj.weight | 0.0002     | 0.0001     | 0.3652    \n",
      "model.transformer.blocks.16.q_proj.weight_quantizer.scales | 0.0002     | 0.9648     | 0.0898    \n",
      "model.transformer.blocks.0.attn_out.weight_quantizer.scales | 0.0002     | 0.9895     | 0.0414    \n",
      "model.transformer.blocks.29.up_proj.weight | 0.0002     | 0.0002     | 0.3161    \n",
      "model.transformer.blocks.18.q_proj.weight_quantizer.scales | 0.0002     | 0.9640     | 0.0873    \n",
      "model.transformer.blocks.0.ff_out.weight_quantizer.scales | 0.0002     | 0.9833     | 0.0740    \n",
      "model.transformer.blocks.28.up_proj.weight | 0.0002     | -0.0010    | 0.3182    \n",
      "model.transformer.blocks.26.up_proj.weight | 0.0002     | 0.0003     | 0.3535    \n",
      "model.transformer.blocks.31.attn_out.weight_quantizer.scales | 0.0001     | 0.9952     | 0.0681    \n",
      "model.transformer.blocks.27.up_proj.weight | 0.0001     | 0.0002     | 0.3011    \n",
      "model.transformer.blocks.30.attn_out.weight_quantizer.scales | 0.0001     | 0.9951     | 0.0663    \n",
      "model.transformer.blocks.10.attn_norm.weight | 0.0001     | 0.9987     | 0.0435    \n",
      "model.transformer.blocks.13.attn_norm.weight | 0.0001     | 0.9988     | 0.0463    \n",
      "model.transformer.blocks.30.ff_proj.weight_quantizer.scales | 0.0001     | 0.9826     | 0.1973    \n",
      "model.transformer.blocks.7.attn_norm.weight | 0.0001     | 0.9988     | 0.0432    \n",
      "model.transformer.blocks.12.attn_norm.weight | 0.0001     | 0.9987     | 0.0466    \n",
      "model.transformer.blocks.24.ff_proj.weight_quantizer.scales | 0.0001     | 0.9774     | 0.1862    \n",
      "model.transformer.blocks.16.attn_norm.weight | 0.0001     | 0.9990     | 0.0402    \n",
      "model.transformer.blocks.31.ff_norm.weight | 0.0001     | 0.9988     | 0.0515    \n",
      "model.transformer.blocks.19.attn_norm.weight | 0.0001     | 0.9991     | 0.0343    \n",
      "model.transformer.blocks.25.ff_proj.weight_quantizer.scales | 0.0001     | 0.9786     | 0.2240    \n",
      "model.transformer.blocks.17.attn_norm.weight | 0.0001     | 0.9990     | 0.0356    \n",
      "model.transformer.blocks.8.ff_norm.weight | 0.0001     | 0.9986     | 0.0326    \n",
      "model.transformer.blocks.14.attn_norm.weight | 0.0001     | 0.9989     | 0.0331    \n",
      "model.transformer.blocks.9.ff_norm.weight | 0.0001     | 0.9986     | 0.0305    \n",
      "model.transformer.blocks.15.attn_norm.weight | 0.0001     | 0.9989     | 0.0391    \n",
      "model.transformer.blocks.18.attn_norm.weight | 0.0001     | 0.9991     | 0.0326    \n",
      "model.transformer.blocks.29.attn_out.weight_quantizer.scales | 0.0001     | 0.9950     | 0.0607    \n",
      "model.transformer.blocks.2.attn_out.weight_quantizer.scales | 0.0001     | 0.9891     | 0.0362    \n",
      "model.transformer.blocks.22.attn_norm.weight | 0.0001     | 0.9991     | 0.0345    \n",
      "model.transformer.blocks.10.ff_norm.weight | 0.0001     | 0.9987     | 0.0359    \n",
      "model.transformer.blocks.21.attn_norm.weight | 0.0001     | 0.9991     | 0.0310    \n",
      "model.transformer.blocks.11.ff_norm.weight | 0.0001     | 0.9987     | 0.0352    \n",
      "model.transformer.blocks.11.attn_norm.weight | 0.0001     | 0.9988     | 0.0315    \n",
      "model.transformer.blocks.23.attn_norm.weight | 0.0001     | 0.9991     | 0.0334    \n",
      "model.transformer.blocks.8.attn_norm.weight | 0.0001     | 0.9987     | 0.0405    \n",
      "model.transformer.blocks.30.ff_norm.weight | 0.0001     | 0.9989     | 0.0328    \n",
      "model.transformer.blocks.20.attn_norm.weight | 0.0001     | 0.9991     | 0.0308    \n",
      "model.transformer.blocks.7.ff_norm.weight | 0.0001     | 0.9986     | 0.0329    \n",
      "model.transformer.blocks.12.ff_norm.weight | 0.0001     | 0.9987     | 0.0386    \n",
      "model.transformer.blocks.9.attn_norm.weight | 0.0001     | 0.9986     | 0.0420    \n",
      "model.transformer.blocks.21.ff_proj.weight_quantizer.scales | 0.0001     | 0.9772     | 0.3156    \n",
      "model.transformer.blocks.26.ff_proj.weight_quantizer.scales | 0.0001     | 0.9818     | 0.2534    \n",
      "model.transformer.blocks.13.ff_norm.weight | 0.0001     | 0.9988     | 0.0388    \n",
      "model.transformer.blocks.6.ff_norm.weight | 0.0001     | 0.9985     | 0.0335    \n",
      "model.transformer.blocks.4.attn_out.weight_quantizer.scales | 0.0001     | 0.9935     | 0.0289    \n",
      "model.transformer.blocks.14.ff_norm.weight | 0.0001     | 0.9989     | 0.0320    \n",
      "model.transformer.blocks.23.ff_norm.weight | 0.0001     | 0.9991     | 0.0326    \n",
      "model.transformer.blocks.24.attn_norm.weight | 0.0001     | 0.9991     | 0.0294    \n",
      "model.transformer.blocks.29.ff_norm.weight | 0.0001     | 0.9989     | 0.0291    \n",
      "model.transformer.blocks.24.ff_norm.weight | 0.0001     | 0.9991     | 0.0306    \n",
      "model.transformer.blocks.19.ff_norm.weight | 0.0001     | 0.9990     | 0.0269    \n",
      "model.transformer.blocks.22.ff_proj.weight_quantizer.scales | 0.0001     | 0.9801     | 0.1798    \n",
      "model.transformer.blocks.17.ff_proj.weight_quantizer.scales | 0.0001     | 0.9808     | 0.1507    \n",
      "model.transformer.blocks.25.attn_norm.weight | 0.0001     | 0.9991     | 0.0306    \n",
      "model.transformer.blocks.5.ff_norm.weight | 0.0001     | 0.9987     | 0.0308    \n",
      "model.transformer.blocks.22.ff_norm.weight | 0.0001     | 0.9991     | 0.0276    \n",
      "model.transformer.blocks.15.ff_norm.weight | 0.0001     | 0.9989     | 0.0345    \n",
      "model.transformer.blocks.20.ff_norm.weight | 0.0001     | 0.9990     | 0.0330    \n",
      "model.transformer.blocks.16.ff_norm.weight | 0.0001     | 0.9990     | 0.0311    \n",
      "model.transformer.blocks.21.ff_norm.weight | 0.0001     | 0.9991     | 0.0339    \n",
      "model.transformer.blocks.28.attn_out.weight_quantizer.scales | 0.0001     | 0.9949     | 0.0685    \n",
      "model.transformer.blocks.17.ff_norm.weight | 0.0001     | 0.9991     | 0.0336    \n",
      "model.transformer.blocks.18.ff_norm.weight | 0.0001     | 0.9990     | 0.0302    \n",
      "model.transformer.blocks.19.ff_proj.weight_quantizer.scales | 0.0001     | 0.9801     | 0.1899    \n",
      "model.transformer.blocks.28.ff_norm.weight | 0.0001     | 0.9990     | 0.0302    \n",
      "model.transformer.blocks.3.attn_out.weight_quantizer.scales | 0.0001     | 0.9920     | 0.0266    \n",
      "model.transformer.blocks.29.ff_proj.weight_quantizer.scales | 0.0001     | 0.9878     | 0.1642    \n",
      "model.transformer.blocks.1.attn_out.weight_quantizer.scales | 0.0001     | 0.9866     | 0.0570    \n",
      "model.transformer.blocks.5.attn_out.weight_quantizer.scales | 0.0001     | 0.9887     | 0.0606    \n",
      "model.transformer.blocks.25.ff_norm.weight | 0.0001     | 0.9992     | 0.0280    \n",
      "model.transformer.blocks.6.attn_norm.weight | 0.0001     | 0.9987     | 0.0574    \n",
      "model.transformer.blocks.26.ff_norm.weight | 0.0001     | 0.9992     | 0.0287    \n",
      "model.transformer.blocks.5.attn_norm.weight | 0.0001     | 0.9989     | 0.0356    \n",
      "model.transformer.blocks.23.ff_proj.weight_quantizer.scales | 0.0001     | 0.9833     | 0.1650    \n",
      "model.transformer.blocks.27.ff_proj.weight_quantizer.scales | 0.0001     | 0.9867     | 0.2405    \n",
      "model.transformer.blocks.27.ff_norm.weight | 0.0001     | 0.9991     | 0.0266    \n",
      "model.transformer.blocks.31.attn_norm.weight | 0.0001     | 0.9989     | 0.0362    \n",
      "model.transformer.blocks.20.ff_proj.weight_quantizer.scales | 0.0001     | 0.9824     | 0.1270    \n",
      "model.transformer.blocks.27.attn_out.weight_quantizer.scales | 0.0001     | 0.9951     | 0.0551    \n",
      "model.transformer.blocks.6.attn_out.weight_quantizer.scales | 0.0001     | 0.9924     | 0.0410    \n",
      "model.transformer.blocks.26.attn_norm.weight | 0.0001     | 0.9992     | 0.0275    \n",
      "model.transformer.blocks.30.attn_norm.weight | 0.0001     | 0.9989     | 0.0245    \n",
      "model.transformer.blocks.27.attn_norm.weight | 0.0000     | 0.9992     | 0.0342    \n",
      "model.transformer.blocks.28.attn_norm.weight | 0.0000     | 0.9990     | 0.0281    \n",
      "model.transformer.blocks.4.ff_norm.weight | 0.0000     | 0.9988     | 0.0249    \n",
      "model.transformer.blocks.15.ff_proj.weight_quantizer.scales | 0.0000     | 0.9828     | 0.1830    \n",
      "model.transformer.blocks.29.attn_norm.weight | 0.0000     | 0.9989     | 0.0214    \n",
      "model.transformer.blocks.26.attn_out.weight_quantizer.scales | 0.0000     | 0.9955     | 0.0532    \n",
      "model.transformer.blocks.16.ff_proj.weight_quantizer.scales | 0.0000     | 0.9859     | 0.1368    \n",
      "model.transformer.blocks.12.ff_proj.weight_quantizer.scales | 0.0000     | 0.9858     | 0.1559    \n",
      "model.transformer.blocks.11.ff_proj.weight_quantizer.scales | 0.0000     | 0.9865     | 0.1089    \n",
      "model.transformer.blocks.7.attn_out.weight_quantizer.scales | 0.0000     | 0.9937     | 0.0416    \n",
      "model.transformer.blocks.8.attn_out.weight_quantizer.scales | 0.0000     | 0.9931     | 0.0418    \n",
      "model.transformer.blocks.14.ff_proj.weight_quantizer.scales | 0.0000     | 0.9866     | 0.1701    \n",
      "model.transformer.blocks.28.ff_proj.weight_quantizer.scales | 0.0000     | 0.9918     | 0.1166    \n",
      "model.transformer.blocks.18.ff_proj.weight_quantizer.scales | 0.0000     | 0.9872     | 0.1483    \n",
      "model.transformer.blocks.4.attn_norm.weight | 0.0000     | 0.9990     | 0.0376    \n",
      "model.transformer.blocks.25.attn_out.weight_quantizer.scales | 0.0000     | 0.9954     | 0.0374    \n",
      "model.transformer.blocks.9.attn_out.weight_quantizer.scales | 0.0000     | 0.9927     | 0.0609    \n",
      "model.transformer.blocks.3.ff_norm.weight | 0.0000     | 0.9990     | 0.0306    \n",
      "model.transformer.blocks.0.ff_proj.weight_quantizer.scales | 0.0000     | 0.9692     | 0.0634    \n",
      "model.transformer.blocks.10.attn_out.weight_quantizer.scales | 0.0000     | 0.9937     | 0.0748    \n",
      "model.transformer.blocks.24.attn_out.weight_quantizer.scales | 0.0000     | 0.9954     | 0.0423    \n",
      "model.transformer.blocks.10.ff_proj.weight_quantizer.scales | 0.0000     | 0.9900     | 0.1214    \n",
      "model.transformer.blocks.11.attn_out.weight_quantizer.scales | 0.0000     | 0.9937     | 0.0481    \n",
      "model.transformer.blocks.14.attn_out.weight_quantizer.scales | 0.0000     | 0.9946     | 0.0526    \n",
      "model.transformer.blocks.13.ff_proj.weight_quantizer.scales | 0.0000     | 0.9913     | 0.1518    \n",
      "model.transformer.blocks.12.attn_out.weight_quantizer.scales | 0.0000     | 0.9939     | 0.0518    \n",
      "model.transformer.blocks.17.attn_out.weight_quantizer.scales | 0.0000     | 0.9950     | 0.0425    \n",
      "model.transformer.blocks.23.attn_out.weight_quantizer.scales | 0.0000     | 0.9954     | 0.0343    \n",
      "model.transformer.blocks.15.attn_out.weight_quantizer.scales | 0.0000     | 0.9944     | 0.0566    \n",
      "model.transformer.blocks.18.attn_out.weight_quantizer.scales | 0.0000     | 0.9947     | 0.0394    \n",
      "model.transformer.blocks.21.attn_out.weight_quantizer.scales | 0.0000     | 0.9954     | 0.0416    \n",
      "model.transformer.blocks.22.attn_out.weight_quantizer.scales | 0.0000     | 0.9957     | 0.0346    \n",
      "model.transformer.blocks.0.up_proj.weight_quantizer.scales | 0.0000     | 0.9743     | 0.0479    \n",
      "model.transformer.blocks.16.attn_out.weight_quantizer.scales | 0.0000     | 0.9948     | 0.0575    \n",
      "model.transformer.blocks.4.v_proj.weight_quantizer.scales | 0.0000     | 0.9252     | 0.0536    \n",
      "model.transformer.blocks.19.attn_out.weight_quantizer.scales | 0.0000     | 0.9951     | 0.0525    \n",
      "model.transformer.blocks.6.v_proj.weight_quantizer.scales | 0.0000     | 0.9199     | 0.0486    \n",
      "model.transformer.blocks.13.attn_out.weight_quantizer.scales | 0.0000     | 0.9947     | 0.0341    \n",
      "model.transformer.blocks.20.attn_out.weight_quantizer.scales | 0.0000     | 0.9955     | 0.0458    \n",
      "model.transformer.blocks.2.ff_norm.weight | 0.0000     | 0.9990     | 0.0244    \n",
      "model.transformer.blocks.9.ff_proj.weight_quantizer.scales | 0.0000     | 0.9931     | 0.1190    \n",
      "model.transformer.blocks.8.ff_proj.weight_quantizer.scales | 0.0000     | 0.9933     | 0.0898    \n",
      "model.transformer.blocks.7.ff_proj.weight_quantizer.scales | 0.0000     | 0.9928     | 0.0777    \n",
      "model.transformer.blocks.3.attn_norm.weight | 0.0000     | 0.9992     | 0.0306    \n",
      "model.transformer.blocks.6.ff_proj.weight_quantizer.scales | 0.0000     | 0.9916     | 0.0922    \n",
      "model.transformer.blocks.3.v_proj.weight_quantizer.scales | 0.0000     | 0.9563     | 0.0416    \n",
      "model.transformer.blocks.2.attn_norm.weight | 0.0000     | 0.9992     | 0.0298    \n",
      "model.transformer.blocks.1.v_proj.weight_quantizer.scales | 0.0000     | 0.9531     | 0.0383    \n",
      "model.transformer.blocks.1.ff_proj.weight_quantizer.scales | 0.0000     | 0.9829     | 0.0797    \n",
      "model.transformer.blocks.5.ff_proj.weight_quantizer.scales | 0.0000     | 0.9931     | 0.0660    \n",
      "model.transformer.blocks.3.ff_proj.weight_quantizer.scales | 0.0000     | 0.9899     | 0.0782    \n",
      "model.transformer.blocks.1.ff_norm.weight | 0.0000     | 0.9991     | 0.0164    \n",
      "model.transformer.blocks.4.ff_proj.weight_quantizer.scales | 0.0000     | 0.9916     | 0.0774    \n",
      "model.transformer.blocks.5.v_proj.weight_quantizer.scales | 0.0000     | 0.9408     | 0.0686    \n",
      "model.transformer.blocks.2.v_proj.weight_quantizer.scales | 0.0000     | 0.9602     | 0.0429    \n",
      "model.transformer.blocks.20.v_proj.weight_quantizer.scales | 0.0000     | 0.9539     | 0.0351    \n",
      "model.transformer.blocks.7.v_proj.weight_quantizer.scales | 0.0000     | 0.9507     | 0.0589    \n",
      "model.transformer.blocks.21.v_proj.weight_quantizer.scales | 0.0000     | 0.9553     | 0.0377    \n",
      "model.transformer.blocks.25.v_proj.weight_quantizer.scales | 0.0000     | 0.9591     | 0.0365    \n",
      "model.transformer.blocks.2.ff_proj.weight_quantizer.scales | 0.0000     | 0.9907     | 0.0488    \n",
      "model.transformer.blocks.0.attn_norm.weight | 0.0000     | 0.9992     | 0.0312    \n",
      "model.transformer.blocks.22.v_proj.weight_quantizer.scales | 0.0000     | 0.9652     | 0.0412    \n",
      "model.transformer.blocks.1.up_proj.weight_quantizer.scales | 0.0000     | 0.9799     | 0.0316    \n",
      "model.transformer.blocks.27.v_proj.weight_quantizer.scales | 0.0000     | 0.9743     | 0.0435    \n",
      "model.transformer.blocks.19.v_proj.weight_quantizer.scales | 0.0000     | 0.9651     | 0.0225    \n",
      "model.transformer.blocks.1.attn_norm.weight | 0.0000     | 0.9992     | 0.0218    \n",
      "model.transformer.blocks.23.v_proj.weight_quantizer.scales | 0.0000     | 0.9692     | 0.0219    \n",
      "model.transformer.blocks.10.v_proj.weight_quantizer.scales | 0.0000     | 0.9618     | 0.0315    \n",
      "model.transformer.blocks.3.up_proj.weight_quantizer.scales | 0.0000     | 0.9672     | 0.0775    \n",
      "model.transformer.blocks.12.v_proj.weight_quantizer.scales | 0.0000     | 0.9689     | 0.0459    \n",
      "model.transformer.blocks.0.ff_norm.weight | 0.0000     | 0.9991     | 0.0144    \n",
      "model.transformer.blocks.8.v_proj.weight_quantizer.scales | 0.0000     | 0.9740     | 0.0325    \n",
      "model.transformer.blocks.18.v_proj.weight_quantizer.scales | 0.0000     | 0.9714     | 0.0263    \n",
      "model.transformer.blocks.9.v_proj.weight_quantizer.scales | 0.0000     | 0.9810     | 0.0335    \n",
      "model.transformer.blocks.2.up_proj.weight_quantizer.scales | 0.0000     | 0.9809     | 0.0197    \n",
      "model.transformer.blocks.31.v_proj.weight_quantizer.scales | 0.0000     | 0.9908     | 0.0190    \n",
      "model.transformer.blocks.30.v_proj.weight_quantizer.scales | 0.0000     | 0.9910     | 0.0163    \n",
      "model.transformer.blocks.26.v_proj.weight_quantizer.scales | 0.0000     | 0.9815     | 0.0172    \n",
      "model.transformer.blocks.6.up_proj.weight_quantizer.scales | 0.0000     | 0.9628     | 0.0557    \n",
      "model.transformer.blocks.7.up_proj.weight_quantizer.scales | 0.0000     | 0.9583     | 0.0430    \n",
      "model.transformer.blocks.4.up_proj.weight_quantizer.scales | 0.0000     | 0.9697     | 0.0457    \n",
      "model.transformer.blocks.24.v_proj.weight_quantizer.scales | 0.0000     | 0.9812     | 0.0151    \n",
      "model.transformer.blocks.17.v_proj.weight_quantizer.scales | 0.0000     | 0.9721     | 0.0315    \n",
      "model.transformer.blocks.17.up_proj.weight_quantizer.scales | 0.0000     | 0.9572     | 0.0465    \n",
      "model.transformer.blocks.14.v_proj.weight_quantizer.scales | 0.0000     | 0.9758     | 0.0271    \n",
      "model.transformer.blocks.12.up_proj.weight_quantizer.scales | 0.0000     | 0.9617     | 0.0508    \n",
      "model.transformer.blocks.16.v_proj.weight_quantizer.scales | 0.0000     | 0.9772     | 0.0240    \n",
      "model.transformer.blocks.28.v_proj.weight_quantizer.scales | 0.0000     | 0.9905     | 0.0187    \n",
      "model.transformer.blocks.10.up_proj.weight_quantizer.scales | 0.0000     | 0.9624     | 0.0401    \n",
      "model.transformer.blocks.29.v_proj.weight_quantizer.scales | 0.0000     | 0.9920     | 0.0167    \n",
      "model.transformer.blocks.5.up_proj.weight_quantizer.scales | 0.0000     | 0.9730     | 0.0414    \n",
      "model.transformer.blocks.11.v_proj.weight_quantizer.scales | 0.0000     | 0.9806     | 0.0194    \n",
      "model.transformer.blocks.16.up_proj.weight_quantizer.scales | 0.0000     | 0.9651     | 0.0299    \n",
      "model.transformer.blocks.0.v_proj.weight_quantizer.scales | 0.0000     | 0.9853     | 0.0185    \n",
      "model.transformer.blocks.11.up_proj.weight_quantizer.scales | 0.0000     | 0.9657     | 0.0323    \n",
      "model.transformer.blocks.9.up_proj.weight_quantizer.scales | 0.0000     | 0.9659     | 0.0306    \n",
      "model.transformer.blocks.15.up_proj.weight_quantizer.scales | 0.0000     | 0.9669     | 0.0375    \n",
      "model.transformer.blocks.8.up_proj.weight_quantizer.scales | 0.0000     | 0.9652     | 0.0399    \n",
      "model.transformer.blocks.21.up_proj.weight_quantizer.scales | 0.0000     | 0.9594     | 0.0369    \n",
      "model.transformer.blocks.15.v_proj.weight_quantizer.scales | 0.0000     | 0.9795     | 0.0364    \n",
      "model.transformer.blocks.19.up_proj.weight_quantizer.scales | 0.0000     | 0.9649     | 0.0405    \n",
      "model.transformer.blocks.14.up_proj.weight_quantizer.scales | 0.0000     | 0.9683     | 0.0271    \n",
      "model.transformer.blocks.13.up_proj.weight_quantizer.scales | 0.0000     | 0.9690     | 0.0324    \n",
      "model.transformer.blocks.20.up_proj.weight_quantizer.scales | 0.0000     | 0.9702     | 0.0247    \n",
      "model.transformer.blocks.18.up_proj.weight_quantizer.scales | 0.0000     | 0.9713     | 0.0217    \n",
      "model.transformer.blocks.30.up_proj.weight_quantizer.scales | 0.0000     | 0.9535     | 0.0543    \n",
      "model.transformer.blocks.22.up_proj.weight_quantizer.scales | 0.0000     | 0.9663     | 0.0256    \n",
      "model.transformer.blocks.31.up_proj.weight_quantizer.scales | 0.0000     | 0.9629     | 0.0383    \n",
      "model.transformer.blocks.24.up_proj.weight_quantizer.scales | 0.0000     | 0.9591     | 0.0366    \n",
      "model.transformer.blocks.13.v_proj.weight_quantizer.scales | 0.0000     | 0.9816     | 0.0274    \n",
      "model.transformer.blocks.23.up_proj.weight_quantizer.scales | 0.0000     | 0.9650     | 0.0262    \n",
      "model.transformer.blocks.25.up_proj.weight_quantizer.scales | 0.0000     | 0.9592     | 0.0313    \n",
      "model.transformer.blocks.26.up_proj.weight_quantizer.scales | 0.0000     | 0.9609     | 0.0349    \n",
      "model.transformer.blocks.29.up_proj.weight_quantizer.scales | 0.0000     | 0.9713     | 0.0294    \n",
      "model.transformer.blocks.27.up_proj.weight_quantizer.scales | 0.0000     | 0.9683     | 0.0334    \n",
      "model.transformer.blocks.28.up_proj.weight_quantizer.scales | 0.0000     | 0.9748     | 0.0143    \n",
      "model.transformer.blocks.5.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.embed_tokens.weight | 0.0000     | 1.5949     | 0.0000    \n",
      "model.transformer.blocks.12.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.0.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.ln_f.weight | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.9.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.30.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.6.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.26.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.4.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.7.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.28.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.5.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.12.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.21.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.2.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.13.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.wte.weight | 0.0000     | 1.5949     | 0.0000    \n",
      "model.transformer.blocks.25.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.11.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.14.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.23.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.25.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.19.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.qkt_smooth_scale | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.10.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.27.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.8.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.3.k_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.22.ff_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.ff_out.weight | 0.0000     | 1.4223     | 0.0000    \n",
      "model.transformer.blocks.23.ff_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.20.up_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.q_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.29.v_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.15.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.31.up_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.v_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.q_proj.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.18.attn_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.17.ff_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.16.attn_out.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.1.ff_out.weight_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n",
      "model.transformer.blocks.24.k_proj.act_quantizer.init_duquant_params | 0.0000     | 1.0000     | 0.0000    \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path_1 = \"models/quantized_model.pth\"\n",
    "model_path_2 = \"models/my_quantized_4_4.pth\"\n",
    "\n",
    "# Load state dicts (adjust if using safetensors or specific quant loaders)\n",
    "sd1 = torch.load(model_path_1, map_location=\"cpu\")\n",
    "sd2 = torch.load(model_path_2, map_location=\"cpu\")\n",
    "\n",
    "# Ensure keys match\n",
    "keys1, keys2 = set(sd1.keys()), set(sd2.keys())\n",
    "common_keys = keys1.intersection(keys2)\n",
    "print(keys1 ^ keys2)\n",
    "\n",
    "if len(common_keys) == 0:\n",
    "    print(\"Error: No matching layers found. Check naming conventions.\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for key in common_keys:\n",
    "    tensor1 = sd1[key].float().flatten()\n",
    "    tensor2 = sd2[key].float().flatten()\n",
    "    \n",
    "    # Check for shape mismatches (e.g., if one fused Q/K/V and the other didn't)\n",
    "    if tensor1.shape != tensor2.shape:\n",
    "        print(f\"Shape mismatch at {key}: {tensor1.shape} vs {tensor2.shape}\")\n",
    "        continue\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = F.mse_loss(tensor1, tensor2).item()\n",
    "    cos_sim = F.cosine_similarity(tensor1.unsqueeze(0), tensor2.unsqueeze(0)).item()\n",
    "    max_diff = torch.max(torch.abs(tensor1 - tensor2)).item()\n",
    "    \n",
    "    results.append({\n",
    "        \"layer\": key,\n",
    "        \"mse\": mse,\n",
    "        \"cos_sim\": cos_sim,\n",
    "        \"max_diff\": max_diff\n",
    "    })\n",
    "\n",
    "# Sort by MSE to find the most divergent layers\n",
    "results.sort(key=lambda x: x['mse'], reverse=True)\n",
    "\n",
    "print(f\"{'Layer Name':<45} | {'MSE':<10} | {'Cos Sim':<10} | {'Max Diff':<10}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "# Print the top 15 most divergent layers\n",
    "for res in results:\n",
    "    print(f\"{res['layer']} | {res['mse']:<10.4f} | {res['cos_sim']:<10.4f} | {res['max_diff']:<10.4f}\")\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c582c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11499,  7132,  3515,  ...,   501,  8872,  3334]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd1[\"model.transformer.blocks.1.ff_out.weight_quantizer.permutation_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05da494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11482,  1776,  4833,  ...,  1676, 11236,  2820]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd2[\"model.transformer.blocks.1.ff_out.weight_quantizer.permutation_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56fa034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.transformer.blocks.0.attn_norm.bias',\n",
       " 'model.transformer.blocks.0.attn_out.bias',\n",
       " 'model.transformer.blocks.0.down_smooth_shift',\n",
       " 'model.transformer.blocks.0.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.0.ff_norm.bias',\n",
       " 'model.transformer.blocks.0.ff_out.bias',\n",
       " 'model.transformer.blocks.0.ff_proj.bias',\n",
       " 'model.transformer.blocks.0.k_proj.bias',\n",
       " 'model.transformer.blocks.0.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.0.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.0.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.0.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.0.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.0.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.0.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.0.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.0.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.0.out_smooth_shift',\n",
       " 'model.transformer.blocks.0.q_proj.bias',\n",
       " 'model.transformer.blocks.0.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.0.up_proj.bias',\n",
       " 'model.transformer.blocks.0.v_proj.bias',\n",
       " 'model.transformer.blocks.1.attn_norm.bias',\n",
       " 'model.transformer.blocks.1.attn_out.bias',\n",
       " 'model.transformer.blocks.1.down_smooth_shift',\n",
       " 'model.transformer.blocks.1.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.1.ff_norm.bias',\n",
       " 'model.transformer.blocks.1.ff_out.bias',\n",
       " 'model.transformer.blocks.1.ff_proj.bias',\n",
       " 'model.transformer.blocks.1.k_proj.bias',\n",
       " 'model.transformer.blocks.1.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.1.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.1.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.1.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.1.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.1.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.1.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.1.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.1.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.1.out_smooth_shift',\n",
       " 'model.transformer.blocks.1.q_proj.bias',\n",
       " 'model.transformer.blocks.1.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.1.up_proj.bias',\n",
       " 'model.transformer.blocks.1.v_proj.bias',\n",
       " 'model.transformer.blocks.10.attn_norm.bias',\n",
       " 'model.transformer.blocks.10.attn_out.bias',\n",
       " 'model.transformer.blocks.10.down_smooth_shift',\n",
       " 'model.transformer.blocks.10.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.10.ff_norm.bias',\n",
       " 'model.transformer.blocks.10.ff_out.bias',\n",
       " 'model.transformer.blocks.10.ff_proj.bias',\n",
       " 'model.transformer.blocks.10.k_proj.bias',\n",
       " 'model.transformer.blocks.10.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.10.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.10.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.10.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.10.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.10.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.10.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.10.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.10.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.10.out_smooth_shift',\n",
       " 'model.transformer.blocks.10.q_proj.bias',\n",
       " 'model.transformer.blocks.10.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.10.up_proj.bias',\n",
       " 'model.transformer.blocks.10.v_proj.bias',\n",
       " 'model.transformer.blocks.11.attn_norm.bias',\n",
       " 'model.transformer.blocks.11.attn_out.bias',\n",
       " 'model.transformer.blocks.11.down_smooth_shift',\n",
       " 'model.transformer.blocks.11.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.11.ff_norm.bias',\n",
       " 'model.transformer.blocks.11.ff_out.bias',\n",
       " 'model.transformer.blocks.11.ff_proj.bias',\n",
       " 'model.transformer.blocks.11.k_proj.bias',\n",
       " 'model.transformer.blocks.11.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.11.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.11.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.11.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.11.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.11.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.11.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.11.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.11.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.11.out_smooth_shift',\n",
       " 'model.transformer.blocks.11.q_proj.bias',\n",
       " 'model.transformer.blocks.11.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.11.up_proj.bias',\n",
       " 'model.transformer.blocks.11.v_proj.bias',\n",
       " 'model.transformer.blocks.12.attn_norm.bias',\n",
       " 'model.transformer.blocks.12.attn_out.bias',\n",
       " 'model.transformer.blocks.12.down_smooth_shift',\n",
       " 'model.transformer.blocks.12.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.12.ff_norm.bias',\n",
       " 'model.transformer.blocks.12.ff_out.bias',\n",
       " 'model.transformer.blocks.12.ff_proj.bias',\n",
       " 'model.transformer.blocks.12.k_proj.bias',\n",
       " 'model.transformer.blocks.12.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.12.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.12.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.12.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.12.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.12.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.12.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.12.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.12.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.12.out_smooth_shift',\n",
       " 'model.transformer.blocks.12.q_proj.bias',\n",
       " 'model.transformer.blocks.12.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.12.up_proj.bias',\n",
       " 'model.transformer.blocks.12.v_proj.bias',\n",
       " 'model.transformer.blocks.13.attn_norm.bias',\n",
       " 'model.transformer.blocks.13.attn_out.bias',\n",
       " 'model.transformer.blocks.13.down_smooth_shift',\n",
       " 'model.transformer.blocks.13.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.13.ff_norm.bias',\n",
       " 'model.transformer.blocks.13.ff_out.bias',\n",
       " 'model.transformer.blocks.13.ff_proj.bias',\n",
       " 'model.transformer.blocks.13.k_proj.bias',\n",
       " 'model.transformer.blocks.13.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.13.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.13.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.13.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.13.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.13.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.13.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.13.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.13.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.13.out_smooth_shift',\n",
       " 'model.transformer.blocks.13.q_proj.bias',\n",
       " 'model.transformer.blocks.13.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.13.up_proj.bias',\n",
       " 'model.transformer.blocks.13.v_proj.bias',\n",
       " 'model.transformer.blocks.14.attn_norm.bias',\n",
       " 'model.transformer.blocks.14.attn_out.bias',\n",
       " 'model.transformer.blocks.14.down_smooth_shift',\n",
       " 'model.transformer.blocks.14.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.14.ff_norm.bias',\n",
       " 'model.transformer.blocks.14.ff_out.bias',\n",
       " 'model.transformer.blocks.14.ff_proj.bias',\n",
       " 'model.transformer.blocks.14.k_proj.bias',\n",
       " 'model.transformer.blocks.14.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.14.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.14.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.14.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.14.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.14.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.14.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.14.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.14.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.14.out_smooth_shift',\n",
       " 'model.transformer.blocks.14.q_proj.bias',\n",
       " 'model.transformer.blocks.14.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.14.up_proj.bias',\n",
       " 'model.transformer.blocks.14.v_proj.bias',\n",
       " 'model.transformer.blocks.15.attn_norm.bias',\n",
       " 'model.transformer.blocks.15.attn_out.bias',\n",
       " 'model.transformer.blocks.15.down_smooth_shift',\n",
       " 'model.transformer.blocks.15.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.15.ff_norm.bias',\n",
       " 'model.transformer.blocks.15.ff_out.bias',\n",
       " 'model.transformer.blocks.15.ff_proj.bias',\n",
       " 'model.transformer.blocks.15.k_proj.bias',\n",
       " 'model.transformer.blocks.15.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.15.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.15.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.15.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.15.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.15.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.15.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.15.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.15.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.15.out_smooth_shift',\n",
       " 'model.transformer.blocks.15.q_proj.bias',\n",
       " 'model.transformer.blocks.15.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.15.up_proj.bias',\n",
       " 'model.transformer.blocks.15.v_proj.bias',\n",
       " 'model.transformer.blocks.16.attn_norm.bias',\n",
       " 'model.transformer.blocks.16.attn_out.bias',\n",
       " 'model.transformer.blocks.16.down_smooth_shift',\n",
       " 'model.transformer.blocks.16.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.16.ff_norm.bias',\n",
       " 'model.transformer.blocks.16.ff_out.bias',\n",
       " 'model.transformer.blocks.16.ff_proj.bias',\n",
       " 'model.transformer.blocks.16.k_proj.bias',\n",
       " 'model.transformer.blocks.16.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.16.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.16.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.16.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.16.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.16.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.16.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.16.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.16.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.16.out_smooth_shift',\n",
       " 'model.transformer.blocks.16.q_proj.bias',\n",
       " 'model.transformer.blocks.16.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.16.up_proj.bias',\n",
       " 'model.transformer.blocks.16.v_proj.bias',\n",
       " 'model.transformer.blocks.17.attn_norm.bias',\n",
       " 'model.transformer.blocks.17.attn_out.bias',\n",
       " 'model.transformer.blocks.17.down_smooth_shift',\n",
       " 'model.transformer.blocks.17.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.17.ff_norm.bias',\n",
       " 'model.transformer.blocks.17.ff_out.bias',\n",
       " 'model.transformer.blocks.17.ff_proj.bias',\n",
       " 'model.transformer.blocks.17.k_proj.bias',\n",
       " 'model.transformer.blocks.17.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.17.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.17.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.17.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.17.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.17.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.17.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.17.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.17.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.17.out_smooth_shift',\n",
       " 'model.transformer.blocks.17.q_proj.bias',\n",
       " 'model.transformer.blocks.17.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.17.up_proj.bias',\n",
       " 'model.transformer.blocks.17.v_proj.bias',\n",
       " 'model.transformer.blocks.18.attn_norm.bias',\n",
       " 'model.transformer.blocks.18.attn_out.bias',\n",
       " 'model.transformer.blocks.18.down_smooth_shift',\n",
       " 'model.transformer.blocks.18.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.18.ff_norm.bias',\n",
       " 'model.transformer.blocks.18.ff_out.bias',\n",
       " 'model.transformer.blocks.18.ff_proj.bias',\n",
       " 'model.transformer.blocks.18.k_proj.bias',\n",
       " 'model.transformer.blocks.18.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.18.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.18.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.18.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.18.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.18.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.18.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.18.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.18.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.18.out_smooth_shift',\n",
       " 'model.transformer.blocks.18.q_proj.bias',\n",
       " 'model.transformer.blocks.18.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.18.up_proj.bias',\n",
       " 'model.transformer.blocks.18.v_proj.bias',\n",
       " 'model.transformer.blocks.19.attn_norm.bias',\n",
       " 'model.transformer.blocks.19.attn_out.bias',\n",
       " 'model.transformer.blocks.19.down_smooth_shift',\n",
       " 'model.transformer.blocks.19.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.19.ff_norm.bias',\n",
       " 'model.transformer.blocks.19.ff_out.bias',\n",
       " 'model.transformer.blocks.19.ff_proj.bias',\n",
       " 'model.transformer.blocks.19.k_proj.bias',\n",
       " 'model.transformer.blocks.19.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.19.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.19.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.19.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.19.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.19.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.19.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.19.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.19.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.19.out_smooth_shift',\n",
       " 'model.transformer.blocks.19.q_proj.bias',\n",
       " 'model.transformer.blocks.19.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.19.up_proj.bias',\n",
       " 'model.transformer.blocks.19.v_proj.bias',\n",
       " 'model.transformer.blocks.2.attn_norm.bias',\n",
       " 'model.transformer.blocks.2.attn_out.bias',\n",
       " 'model.transformer.blocks.2.down_smooth_shift',\n",
       " 'model.transformer.blocks.2.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.2.ff_norm.bias',\n",
       " 'model.transformer.blocks.2.ff_out.bias',\n",
       " 'model.transformer.blocks.2.ff_proj.bias',\n",
       " 'model.transformer.blocks.2.k_proj.bias',\n",
       " 'model.transformer.blocks.2.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.2.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.2.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.2.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.2.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.2.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.2.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.2.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.2.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.2.out_smooth_shift',\n",
       " 'model.transformer.blocks.2.q_proj.bias',\n",
       " 'model.transformer.blocks.2.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.2.up_proj.bias',\n",
       " 'model.transformer.blocks.2.v_proj.bias',\n",
       " 'model.transformer.blocks.20.attn_norm.bias',\n",
       " 'model.transformer.blocks.20.attn_out.bias',\n",
       " 'model.transformer.blocks.20.down_smooth_shift',\n",
       " 'model.transformer.blocks.20.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.20.ff_norm.bias',\n",
       " 'model.transformer.blocks.20.ff_out.bias',\n",
       " 'model.transformer.blocks.20.ff_proj.bias',\n",
       " 'model.transformer.blocks.20.k_proj.bias',\n",
       " 'model.transformer.blocks.20.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.20.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.20.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.20.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.20.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.20.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.20.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.20.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.20.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.20.out_smooth_shift',\n",
       " 'model.transformer.blocks.20.q_proj.bias',\n",
       " 'model.transformer.blocks.20.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.20.up_proj.bias',\n",
       " 'model.transformer.blocks.20.v_proj.bias',\n",
       " 'model.transformer.blocks.21.attn_norm.bias',\n",
       " 'model.transformer.blocks.21.attn_out.bias',\n",
       " 'model.transformer.blocks.21.down_smooth_shift',\n",
       " 'model.transformer.blocks.21.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.21.ff_norm.bias',\n",
       " 'model.transformer.blocks.21.ff_out.bias',\n",
       " 'model.transformer.blocks.21.ff_proj.bias',\n",
       " 'model.transformer.blocks.21.k_proj.bias',\n",
       " 'model.transformer.blocks.21.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.21.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.21.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.21.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.21.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.21.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.21.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.21.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.21.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.21.out_smooth_shift',\n",
       " 'model.transformer.blocks.21.q_proj.bias',\n",
       " 'model.transformer.blocks.21.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.21.up_proj.bias',\n",
       " 'model.transformer.blocks.21.v_proj.bias',\n",
       " 'model.transformer.blocks.22.attn_norm.bias',\n",
       " 'model.transformer.blocks.22.attn_out.bias',\n",
       " 'model.transformer.blocks.22.down_smooth_shift',\n",
       " 'model.transformer.blocks.22.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.22.ff_norm.bias',\n",
       " 'model.transformer.blocks.22.ff_out.bias',\n",
       " 'model.transformer.blocks.22.ff_proj.bias',\n",
       " 'model.transformer.blocks.22.k_proj.bias',\n",
       " 'model.transformer.blocks.22.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.22.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.22.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.22.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.22.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.22.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.22.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.22.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.22.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.22.out_smooth_shift',\n",
       " 'model.transformer.blocks.22.q_proj.bias',\n",
       " 'model.transformer.blocks.22.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.22.up_proj.bias',\n",
       " 'model.transformer.blocks.22.v_proj.bias',\n",
       " 'model.transformer.blocks.23.attn_norm.bias',\n",
       " 'model.transformer.blocks.23.attn_out.bias',\n",
       " 'model.transformer.blocks.23.down_smooth_shift',\n",
       " 'model.transformer.blocks.23.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.23.ff_norm.bias',\n",
       " 'model.transformer.blocks.23.ff_out.bias',\n",
       " 'model.transformer.blocks.23.ff_proj.bias',\n",
       " 'model.transformer.blocks.23.k_proj.bias',\n",
       " 'model.transformer.blocks.23.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.23.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.23.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.23.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.23.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.23.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.23.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.23.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.23.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.23.out_smooth_shift',\n",
       " 'model.transformer.blocks.23.q_proj.bias',\n",
       " 'model.transformer.blocks.23.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.23.up_proj.bias',\n",
       " 'model.transformer.blocks.23.v_proj.bias',\n",
       " 'model.transformer.blocks.24.attn_norm.bias',\n",
       " 'model.transformer.blocks.24.attn_out.bias',\n",
       " 'model.transformer.blocks.24.down_smooth_shift',\n",
       " 'model.transformer.blocks.24.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.24.ff_norm.bias',\n",
       " 'model.transformer.blocks.24.ff_out.bias',\n",
       " 'model.transformer.blocks.24.ff_proj.bias',\n",
       " 'model.transformer.blocks.24.k_proj.bias',\n",
       " 'model.transformer.blocks.24.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.24.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.24.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.24.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.24.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.24.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.24.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.24.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.24.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.24.out_smooth_shift',\n",
       " 'model.transformer.blocks.24.q_proj.bias',\n",
       " 'model.transformer.blocks.24.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.24.up_proj.bias',\n",
       " 'model.transformer.blocks.24.v_proj.bias',\n",
       " 'model.transformer.blocks.25.attn_norm.bias',\n",
       " 'model.transformer.blocks.25.attn_out.bias',\n",
       " 'model.transformer.blocks.25.down_smooth_shift',\n",
       " 'model.transformer.blocks.25.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.25.ff_norm.bias',\n",
       " 'model.transformer.blocks.25.ff_out.bias',\n",
       " 'model.transformer.blocks.25.ff_proj.bias',\n",
       " 'model.transformer.blocks.25.k_proj.bias',\n",
       " 'model.transformer.blocks.25.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.25.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.25.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.25.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.25.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.25.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.25.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.25.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.25.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.25.out_smooth_shift',\n",
       " 'model.transformer.blocks.25.q_proj.bias',\n",
       " 'model.transformer.blocks.25.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.25.up_proj.bias',\n",
       " 'model.transformer.blocks.25.v_proj.bias',\n",
       " 'model.transformer.blocks.26.attn_norm.bias',\n",
       " 'model.transformer.blocks.26.attn_out.bias',\n",
       " 'model.transformer.blocks.26.down_smooth_shift',\n",
       " 'model.transformer.blocks.26.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.26.ff_norm.bias',\n",
       " 'model.transformer.blocks.26.ff_out.bias',\n",
       " 'model.transformer.blocks.26.ff_proj.bias',\n",
       " 'model.transformer.blocks.26.k_proj.bias',\n",
       " 'model.transformer.blocks.26.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.26.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.26.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.26.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.26.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.26.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.26.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.26.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.26.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.26.out_smooth_shift',\n",
       " 'model.transformer.blocks.26.q_proj.bias',\n",
       " 'model.transformer.blocks.26.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.26.up_proj.bias',\n",
       " 'model.transformer.blocks.26.v_proj.bias',\n",
       " 'model.transformer.blocks.27.attn_norm.bias',\n",
       " 'model.transformer.blocks.27.attn_out.bias',\n",
       " 'model.transformer.blocks.27.down_smooth_shift',\n",
       " 'model.transformer.blocks.27.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.27.ff_norm.bias',\n",
       " 'model.transformer.blocks.27.ff_out.bias',\n",
       " 'model.transformer.blocks.27.ff_proj.bias',\n",
       " 'model.transformer.blocks.27.k_proj.bias',\n",
       " 'model.transformer.blocks.27.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.27.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.27.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.27.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.27.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.27.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.27.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.27.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.27.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.27.out_smooth_shift',\n",
       " 'model.transformer.blocks.27.q_proj.bias',\n",
       " 'model.transformer.blocks.27.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.27.up_proj.bias',\n",
       " 'model.transformer.blocks.27.v_proj.bias',\n",
       " 'model.transformer.blocks.28.attn_norm.bias',\n",
       " 'model.transformer.blocks.28.attn_out.bias',\n",
       " 'model.transformer.blocks.28.down_smooth_shift',\n",
       " 'model.transformer.blocks.28.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.28.ff_norm.bias',\n",
       " 'model.transformer.blocks.28.ff_out.bias',\n",
       " 'model.transformer.blocks.28.ff_proj.bias',\n",
       " 'model.transformer.blocks.28.k_proj.bias',\n",
       " 'model.transformer.blocks.28.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.28.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.28.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.28.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.28.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.28.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.28.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.28.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.28.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.28.out_smooth_shift',\n",
       " 'model.transformer.blocks.28.q_proj.bias',\n",
       " 'model.transformer.blocks.28.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.28.up_proj.bias',\n",
       " 'model.transformer.blocks.28.v_proj.bias',\n",
       " 'model.transformer.blocks.29.attn_norm.bias',\n",
       " 'model.transformer.blocks.29.attn_out.bias',\n",
       " 'model.transformer.blocks.29.down_smooth_shift',\n",
       " 'model.transformer.blocks.29.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.29.ff_norm.bias',\n",
       " 'model.transformer.blocks.29.ff_out.bias',\n",
       " 'model.transformer.blocks.29.ff_proj.bias',\n",
       " 'model.transformer.blocks.29.k_proj.bias',\n",
       " 'model.transformer.blocks.29.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.29.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.29.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.29.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.29.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.29.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.29.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.29.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.29.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.29.out_smooth_shift',\n",
       " 'model.transformer.blocks.29.q_proj.bias',\n",
       " 'model.transformer.blocks.29.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.29.up_proj.bias',\n",
       " 'model.transformer.blocks.29.v_proj.bias',\n",
       " 'model.transformer.blocks.3.attn_norm.bias',\n",
       " 'model.transformer.blocks.3.attn_out.bias',\n",
       " 'model.transformer.blocks.3.down_smooth_shift',\n",
       " 'model.transformer.blocks.3.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.3.ff_norm.bias',\n",
       " 'model.transformer.blocks.3.ff_out.bias',\n",
       " 'model.transformer.blocks.3.ff_proj.bias',\n",
       " 'model.transformer.blocks.3.k_proj.bias',\n",
       " 'model.transformer.blocks.3.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.3.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.3.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.3.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.3.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.3.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.3.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.3.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.3.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.3.out_smooth_shift',\n",
       " 'model.transformer.blocks.3.q_proj.bias',\n",
       " 'model.transformer.blocks.3.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.3.up_proj.bias',\n",
       " 'model.transformer.blocks.3.v_proj.bias',\n",
       " 'model.transformer.blocks.30.attn_norm.bias',\n",
       " 'model.transformer.blocks.30.attn_out.bias',\n",
       " 'model.transformer.blocks.30.down_smooth_shift',\n",
       " 'model.transformer.blocks.30.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.30.ff_norm.bias',\n",
       " 'model.transformer.blocks.30.ff_out.bias',\n",
       " 'model.transformer.blocks.30.ff_proj.bias',\n",
       " 'model.transformer.blocks.30.k_proj.bias',\n",
       " 'model.transformer.blocks.30.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.30.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.30.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.30.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.30.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.30.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.30.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.30.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.30.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.30.out_smooth_shift',\n",
       " 'model.transformer.blocks.30.q_proj.bias',\n",
       " 'model.transformer.blocks.30.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.30.up_proj.bias',\n",
       " 'model.transformer.blocks.30.v_proj.bias',\n",
       " 'model.transformer.blocks.31.attn_norm.bias',\n",
       " 'model.transformer.blocks.31.attn_out.bias',\n",
       " 'model.transformer.blocks.31.down_smooth_shift',\n",
       " 'model.transformer.blocks.31.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.31.ff_norm.bias',\n",
       " 'model.transformer.blocks.31.ff_out.bias',\n",
       " 'model.transformer.blocks.31.ff_proj.bias',\n",
       " 'model.transformer.blocks.31.k_proj.bias',\n",
       " 'model.transformer.blocks.31.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.31.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.31.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.31.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.31.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.31.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.31.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.31.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.31.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.31.out_smooth_shift',\n",
       " 'model.transformer.blocks.31.q_proj.bias',\n",
       " 'model.transformer.blocks.31.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.31.up_proj.bias',\n",
       " 'model.transformer.blocks.31.v_proj.bias',\n",
       " 'model.transformer.blocks.4.attn_norm.bias',\n",
       " 'model.transformer.blocks.4.attn_out.bias',\n",
       " 'model.transformer.blocks.4.down_smooth_shift',\n",
       " 'model.transformer.blocks.4.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.4.ff_norm.bias',\n",
       " 'model.transformer.blocks.4.ff_out.bias',\n",
       " 'model.transformer.blocks.4.ff_proj.bias',\n",
       " 'model.transformer.blocks.4.k_proj.bias',\n",
       " 'model.transformer.blocks.4.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.4.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.4.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.4.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.4.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.4.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.4.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.4.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.4.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.4.out_smooth_shift',\n",
       " 'model.transformer.blocks.4.q_proj.bias',\n",
       " 'model.transformer.blocks.4.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.4.up_proj.bias',\n",
       " 'model.transformer.blocks.4.v_proj.bias',\n",
       " 'model.transformer.blocks.5.attn_norm.bias',\n",
       " 'model.transformer.blocks.5.attn_out.bias',\n",
       " 'model.transformer.blocks.5.down_smooth_shift',\n",
       " 'model.transformer.blocks.5.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.5.ff_norm.bias',\n",
       " 'model.transformer.blocks.5.ff_out.bias',\n",
       " 'model.transformer.blocks.5.ff_proj.bias',\n",
       " 'model.transformer.blocks.5.k_proj.bias',\n",
       " 'model.transformer.blocks.5.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.5.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.5.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.5.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.5.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.5.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.5.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.5.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.5.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.5.out_smooth_shift',\n",
       " 'model.transformer.blocks.5.q_proj.bias',\n",
       " 'model.transformer.blocks.5.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.5.up_proj.bias',\n",
       " 'model.transformer.blocks.5.v_proj.bias',\n",
       " 'model.transformer.blocks.6.attn_norm.bias',\n",
       " 'model.transformer.blocks.6.attn_out.bias',\n",
       " 'model.transformer.blocks.6.down_smooth_shift',\n",
       " 'model.transformer.blocks.6.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.6.ff_norm.bias',\n",
       " 'model.transformer.blocks.6.ff_out.bias',\n",
       " 'model.transformer.blocks.6.ff_proj.bias',\n",
       " 'model.transformer.blocks.6.k_proj.bias',\n",
       " 'model.transformer.blocks.6.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.6.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.6.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.6.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.6.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.6.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.6.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.6.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.6.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.6.out_smooth_shift',\n",
       " 'model.transformer.blocks.6.q_proj.bias',\n",
       " 'model.transformer.blocks.6.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.6.up_proj.bias',\n",
       " 'model.transformer.blocks.6.v_proj.bias',\n",
       " 'model.transformer.blocks.7.attn_norm.bias',\n",
       " 'model.transformer.blocks.7.attn_out.bias',\n",
       " 'model.transformer.blocks.7.down_smooth_shift',\n",
       " 'model.transformer.blocks.7.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.7.ff_norm.bias',\n",
       " 'model.transformer.blocks.7.ff_out.bias',\n",
       " 'model.transformer.blocks.7.ff_proj.bias',\n",
       " 'model.transformer.blocks.7.k_proj.bias',\n",
       " 'model.transformer.blocks.7.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.7.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.7.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.7.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.7.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.7.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.7.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.7.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.7.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.7.out_smooth_shift',\n",
       " 'model.transformer.blocks.7.q_proj.bias',\n",
       " 'model.transformer.blocks.7.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.7.up_proj.bias',\n",
       " 'model.transformer.blocks.7.v_proj.bias',\n",
       " 'model.transformer.blocks.8.attn_norm.bias',\n",
       " 'model.transformer.blocks.8.attn_out.bias',\n",
       " 'model.transformer.blocks.8.down_smooth_shift',\n",
       " 'model.transformer.blocks.8.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.8.ff_norm.bias',\n",
       " 'model.transformer.blocks.8.ff_out.bias',\n",
       " 'model.transformer.blocks.8.ff_proj.bias',\n",
       " 'model.transformer.blocks.8.k_proj.bias',\n",
       " 'model.transformer.blocks.8.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.8.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.8.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.8.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.8.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.8.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.8.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.8.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.8.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.8.out_smooth_shift',\n",
       " 'model.transformer.blocks.8.q_proj.bias',\n",
       " 'model.transformer.blocks.8.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.8.up_proj.bias',\n",
       " 'model.transformer.blocks.8.v_proj.bias',\n",
       " 'model.transformer.blocks.9.attn_norm.bias',\n",
       " 'model.transformer.blocks.9.attn_out.bias',\n",
       " 'model.transformer.blocks.9.down_smooth_shift',\n",
       " 'model.transformer.blocks.9.fc1_smooth_shift',\n",
       " 'model.transformer.blocks.9.ff_norm.bias',\n",
       " 'model.transformer.blocks.9.ff_out.bias',\n",
       " 'model.transformer.blocks.9.ff_proj.bias',\n",
       " 'model.transformer.blocks.9.k_proj.bias',\n",
       " 'model.transformer.blocks.9.ori_layer.attn_norm.weight',\n",
       " 'model.transformer.blocks.9.ori_layer.attn_out.weight',\n",
       " 'model.transformer.blocks.9.ori_layer.ff_norm.weight',\n",
       " 'model.transformer.blocks.9.ori_layer.ff_out.weight',\n",
       " 'model.transformer.blocks.9.ori_layer.ff_proj.weight',\n",
       " 'model.transformer.blocks.9.ori_layer.k_proj.weight',\n",
       " 'model.transformer.blocks.9.ori_layer.q_proj.weight',\n",
       " 'model.transformer.blocks.9.ori_layer.up_proj.weight',\n",
       " 'model.transformer.blocks.9.ori_layer.v_proj.weight',\n",
       " 'model.transformer.blocks.9.out_smooth_shift',\n",
       " 'model.transformer.blocks.9.q_proj.bias',\n",
       " 'model.transformer.blocks.9.qkv_smooth_shift',\n",
       " 'model.transformer.blocks.9.up_proj.bias',\n",
       " 'model.transformer.blocks.9.v_proj.bias'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd1.keys() - sd2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a9e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef72fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
